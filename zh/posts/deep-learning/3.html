<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.18" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.59" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://crc011220.github.io/zh/posts/deep-learning/3.html"><meta property="og:site_name" content="Ruochen Chen"><meta property="og:title" content="深度学习第三章节"><meta property="og:description" content="深度学习第三章节 1 PyTorch构建线性回归模型 1.1 创建数据集 1.2 训练模型 2 人工神经网络介绍 2.1 什么是人工神经网络 仿生生物学神经网络的计算模型 ANN(人工神经网络)->NN(神经网络) 2.2 如何构建人工神经网络 神经网络是由三个层, 每层由多个神经元构成 输入层: 输入样本的特征值, 一层 隐藏层: 提取复杂特征, 可..."><meta property="og:type" content="article"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-11-30T02:00:34.000Z"><meta property="article:tag" content="Deep Learning"><meta property="article:published_time" content="2025-11-17T00:00:00.000Z"><meta property="article:modified_time" content="2025-11-30T02:00:34.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"深度学习第三章节","image":[""],"datePublished":"2025-11-17T00:00:00.000Z","dateModified":"2025-11-30T02:00:34.000Z","author":[{"@type":"Person","name":"Ruochen Chen"}]}</script><link rel="icon" href="/mac.ico"><title>深度学习第三章节 | Ruochen Chen</title><meta name="description" content="深度学习第三章节 1 PyTorch构建线性回归模型 1.1 创建数据集 1.2 训练模型 2 人工神经网络介绍 2.1 什么是人工神经网络 仿生生物学神经网络的计算模型 ANN(人工神经网络)->NN(神经网络) 2.2 如何构建人工神经网络 神经网络是由三个层, 每层由多个神经元构成 输入层: 输入样本的特征值, 一层 隐藏层: 提取复杂特征, 可...">
    <link rel="stylesheet" href="/assets/css/styles.563fed46.css">
    <link rel="preload" href="/assets/js/runtime~app.9bb67f43.js" as="script"><link rel="preload" href="/assets/css/styles.563fed46.css" as="style"><link rel="preload" href="/assets/js/6312.34f20d6c.js" as="script"><link rel="preload" href="/assets/js/app.ff77994c.js" as="script">
    <link rel="prefetch" href="/assets/js/zh_posts_declarative_haskell.html.8c87b5f2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_java8_函数式编程.html.40d1660d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_cmb_review.html.13458b80.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_Netty01-nio.html.6b030cf9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_Netty04-优化与源码.html.a06bcb3d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_Netty03-进阶.html.10e8bde8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_动态规划.html.f8a6083b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_数组.html.8af35e83.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_Netty02-intro.html.17d2ad2a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_二叉树.html.0252c56b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_nginx_1.html.c3c98206.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_其他问题.html.1275958b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_面试要点.html.1c7f13b2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_declarative_prolog.html.3a954dea.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_链表.html.b1dfdd7a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_其他.html.80e868f3.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_COMP90024.html.45f38ae1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_图.html.69b9a845.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_deep-learning_4.html.fd9ffcf6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_deep-learning_卷积神经网络CNN.html.47996a3b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_栈和队列.html.af497ee4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hive_Hive-SQL语法大全.html.f759f418.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_deep-learning_5.html.76bc5477.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_14.html.9aaba6e1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_declarative_haskell速记.html.ef4f7d84.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_回溯.html.ecd8e9b5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_deep-learning_循环神经网络RNN.html.27d1b54f.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_COMP90049.html.f2fdd90a.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_COMP90050.html.d392f89b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_deep-learning_1.html.c99a1c9b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_数据结构.html.4979e774.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_deep-learning_2.html.4f5247a4.js" as="script"><link rel="prefetch" href="/assets/js/posts_note_Coin-exchange-project-note.html.b25a336f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_deep-learning_3.html.e770d362.js" as="script"><link rel="prefetch" href="/assets/js/posts_tailwind_summary.html.12cdb2f0.js" as="script"><link rel="prefetch" href="/assets/js/2664.86a91f7e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_计算机网络.html.696d6361.js" as="script"><link rel="prefetch" href="/assets/js/posts_typescript_1.html.5dc7387d.js" as="script"><link rel="prefetch" href="/assets/js/posts_typescript_2.html.bceb6a75.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_贪心.html.c6b34afe.js" as="script"><link rel="prefetch" href="/assets/js/posts_aws-saa_1.html.177e1f79.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_ml.html.788cf46b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_数据库.html.38294ea6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_操作系统.html.2e1d2bbb.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_nlp_1.html.91b39bb8.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_COMP90048.html.5bc76c43.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_计算机组成原理.html.ccb41d2c.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_1.html.c5da541d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_declarative_prolog速记.html.c0c75089.js" as="script"><link rel="prefetch" href="/assets/js/8300.14894ef4.js" as="script"><link rel="prefetch" href="/assets/js/posts_mybatis_2.html.db75dcd2.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_双指针.html.dcbf74cb.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_7.html.75cd7a1b.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_4.html.7b61713b.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_5.html.4e640a94.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_哈希.html.7191fba9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_nlp_2.html.7e627558.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_8.html.2a069622.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_2.html.28e1dffb.js" as="script"><link rel="prefetch" href="/assets/js/posts_aws-saa_3.html.982df5d0.js" as="script"><link rel="prefetch" href="/assets/js/posts_nginx_1.html.0a9ef4e3.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_SWEN90016.html.91bb292c.js" as="script"><link rel="prefetch" href="/assets/js/posts_spark_Spark-Core.html.05cb9b15.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_11.html.970906ea.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_14.html.45fbc6bb.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_8.html.002dcc85.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_4.html.ba6c0782.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_信息新技术.html.be677525.js" as="script"><link rel="prefetch" href="/assets/js/posts_spark_Spark-Sql.html.0a30b882.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_21.html.4496521a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_daily_skills.html.3e0bb714.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_12-美股投资策略.html.86a9eb3b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_13-美股交易规则.html.679e9c1c.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_11.html.c16822d9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_7-风险管理.html.28f3141d.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_5.html.22b3e187.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_6.html.6a4a300d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_daily_CE-project.html.fb8c775b.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_10.html.446c7da5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_11-如何投资美股.html.7483b3b5.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_15-ETF选择指南-纳斯达克100.html.34f1039b.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_1.html.b58eda92.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_14-个股分析案例-英伟达.html.7821f77a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_8-交易技巧.html.bec79c90.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_5-财务报表解读.html.cb55ed64.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_单调栈.html.65c2776c.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_6.html.90316726.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_4.html.15a69407.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_10-美股市场特点.html.19afbd3e.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_15.html.083892cc.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_py_numpy.html.6b59cce4.js" as="script"><link rel="prefetch" href="/assets/js/posts_aws-saa_2.html.63b9fd8e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_py_pandas.html.83447d88.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_6.html.3681f2b0.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_6-投资策略.html.2648c568.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_3.html.42b1f4d4.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_12.html.ca965f90.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_9-美股基础知识.html.10db055b.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_3-股票市场入门.html.91b91696.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_14.html.d5372a71.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_2-股票基础知识.html.d0decc31.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_13.html.1f2b36bf.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_javaai.html.74fdba9d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_字符串.html.ff3d7193.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_4-股票分析方法.html.6d6e43c7.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_5.html.7f4e8fb8.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_6.html.087ef28e.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_2.html.4def8772.js" as="script"><link rel="prefetch" href="/assets/js/posts_typescript_3.html.249b422e.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_2.html.0325f0d9.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_16.html.ac1e8d01.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_2.html.46e9824a.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_7.html.cbe998f9.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_3.html.f8dc6fdd.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_12.html.ba44f1e4.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_17.html.37ee66f3.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_位运算.html.218c3265.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_13.html.fef35e9b.js" as="script"><link rel="prefetch" href="/assets/js/intro.html.2e98292e.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_9.html.632a787f.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_15.html.8c8188a0.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_create_mcp.html.533f660c.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_18.html.8e1ad428.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_1.html.8751908b.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_mcp.html.ed4aa6a9.js" as="script"><link rel="prefetch" href="/assets/js/posts_mybatis_1.html.4f6a9358.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_1.html.9e383813.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_1-金融基础概念.html.3b1274d3.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_7.html.95648d46.js" as="script"><link rel="prefetch" href="/assets/js/posts_istio_1.html.30859a44.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_4.html.9a08d7d3.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_15.html.3fa1eae7.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_10.html.c68171c4.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_1.html.de1e1552.js" as="script"><link rel="prefetch" href="/assets/js/zh_intro.html.3d16bbfe.js" as="script"><link rel="prefetch" href="/assets/js/posts_spark_Spark-Intro.html.d16644da.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_5.html.16d411e3.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_19.html.38712a54.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_7.html.2437ce47.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_数学.html.5fe6c3f9.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_3.html.7e27f56c.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_7.html.abcbe1ef.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_8.html.2569e227.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_finance_index.html.778e8390.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_index.html.c0edcde2.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_3.html.802f030e.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_Hive.html.eb88f001.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_7.html.d89efd0f.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_9.html.f901c68a.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_HDFS.html.91ff53ef.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_index.html.116eb444.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_good_mcp.html.68e7736e.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_2.html.aecf58f9.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_8.html.a6bfae84.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_4.html.e48b4853.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_daily_good_mcp.html.a3c0902a.js" as="script"><link rel="prefetch" href="/assets/js/posts_jd_note.html.6b67dee8.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_5.html.a2ff101c.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_3.html.69869cbb.js" as="script"><link rel="prefetch" href="/assets/js/posts_docker_1.html.377d8749.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_11.html.9ebfb3bd.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_microsvc_1.html.8ae60b3b.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_index.html.8ab4401b.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_summary.html.d72e0b7d.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_6.html.76d483d6.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_6.html.7c3748ee.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_3.html.9fd07548.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_6.html.6ed2bd98.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_7.html.d245ffc7.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_8.html.5515b3e2.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_4.html.2e3e4df8.js" as="script"><link rel="prefetch" href="/assets/js/posts_elasticsearch_query-dsl.html.60aa5ed1.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_cloudflare.html.bf17ad2d.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_20.html.4de7341b.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_1.html.67e91c06.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_5.html.11d820af.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_2.html.0716d1a1.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_10.html.1f4d9b9c.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_16.html.fd55f91e.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_3.html.83b7a26f.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_tools.html.1fdbd61f.js" as="script"><link rel="prefetch" href="/assets/js/posts_elasticsearch_1.html.f4e979a2.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_2.html.bb38228d.js" as="script"><link rel="prefetch" href="/assets/js/posts_docker_docker-podman.html.abacaf64.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_index.html.c331ef18.js" as="script"><link rel="prefetch" href="/assets/js/posts_dubbo_1.html.405486fb.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_4.html.046bb2ce.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_9.html.f45d605e.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_index.html.63af927c.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_index.html.b0bb4f27.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_index.html.cad521ad.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_9.html.836391d2.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_1.html.b1996c1d.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_8.html.db9f98c6.js" as="script"><link rel="prefetch" href="/assets/js/posts_elasticsearch_2.html.22acec5f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_genesis.html.b7e816b9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_词汇.html.4b433385.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_5.html.8cd4d1cf.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_GEOM90007.html.e3b372c0.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_index.html.f4e57161.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_MapReduce.html.75723559.js" as="script"><link rel="prefetch" href="/assets/js/posts_genesis.html.4e94cd83.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_12.html.9b6357a9.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_sealos.html.29198f4a.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_index.html.baea0f7a.js" as="script"><link rel="prefetch" href="/assets/js/posts_dubbo_2.html.62d5a24e.js" as="script"><link rel="prefetch" href="/assets/js/posts_cliché_13.html.df726101.js" as="script"><link rel="prefetch" href="/assets/js/posts_aws-saa_index.html.b3e65945.js" as="script"><link rel="prefetch" href="/assets/js/posts_typescript_index.html.5fd62eae.js" as="script"><link rel="prefetch" href="/assets/js/posts_elasticsearch_index.html.a08b1976.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_index.html.b0a1975e.js" as="script"><link rel="prefetch" href="/assets/js/index.html.b2d0a002.js" as="script"><link rel="prefetch" href="/assets/js/posts_dubbo_index.html.42302fb2.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_Yarn.html.db1a275b.js" as="script"><link rel="prefetch" href="/assets/js/posts_nginx_index.html.350d8a38.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_index.html.0f59a711.js" as="script"><link rel="prefetch" href="/assets/js/posts_mybatis_index.html.931c43c6.js" as="script"><link rel="prefetch" href="/assets/js/posts_spark_index.html.4b085309.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_microsvc_index.html.f9c35bbc.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_9.html.71162abb.js" as="script"><link rel="prefetch" href="/assets/js/posts_nginx_2.html.3a2f1fef.js" as="script"><link rel="prefetch" href="/assets/js/zh_index.html.a165dbd7.js" as="script"><link rel="prefetch" href="/assets/js/posts_tailwind_index.html.b0d16a8c.js" as="script"><link rel="prefetch" href="/assets/js/posts_docker_index.html.a7c8c584.js" as="script"><link rel="prefetch" href="/assets/js/posts_istio_index.html.17123110.js" as="script"><link rel="prefetch" href="/assets/js/posts_note_index.html.fec20934.js" as="script"><link rel="prefetch" href="/assets/js/category_learning-records_index.html.510e9bba.js" as="script"><link rel="prefetch" href="/assets/js/tag_china-merchant-bank_index.html.0b9b9b12.js" as="script"><link rel="prefetch" href="/assets/js/tag_notes_index.html.0ac76b75.js" as="script"><link rel="prefetch" href="/assets/js/tag_nginx_index.html.e7be5f14.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_declarative-programming_index.html.a822ad65.js" as="script"><link rel="prefetch" href="/assets/js/category_index.html.768835fc.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai_index.html.fe4f2152.js" as="script"><link rel="prefetch" href="/assets/js/timeline_index.html.b424f566.js" as="script"><link rel="prefetch" href="/assets/js/article_index.html.9adb921b.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_学习笔记_index.html.29a3fb96.js" as="script"><link rel="prefetch" href="/assets/js/category_internship-journal_index.html.f69799d2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_china-merchant-bank_index.html.cc251181.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_learning-records_index.html.59568783.js" as="script"><link rel="prefetch" href="/assets/js/star_index.html.32212a7d.js" as="script"><link rel="prefetch" href="/assets/js/tag_index.html.097dea27.js" as="script"><link rel="prefetch" href="/assets/js/tag_programmer-cliché_index.html.a6185911.js" as="script"><link rel="prefetch" href="/assets/js/tag_algorithm-practices_index.html.97c60e68.js" as="script"><link rel="prefetch" href="/assets/js/tag_technical-interview_index.html.b2812be8.js" as="script"><link rel="prefetch" href="/assets/js/posts_index.html.33b12a16.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_deep-learning_index.html.4a7794c4.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_job-journal_index.html.9683f713.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_开始_index.html.57d4c6ef.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_case-study_index.html.8daf32af.js" as="script"><link rel="prefetch" href="/assets/js/tag_tailwind-css_index.html.54d490c2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_旅程_index.html.b1e6b88d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_简历_index.html.4e50e8ea.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_algorithm_index.html.e80eac7f.js" as="script"><link rel="prefetch" href="/assets/js/category_genesis_index.html.591bccca.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_us-stock_index.html.b9c88b47.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_python_index.html.d1edd527.js" as="script"><link rel="prefetch" href="/assets/js/tag_javascript_index.html.001c06ee.js" as="script"><link rel="prefetch" href="/assets/js/tag_kubernetes_index.html.eef84d75.js" as="script"><link rel="prefetch" href="/assets/js/tag_typescript_index.html.6184e840.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_finance_index.html.10c74222.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_review_index.html.6742583d.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_pandas_index.html.49352803.js" as="script"><link rel="prefetch" href="/assets/js/tag_leetcode_index.html.498be3e5.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_java8_index.html.28884a39.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_netty_index.html.53b52f0e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_notes_index.html.3f741263.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_numpy_index.html.1b33f3a1.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_stock_index.html.a3279b5e.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_nginx_index.html.4491ae9e.js" as="script"><link rel="prefetch" href="/assets/js/tag_aws-saa_index.html.20911f7f.js" as="script"><link rel="prefetch" href="/assets/js/tag_mybatis_index.html.6033540a.js" as="script"><link rel="prefetch" href="/assets/js/tag_unimelb_index.html.328045e2.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_hive_index.html.9768a59d.js" as="script"><link rel="prefetch" href="/assets/js/tag_docker_index.html.b878209e.js" as="script"><link rel="prefetch" href="/assets/js/tag_hadoop_index.html.690832f8.js" as="script"><link rel="prefetch" href="/assets/js/tag_nextjs_index.html.a6285052.js" as="script"><link rel="prefetch" href="/assets/js/tag_resume_index.html.38124bb9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_etf_index.html.e24ec755.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_nlp_index.html.dcf160a8.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_nio_index.html.bb0f4482.js" as="script"><link rel="prefetch" href="/assets/js/tag_dubbo_index.html.abf3ebe1.js" as="script"><link rel="prefetch" href="/assets/js/tag_index_index.html.8ae4b8d4.js" as="script"><link rel="prefetch" href="/assets/js/tag_istio_index.html.858428e3.js" as="script"><link rel="prefetch" href="/assets/js/tag_react_index.html.43ba41a0.js" as="script"><link rel="prefetch" href="/assets/js/tag_spark_index.html.29181dd3.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ai_index.html.325869d0.js" as="script"><link rel="prefetch" href="/assets/js/404.html.21f5a3fe.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_deep-learning_index.html.54b8bafd.js" as="script"><link rel="prefetch" href="/assets/js/zh_timeline_index.html.72e8127a.js" as="script"><link rel="prefetch" href="/assets/js/tag_es_index.html.57e41629.js" as="script"><link rel="prefetch" href="/assets/js/tag_jd_index.html.a77e5283.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_index.html.7475689f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_declarative_index.html.af0bc0ff.js" as="script"><link rel="prefetch" href="/assets/js/zh_article_index.html.81774320.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_index.html.f4be6e27.js" as="script"><link rel="prefetch" href="/assets/js/zh_star_index.html.bba3a853.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_index.html.52fa9622.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_daily_index.html.a7f16b51.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_java8_index.html.5af50263.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_index.html.0308eef4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_nginx_index.html.cbe553ce.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_index.html.584fefbd.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hive_index.html.40be20be.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_index.html.43c8149d.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_nlp_index.html.6ca94a7a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_cmb_index.html.08bb2469.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_py_index.html.c412c1ae.js" as="script"><link rel="prefetch" href="/assets/js/posts_jd_index.html.5097556f.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">跳至主要內容</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/zh/" aria-label="带我回家"><img class="vp-nav-logo" src="/bubu.jpg" alt><!----><span class="vp-site-name hide-in-pad">Ruochen Chen</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/zh/" aria-label="主页"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span><!--]-->主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="笔记"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>笔记<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">算法</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E6%95%B0%E7%BB%84.html" aria-label="数组"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->数组<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E9%93%BE%E8%A1%A8.html" aria-label="链表"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->链表<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E5%AD%97%E7%AC%A6%E4%B8%B2.html" aria-label="字符串"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->字符串<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97.html" aria-label="栈和队列"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->栈和队列<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E4%BA%8C%E5%8F%89%E6%A0%91.html" aria-label="二叉树"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->二叉树<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E5%9B%BE.html" aria-label="图"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->图<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E5%93%88%E5%B8%8C.html" aria-label="哈希"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->哈希<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E5%8F%8C%E6%8C%87%E9%92%88.html" aria-label="双指针"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->双指针<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92.html" aria-label="动态规划"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->动态规划<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E5%9B%9E%E6%BA%AF.html" aria-label="回溯"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->回溯<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E8%B4%AA%E5%BF%83.html" aria-label="贪心"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->贪心<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E5%8D%95%E8%B0%83%E6%A0%88.html" aria-label="单调栈"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->单调栈<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E4%BD%8D%E8%BF%90%E7%AE%97.html" aria-label="位运算"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->位运算<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/algo/%E5%85%B6%E4%BB%96.html" aria-label="其他"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->其他<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">招商银行</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/cmb/review.html" aria-label="实习记录"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->实习记录<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">日常记录</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/daily/CE-project.html" aria-label="CE项目"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->CE项目<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/daily/good_mcp.html" aria-label="Good MCP"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Good MCP<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/daily/skills.html" aria-label="Skills"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Skills<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">声明式编程</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/declarative/haskell.html" aria-label="Haskell"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Haskell<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/declarative/haskell%E9%80%9F%E8%AE%B0.html" aria-label="Haskell速记"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Haskell速记<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/declarative/prolog.html" aria-label="Prolog"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Prolog<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/declarative/prolog%E9%80%9F%E8%AE%B0.html" aria-label="Prolog速记"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Prolog速记<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">深度学习</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/deep-learning/1.html" aria-label="深度学习基础"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习基础<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/deep-learning/2.html" aria-label="深度学习进阶"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习进阶<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/zh/posts/deep-learning/3.html" aria-label="深度学习应用"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习应用<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/deep-learning/4.html" aria-label="深度学习优化"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习优化<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/deep-learning/5.html" aria-label="深度学习实践"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习实践<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/deep-learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN.html" aria-label="卷积神经网络CNN"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->卷积神经网络CNN<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/deep-learning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN.html" aria-label="循环神经网络RNN"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->循环神经网络RNN<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Hive</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/hive/Hive-SQL%E8%AF%AD%E6%B3%95%E5%A4%A7%E5%85%A8.html" aria-label="Hive语法大全"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Hive语法大全<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Java8特性</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/java8/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B.html" aria-label="函数式编程"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->函数式编程<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">自然语言处理</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/nlp/1.html" aria-label="NLP基础"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->NLP基础<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/nlp/2.html" aria-label="NLP进阶"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->NLP进阶<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Netty</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/netty/Netty01-nio.html" aria-label="Nio介绍"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Nio介绍<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/netty/Netty02-intro.html" aria-label="Netty入门"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Netty入门<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/netty/Netty03-%E8%BF%9B%E9%98%B6.html" aria-label="Netty进阶"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Netty进阶<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/netty/Netty04-%E4%BC%98%E5%8C%96%E4%B8%8E%E6%BA%90%E7%A0%81.html" aria-label="Netty优化"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Netty优化<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">NGINX</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/nginx/1.html" aria-label="NGINX 高级"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->NGINX 高级<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Python</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/py/numpy.html" aria-label="NumPy"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->NumPy<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/py/pandas.html" aria-label="Pandas"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Pandas<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">复习笔记</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E9%9D%A2%E8%AF%95%E8%A6%81%E7%82%B9.html" aria-label="面试要点"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->面试要点<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.html" aria-label="数据结构"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->数据结构<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E5%85%B6%E4%BB%96%E9%97%AE%E9%A2%98.html" aria-label="算法"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->算法<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F.html" aria-label="操作系统"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->操作系统<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C.html" aria-label="计算机网络"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->计算机网络<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E6%95%B0%E6%8D%AE%E5%BA%93.html" aria-label="数据库"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->数据库<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86.html" aria-label="计算机组成原理"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->计算机组成原理<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E4%BF%A1%E6%81%AF%E6%96%B0%E6%8A%80%E6%9C%AF.html" aria-label="信息新技术"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->信息新技术<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E6%95%B0%E5%AD%A6.html" aria-label="数学"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->数学<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/zh/posts/review/%E8%AF%8D%E6%B1%87.html" aria-label="词汇"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->词汇<!----></a></li></ul></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="选择语言"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/zh/posts/deep-learning/3.html" aria-label="简体中文"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/Crc011220/Crc011220.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="搜索文档"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">搜索文档</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/" aria-label="主页"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span><!--]-->主页<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span><span class="vp-sidebar-title">笔记</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Algo</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Cmb</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Daily</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Declarative</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Deep Learning</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/deep-learning/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN.html" aria-label="卷积神经网络CNN"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->卷积神经网络CNN<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/deep-learning/%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CRNN.html" aria-label="循环神经网络RNN"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->循环神经网络RNN<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/deep-learning/1.html" aria-label="深度学习第一章节"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习第一章节<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/zh/posts/deep-learning/3.html" aria-label="深度学习第三章节"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习第三章节<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/deep-learning/2.html" aria-label="深度学习第二章节"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习第二章节<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/deep-learning/5.html" aria-label="深度学习第五章节"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习第五章节<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/deep-learning/4.html" aria-label="深度学习第四章节"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->深度学习第四章节<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Finance</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Hive</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Java8</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Netty</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Nginx</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Nlp</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Py</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Review</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/posts/genesis.html" aria-label="开始"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->开始<!----></a></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/zh/intro.html" aria-label="关于我"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-info" style=""></span><!--]-->关于我<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>深度学习第三章节</h1><div class="page-info"><span class="page-author-info" aria-label="作者🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Ruochen Chen</span></span><span property="author" content="Ruochen Chen"></span></span><!----><span class="page-date-info" aria-label="写作日期📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025年11月17日</span><meta property="datePublished" content="2025-11-17T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="阅读时间⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>大约 13 分钟</span><meta property="timeRequired" content="PT13M"></span><span class="page-category-info" aria-label="分类🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color5 clickable" role="navigation">Learning Records</span><!--]--><meta property="articleSection" content="Learning Records"></span><span class="page-tag-info" aria-label="标签🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color1 clickable" role="navigation">Deep Learning</span><!--]--><meta property="keywords" content="Deep Learning"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc" vp-toc><!----><div class="vp-toc-header">此页内容<button type="button" class="print-button" title="打印"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_1-pytorch构建线性回归模型">1 PyTorch构建线性回归模型</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-1-创建数据集">1.1 创建数据集</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-2-训练模型">1.2 训练模型</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_2-人工神经网络介绍">2 人工神经网络介绍</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-1-什么是人工神经网络">2.1 什么是人工神经网络</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-2-如何构建人工神经网络">2.2 如何构建人工神经网络</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-3-人工神经网络内部状态值和激活值">2.3 人工神经网络内部状态值和激活值</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_3-激活函数介绍">3 激活函数介绍</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-1-激活函数作用">3.1 激活函数作用</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-2-常见激活函数">3.2 常见激活函数</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-6-如何选择激活函数">3.6 如何选择激活函数</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#_4-参数初始化">4 参数初始化</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-1-参数初始化作用">4.1 参数初始化作用</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-2-常见参数初始化方法">4.2 常见参数初始化方法</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-3-权重初始化方法速查表">4.3 权重初始化方法速查表</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-3-如何选择参数初始化方法">4.3 如何选择参数初始化方法</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_4-4-参数初始化总结">4.4 参数初始化总结</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="深度学习第三章节" tabindex="-1"><a class="header-anchor" href="#深度学习第三章节"><span>深度学习第三章节</span></a></h1><h2 id="_1-pytorch构建线性回归模型" tabindex="-1"><a class="header-anchor" href="#_1-pytorch构建线性回归模型"><span>1 PyTorch构建线性回归模型</span></a></h2><h3 id="_1-1-创建数据集" tabindex="-1"><a class="header-anchor" href="#_1-1-创建数据集"><span>1.1 创建数据集</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.utils.data </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> TensorDataset  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 创建x和y张量数据集对象</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.utils.data </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> DataLoader  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 创建数据集加载器</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.nn </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 损失函数和回归函数</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.optim </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> SGD</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 随机梯度下降函数, 取一个训练样本算梯度值</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> sklearn.datasets </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> make_regression  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 创建随机样本, 工作中不使用</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> matplotlib.pyplot </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.rcParams[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;font.sans-serif&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;SimHei&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 用来正常显示中文标签</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.rcParams[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;axes.unicode_minus&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> False</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 用来正常显示负号</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># todo: 1-创建线性回归样本 x y coef(w) b</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> create_datasets</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x, y, coef </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> make_regression</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">n_samples</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">100</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 样本数</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">								 n_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 特征数</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">								 noise</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 标准差, 噪声, 样本离散程度</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">								 coef</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 返回系数, w</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">								 bias</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">14.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 截距 b</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">								 random_state</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 将数组转换成张量</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">data</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">data</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">y)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# print(&#39;x-&gt;&#39;, x)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# print(&#39;y-&gt;&#39;, y)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# print(&#39;coef-&gt;&#39;, coef)</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">	return</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x, y, coef</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x, y, coef </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> create_datasets</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_1-2-训练模型" tabindex="-1"><a class="header-anchor" href="#_1-2-训练模型"><span>1.2 训练模型</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># todo: 2-模型训练</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> train</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;">x</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> y</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#D19A66;--shiki-dark-font-style:italic;"> coef</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">):</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建张量数据集对象</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	datasets </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> TensorDataset</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;datasets-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, datasets)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建数据加载器对象</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# dataset: 张量数据集对象</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# batch_size: 每个batch的样本数</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# shuffle: 是否打乱样本</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	dataloader </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> DataLoader</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dataset</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">datasets, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">batch_size</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">16</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">shuffle</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;dataloader-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, dataloader)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# for batch in dataloader:  # 每次遍历取每个batch样本</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 	print(&#39;batch-&gt;&#39;, batch)  # [x张量对象, y张量对象]</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 	break</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建初始回归模型对象, 随机生成w和b, 元素类型为float32</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# in_features: 输入特征数 1个</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# out_features: 输出特征数 1个</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	model </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Linear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">in_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">out_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;model-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, model)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 获取模型对象的w和b参数</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;model.weight-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, model.weight)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;model.bias-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, model.bias)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;model.parameters()-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">list</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">parameters</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()))</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建损失函数对象, 计算损失值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	criterion </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">MSELoss</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建SGD优化器对象, 更新w和b</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	optimizer </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> SGD</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">params</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">model.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">parameters</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">lr</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 定义变量, 接收训练次数, 损失值, 训练样本数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	epochs </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 100</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	loss_list </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> []  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 存储每次训练的平均损失值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	total_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0.0</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	train_samples </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 0</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">	for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> epoch </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;"> range</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(epochs):  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 训练100次</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">        # 借助循环实现 mini-batch SGD 模型训练</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">		for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> train_x, train_y </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> dataloader:</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 模型预测</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# train_x-&gt;float64</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# w-&gt;float32</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">			y_pred </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> model</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(train_x.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">type</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float32))  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># y=w*x+b</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">			print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;y_pred-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, y_pred)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 计算损失值, 调用损失函数对象</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# print(&#39;train_y-&gt;&#39;, train_y)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# y_pred: 二维张量</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# train_y: 一维张量, 修改成二维张量, n行1列</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 可能发生报错, 修改形状</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 修改train_y元素类型, 和y_pred类型一致, 否则发生报错</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">			loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> criterion</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(y_pred, train_y.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">reshape</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">shape</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">type</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.float32))</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">			print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;loss-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, loss)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 获取loss标量张量的数值 item()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 统计n次batch的总MSE值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">			total_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> loss.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">item</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 统计batch次数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">			train_samples </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 梯度清零</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">			optimizer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">zero_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 计算梯度值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">			loss.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">backward</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# 梯度更新 w和b更新</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">			# step()等同 w=w-lr*grad</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">			optimizer.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">step</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">		# 每次训练的平均损失值保存到loss列表中</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">		loss_list.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">append</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(total_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> train_samples)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">		print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;每次训练的平均损失值-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, total_loss </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> train_samples)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;loss_list-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, loss_list)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;w-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, model.weight)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;b-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, model.bias)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    </span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">    # 绘制每次训练损失值曲线变化图</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">range</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(epochs), loss_list)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">title</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;损失值曲线变化图&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">grid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">show</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 绘制预测值和真实值对比图</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 绘制样本点分布</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">scatter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 获取1000个样本点</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# x = torch.linspace(start=x.min(), end=x.max(), steps=1000)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 计算训练模型的预测值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	y1 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">data</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[v </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> model.weight </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> model.bias </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> v </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x])</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 计算真实值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	y2 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">data</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[v </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">*</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> coef </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 14.5</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> for</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> v </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">in</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> x])</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y1, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">label</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;训练&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y2, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">label</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;真实&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">legend</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">grid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">show</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x, y, coef </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> create_datasets</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">	train</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y, coef)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-人工神经网络介绍" tabindex="-1"><a class="header-anchor" href="#_2-人工神经网络介绍"><span>2 人工神经网络介绍</span></a></h2><h3 id="_2-1-什么是人工神经网络" tabindex="-1"><a class="header-anchor" href="#_2-1-什么是人工神经网络"><span>2.1 什么是人工神经网络</span></a></h3><ul><li>仿生生物学神经网络的计算模型</li><li>ANN(人工神经网络)-&gt;NN(神经网络)</li></ul><h3 id="_2-2-如何构建人工神经网络" tabindex="-1"><a class="header-anchor" href="#_2-2-如何构建人工神经网络"><span>2.2 如何构建人工神经网络</span></a></h3><blockquote><p>神经网络是由三个层, 每层由多个神经元构成</p></blockquote><ul><li>输入层: 输入样本的特征值, 一层</li><li>隐藏层: 提取复杂特征, 可以有多层</li><li>输出层: 输出y值, y预测值</li></ul><h3 id="_2-3-人工神经网络内部状态值和激活值" tabindex="-1"><a class="header-anchor" href="#_2-3-人工神经网络内部状态值和激活值"><span>2.3 人工神经网络内部状态值和激活值</span></a></h3><blockquote><p>神经元如何工作</p></blockquote><ul><li>内部状态值(加权求和值) <ul><li><code>z=w1*x1+w2*x2+...+b</code></li></ul></li><li>激活值 <ul><li><code>a=f(z)</code></li></ul></li></ul><h2 id="_3-激活函数介绍" tabindex="-1"><a class="header-anchor" href="#_3-激活函数介绍"><span>3 激活函数介绍</span></a></h2><h3 id="_3-1-激活函数作用" tabindex="-1"><a class="header-anchor" href="#_3-1-激活函数作用"><span>3.1 激活函数作用</span></a></h3><ul><li>给神经网络模型中引入非线性因素</li><li>生产环境中,问题存在线性不可分情况</li></ul><h3 id="_3-2-常见激活函数" tabindex="-1"><a class="header-anchor" href="#_3-2-常见激活函数"><span>3.2 常见激活函数</span></a></h3><ul><li><p>sigmoid激活函数</p><ul><li>sigmoid激活值范围是[0, 1], 只有正信号, 没有负信号, 模型只能学习到正信号</li><li>加权求和值在[-6,6]范围, 计算激活值时分布到[0, 1], 否则激活值只能是0或1</li><li>sigmoid激活函数导数值范围是[0,0.25], 加权求和值在[-6,6]范围, 激活值梯度才分布到[0, 0.25], 否则梯度为0</li><li>神经网络中梯度连乘, sigmoid激活函数梯度值很小, 接近0, 梯度消失 <code>0.25*0.25*0.25*...</code></li><li>sigmoid一般在二分类输出层使用, 如果神经网络隐藏层在5层之内也可以考虑使用sigmoid，实践中使用很少</li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># sigmoid激活值: torch.sigmoid(x) </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> matplotlib.pyplot </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.rcParams[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;font.sans-serif&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;SimHei&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 用来正常显示中文标签</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.rcParams[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;axes.unicode_minus&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> False</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 用来正常显示负号</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建x值, 线性模型输出值作为激活函数的输入值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">linspace</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 计算激活值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sigmoid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建画布对象和坐标轴对象</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	_, axes </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">subplots</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 一行两列, 绘制两个子图</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">grid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">set_title</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;sigmoid激活函数&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建x值,可以自动微分, 线性模型输出值作为激活函数的输入值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">linspace</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">requires_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sigmoid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sum</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">backward</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">detach</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">numpy</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(), x.grad)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">grid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">set_title</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;sigmoid激活函数&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">show</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">	dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><figure><img src="/assets/img/sigmoid.6542f779.png" alt="sigmoid激活函数" tabindex="0" loading="lazy"><figcaption>sigmoid激活函数</figcaption></figure><ul><li><p>tanh激活函数</p><ul><li>tanh激活值范围是[-1, 1], 既有正信号, 又有负信号, 激活值是以0对称, 模型可以学习到正负信号</li><li>加权求和值在[-3,3]范围, 计算激活值时分布到[-1, 1], 否则激活值只能是-1或1</li><li>tanh激活函数导数值范围是[0,1], 加权求和值在[-3,3]范围, 相比sigmoid激活导数更大, 模型收敛程度更快, 迭代次数更少, 但是如果加权求和值大于3或小于-3, 也是会导致梯度消失, 最好分布在0附近(梯度值最大)</li><li>tanh激活函数可以在隐藏层使用, 不是优先选择, 浅层神经网络可以使用</li><li>主要用于隐藏层（浅层不超过5层，因为深层使用tanh会导致梯度消失）, 输出层使用sigmoid激活函数</li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># tanh激活值: torch.tanh(x)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> matplotlib.pyplot </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.nn </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> functional </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> F</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># F.sigmoid()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># F.tanh()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.rcParams[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;font.sans-serif&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;SimHei&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 用来正常显示中文标签</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.rcParams[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;axes.unicode_minus&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> False</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 用来正常显示负号</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建x值, 线性模型输出值作为激活函数的输入值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">linspace</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 计算激活值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tanh</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建画布对象和坐标轴对象</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	_, axes </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">subplots</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 一行两列, 绘制两个子图</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">grid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">set_title</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;tanh激活函数&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建x值,可以自动微分, 线性模型输出值作为激活函数的输入值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">linspace</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">requires_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tanh</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sum</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">backward</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">detach</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">numpy</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(), x.grad)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">grid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">set_title</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;tanh激活函数&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">show</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">	dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><figure><img src="/assets/img/tanh.2e708b14.png" alt="tanh激活函数" tabindex="0" loading="lazy"><figcaption>tanh激活函数</figcaption></figure><ul><li><p>relu激活函数</p><ul><li>relu激活值范围是[0, x], x是线性输出的正值, 只有正信号</li><li>加权求和值大于0, 也可以一部分小于0(神经元死亡, 防止过拟合)</li><li>relu激活函数导数值0或1, 如果线性输出大于0, 导数为1, 不会出现梯度消失情况, 模型收敛程度更快, 比tanh收敛程度更快; 如果线性输出小于0, 权重不更新这个现象称为神经元死亡, 防止过拟合(选择leaky relu或prelu)</li><li>relu激活函数优先选择, 计算复杂度最小, 大于0不存在梯度消失情况</li><li>适合隐藏层，深层因为没有梯度消失问题</li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># relu激活值: torch.relu(x)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> matplotlib.pyplot </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.nn </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> functional </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> F</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># F.sigmoid()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># F.tanh()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.rcParams[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;font.sans-serif&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> [</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;SimHei&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 用来正常显示中文标签</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.rcParams[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;axes.unicode_minus&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> False</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 用来正常显示负号</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建x值, 线性模型输出值作为激活函数的输入值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">linspace</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 计算激活值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">relu</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# torch.leaky_relu()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# torch.prelu()</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建画布对象和坐标轴对象</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	_, axes </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">subplots</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 一行两列, 绘制两个子图</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">grid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">set_title</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;relu激活函数&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建x值,可以自动微分, 线性模型输出值作为激活函数的输入值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">linspace</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">20</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1000</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">requires_grad</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">relu</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x).</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sum</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">backward</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">detach</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">numpy</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(), x.grad)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">grid</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	axes[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">set_title</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;relu激活函数&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">show</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">	dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><figure><img src="/assets/img/relu.025d97e4.png" alt="relu激活函数" tabindex="0" loading="lazy"><figcaption>relu激活函数</figcaption></figure><ul><li><p>softmax激活函数</p><ul><li>多分类任务的输出层使用, 将输出层加权求和值转换成概率</li><li>比如a,b,c,d,e,f,g,h,i,j 10个类别, 输出层加权求和值为[0.2, 0.02, 0.15, 0.15, 1.3, 0.5, 0.06, 1.1, 0.05, 3.75], 通过softmax激活函数转换成概率值为[0.018, 0.002, 0.013, 0.013, 0.118, 0.046, 0.006, 0.099, 0.005, 0.331] <ul><li>概率值之和为1</li><li>概率值最大的为3.75, 对应的类别为j</li><li>概率值最小的为0.002, 对应的类别为b</li><li>概率值中间的为0.046, 对应的类别为f</li></ul></li></ul><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pandas </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建输出层加权求和值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">data</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.02</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.15</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.15</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1.3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.06</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1.1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.05</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.75</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">],</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">						   [</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.02</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.15</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">3.75</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1.3</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.06</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1.1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.05</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.15</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">]])</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# softmax激活函数转换成概率值</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 1轴按列计算</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# y_softmax = torch.softmax(input=y, dim=-1)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	y_softmax </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">softmax</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">input</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">y, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">dim</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;y_softmax-&gt;&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, y_softmax)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">	dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul><h3 id="_3-6-如何选择激活函数" tabindex="-1"><a class="header-anchor" href="#_3-6-如何选择激活函数"><span>3.6 如何选择激活函数</span></a></h3><ul><li><p>隐藏层</p><ul><li>优选relu激活函数, 其次选leaky relu/prelu &gt; tanh &gt; sigmoid</li><li>尽量少使用sigmoid激活函数, 可以使用tanh激活函数代替sigmoid激活函数 浅层神经网络</li></ul></li><li><p>输出层</p><ul><li>二分类问题 sigmoid激活函数</li><li>多分类问题 softmax激活函数</li><li>回归问题 identity激活函数</li></ul></li><li><p>激活函数总结</p></li></ul><figure><img src="/assets/img/activation_function.8a5f765c.png" alt="激活函数总结" tabindex="0" loading="lazy"><figcaption>激活函数总结</figcaption></figure><ul><li>激活函数的作用是引入非线性因素, 增加模型复杂度, 提高模型表达能力</li><li>神经网络绝大多数是处理分类问题, 只有少部分是处理回归问题</li></ul><h2 id="_4-参数初始化" tabindex="-1"><a class="header-anchor" href="#_4-参数初始化"><span>4 参数初始化</span></a></h2><ul><li>参数初始化的目的： <ul><li>防止梯度消失</li><li>防止梯度爆炸</li><li>加快模型收敛速度</li><li>打破对称性</li></ul></li></ul><h3 id="_4-1-参数初始化作用" tabindex="-1"><a class="header-anchor" href="#_4-1-参数初始化作用"><span>4.1 参数初始化作用</span></a></h3><ul><li>参数-&gt;w和b, 创建初版模型时指定w和b的值</li><li>选择合适的参数, 计算得到的加权求和的值会落到激活函数合理的区间, 加快模型收敛速度以及增加不同学习特征值</li></ul><h3 id="_4-2-常见参数初始化方法" tabindex="-1"><a class="header-anchor" href="#_4-2-常见参数初始化方法"><span>4.2 常见参数初始化方法</span></a></h3><h4 id="_1-随机初始化" tabindex="-1"><a class="header-anchor" href="#_1-随机初始化"><span>1. 随机初始化</span></a></h4><ul><li><strong>优点</strong>：避免神经元输出一致导致的梯度消失，实现简单。</li><li><strong>缺点</strong>：随机范围难把控，过大易导致激活值饱和，过小则梯度微弱。</li><li><strong>使用场景</strong>：适用于简单模型或无明确适配初始化的场景，需配合合适的随机范围（如[-0.01, 0.01]）。</li></ul><h4 id="_2-全0-1初始化" tabindex="-1"><a class="header-anchor" href="#_2-全0-1初始化"><span>2. 全0/1初始化</span></a></h4><ul><li><strong>优点</strong>：实现极简，参数完全一致。</li><li><strong>缺点</strong>：全0会导致所有神经元输出相同，梯度更新同步失效；全1易使激活值饱和，梯度消失。</li><li><strong>使用场景</strong>：仅适用于偏置项（bias）初始化（全0为主），<strong>绝对不能用于权重初始化</strong>。</li></ul><h4 id="_3-固定值初始化" tabindex="-1"><a class="header-anchor" href="#_3-固定值初始化"><span>3. 固定值初始化</span></a></h4><ul><li><strong>优点</strong>：参数可控，结果可复现，实现简单。</li><li><strong>缺点</strong>：固定值易导致神经元功能同质化，复杂模型中梯度传播受阻。</li><li><strong>使用场景</strong>：简单线性模型、调试阶段验证代码，或对参数有明确先验知识的场景。</li></ul><h4 id="_4-kaiming初始化" tabindex="-1"><a class="header-anchor" href="#_4-kaiming初始化"><span>4. Kaiming初始化</span></a></h4><ul><li><strong>优点</strong>：专为ReLU及其变种（如Leaky ReLU）设计，适配其非对称激活特性，有效缓解梯度消失/爆炸。</li><li><strong>缺点</strong>：不适用于Sigmoid、Tanh等对称激活函数，会导致输出方差失衡。</li><li><strong>使用场景</strong>：采用ReLU系列激活函数的模型，如CNN、ResNet、Transformer的部分层。</li></ul><h4 id="_5-xavier初始化" tabindex="-1"><a class="header-anchor" href="#_5-xavier初始化"><span>5. Xavier初始化</span></a></h4><ul><li><strong>优点</strong>：适配Sigmoid、Tanh等对称激活函数，保证前向传播输出方差与反向传播梯度方差一致。</li><li><strong>缺点</strong>：用于ReLU时效果不佳，无法抵消ReLU对负数部分的“截断”影响。</li><li><strong>使用场景</strong>：采用Sigmoid、Tanh激活函数的模型，如传统DNN、RNN的隐藏层。</li></ul><h3 id="_4-3-权重初始化方法速查表" tabindex="-1"><a class="header-anchor" href="#_4-3-权重初始化方法速查表"><span>4.3 权重初始化方法速查表</span></a></h3><table><thead><tr><th>初始化方法</th><th>核心公式（简化版）</th><th>适用激活函数</th><th>核心代码示例（PyTorch）</th></tr></thead><tbody><tr><td>随机初始化</td><td>权重 ~ Uniform(-a, a)（a通常取0.01）或 Normal(0, σ²)（σ取0.01）</td><td>通用（无明确适配时）</td><td><code>nn.init.uniform_(w, -0.01, 0.01)</code> 或 <code>nn.init.normal_(w, 0, 0.01)</code></td></tr><tr><td>全0/1初始化</td><td>权重 = 0 或 权重 = 1</td><td>仅偏置项（全0）</td><td><code>nn.init.zeros_(bias)</code> （权重禁用全0/1）</td></tr><tr><td>固定值初始化</td><td>权重 = 预设固定值（如0.02、0.1）</td><td>简单线性模型、调试场景</td><td><code>nn.init.constant_(w, 0.02)</code></td></tr><tr><td>Kaiming初始化</td><td>均匀分布：w ~ Uniform(-√(6/(fan_in)), √(6/(fan_in)))；正态分布：w ~ Normal(0, √(2/fan_in))</td><td>ReLU、Leaky ReLU、GELU等</td><td><code>nn.init.kaiming_uniform_(w, mode=&#39;fan_in&#39;, nonlinearity=&#39;relu&#39;)</code></td></tr><tr><td>Xavier初始化</td><td>均匀分布：w ~ Uniform(-√(6/(fan_in+fan_out)), √(6/(fan_in+fan_out)))；正态分布：w ~ Normal(0, √(2/(fan_in+fan_out)))</td><td>Sigmoid、Tanh、Softmax</td><td><code>nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain(&#39;tanh&#39;))</code></td></tr></tbody></table><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> torch.nn </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 随机参数初始化</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建线性层对象, 对线性层的权重进行初始化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# in_features: 输入神经元个数</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# out_features: 输出神经元个数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	linear1 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Linear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">in_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">out_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">8</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	linear2 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Linear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">in_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">8</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">out_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 均匀分布初始化，默认在(0，1)区间均匀分布, 可以通过a和b参数调整区间</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	nn.init.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">uniform_</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.weight)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    nn.init.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">uniform_</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.weight, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">a</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sqrt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5.0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">b</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sqrt</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(torch.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">tensor</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5.0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)))</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	nn.init.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">uniform_</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.bias)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.weight)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.bias)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 正态分布参数初始化</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">def</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> dm02</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">():</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 创建线性层对象, 对线性层的权重进行初始化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# in_features: 输入神经元个数</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# out_features: 输出神经元个数</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	linear1 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Linear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">in_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">out_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">8</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	linear2 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> nn.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">Linear</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">in_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">8</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">out_features</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">	# 均匀分布初始化</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	nn.init.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">normal_</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.weight)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	nn.init.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">normal_</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.bias)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.weight)</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">	print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(linear1.bias)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># nn.init.zeros_()  # 全0初始化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># nn.init.ones_()  # 全1初始化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># nn.init.constant_(val=0.1)  # 全固定值初始化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># nn.init.kaiming_uniform_()  # 凯明均匀分布初始化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># nn.init.kaiming_normal_()  # 凯明正态分布初始化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># nn.init.xavier_uniform_()  # xavier均匀分布初始化</span></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># nn.init.xavier_normal_()  # xavier正态分布初始化</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">if</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> __name__</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> ==</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> &#39;__main__&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">	dm01</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">	dm02</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_4-3-如何选择参数初始化方法" tabindex="-1"><a class="header-anchor" href="#_4-3-如何选择参数初始化方法"><span>4.3 如何选择参数初始化方法</span></a></h3><ul><li>浅层神经网络可以选择随机初始化</li><li>深层神经网络结合激活函数选择 <ul><li>tanh激活函数 -&gt; xavier初始化</li><li>relu激活函数 -&gt; kaiming初始化</li></ul></li></ul><h3 id="_4-4-参数初始化总结" tabindex="-1"><a class="header-anchor" href="#_4-4-参数初始化总结"><span>4.4 参数初始化总结</span></a></h3><h4 id="参数初始化的目的" tabindex="-1"><a class="header-anchor" href="#参数初始化的目的"><span>参数初始化的目的</span></a></h4><ol><li>防止梯度消失或梯度爆炸</li><li>提高收敛速度</li><li>打破对称性</li></ol><h4 id="参数初始化的方式" tabindex="-1"><a class="header-anchor" href="#参数初始化的方式"><span>参数初始化的方式</span></a></h4><h4 id="无法打破对称性的" tabindex="-1"><a class="header-anchor" href="#无法打破对称性的"><span>无法打破对称性的</span></a></h4><ul><li>全0初始化</li><li>全1初始化</li><li>固定值初始化</li></ul><h4 id="可以打破对称性的" tabindex="-1"><a class="header-anchor" href="#可以打破对称性的"><span>可以打破对称性的</span></a></h4><ul><li>随机初始化</li><li>正态分布初始化</li><li>kaiming初始化</li><li>xavier初始化</li></ul><h4 id="总结" tabindex="-1"><a class="header-anchor" href="#总结"><span>总结</span></a></h4><ol><li>重点记忆：kaiming初始化、xavier初始化、全0初始化</li><li>初始化选择原则： <ul><li>激活函数为ReLU及其系列：优先使用kaiming初始化</li><li>激活函数为非ReLU（如Sigmoid、Tanh）：优先使用xavier初始化</li><li>浅层网络：可考虑使用随机初始化</li></ul></li></ol></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/Crc011220/Crc011220.github.io/edit/main/src/zh/posts/deep-learning/3.md" aria-label="在 GitHub 上编辑此页" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->在 GitHub 上编辑此页<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">上次编辑于: </span><span class="vp-meta-info" data-allow-mismatch="text">2025/11/30 02:00:34</span></div><div class="contributors"><span class="vp-meta-label">贡献者: </span><!--[--><!--[--><span class="vp-meta-info" title="email: ruocchen1220@gmail.com">Ruochen Chen</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/zh/posts/deep-learning/1.html" aria-label="深度学习第一章节"><div class="hint"><span class="arrow start"></span>上一页</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>深度学习第一章节</div></a><a class="route-link auto-link next" href="/zh/posts/deep-learning/2.html" aria-label="深度学习第二章节"><div class="hint">下一页<span class="arrow end"></span></div><div class="link">深度学习第二章节<span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">学海无涯</div><div class="vp-copyright">Copyright © 2026 Ruochen Chen </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script src="/assets/js/runtime~app.9bb67f43.js" defer></script><script src="/assets/js/6312.34f20d6c.js" defer></script><script src="/assets/js/app.ff77994c.js" defer></script>
  </body>
</html>
