"use strict";(self.webpackChunkpersonalweb=self.webpackChunkpersonalweb||[]).push([[9641],{66262:(e,t)=>{t.A=(e,t)=>{const a=e.__vccOpts||e;for(const[e,n]of t)a[e]=n;return a}},79601:(e,t,a)=>{a.r(t),a.d(t,{comp:()=>o,data:()=>r});var n=a(20641);const l={},o=(0,a(66262).A)(l,[["render",function(e,t){return(0,n.uX)(),(0,n.CE)("div",null,t[0]||(t[0]=[(0,n.Fv)('<h1 id="fine-tuning-微调与-lora" tabindex="-1"><a class="header-anchor" href="#fine-tuning-微调与-lora"><span>Fine Tuning 微调与 LoRA</span></a></h1><h2 id="一、微调与-lora-的底层逻辑" tabindex="-1"><a class="header-anchor" href="#一、微调与-lora-的底层逻辑"><span>一、微调与 LoRA 的底层逻辑</span></a></h2><h3 id="什么是微调" tabindex="-1"><a class="header-anchor" href="#什么是微调"><span>什么是微调</span></a></h3><p>可以将预训练模型比作刚毕业的全能本科生，具备广泛知识但缺乏行业特定业务能力。<strong>微调</strong>就是通过行业数据训练，使其从通才转变为懂业务的专才，让模型掌握公司业务或行业黑话。</p><h3 id="lora-的原理" tabindex="-1"><a class="header-anchor" href="#lora-的原理"><span>LoRA 的原理</span></a></h3><p><strong>LoRA</strong>（Low-Rank Adaptation）的核心逻辑是：冻结原模型参数，不修改模型「大脑」，而是在模型层间插入可训练的低秩矩阵（Adapter 适配器参数）。如同给教科书贴便利贴，新增知识写在便利贴上，模型推理时同时参考原模型和新增参数。</p><h3 id="lora-的三大优势" tabindex="-1"><a class="header-anchor" href="#lora-的三大优势"><span>LoRA 的三大优势</span></a></h3><ul><li><strong>省显存</strong>：仅训练新增的 Adapter 参数，显存占用仅为全量微调的 1/3 甚至更少，免费云端显卡也能运行</li><li><strong>速度快</strong>：训练时间大幅缩短，别人需一周，LoRA 可能仅需几十分钟，且在垂直领域效果不输全量微调</li><li><strong>效果好</strong>：以最小代价实现专属领域效果优化，实现「不动大手术，只做微整形」</li></ul><h2 id="二、环境准备" tabindex="-1"><a class="header-anchor" href="#二、环境准备"><span>二、环境准备</span></a></h2><h3 id="使用-modelscope-免费云端算力" tabindex="-1"><a class="header-anchor" href="#使用-modelscope-免费云端算力"><span>使用 ModelScope 免费云端算力</span></a></h3><ol><li>登录 <a href="https://modelscope.cn" target="_blank" rel="noopener noreferrer">ModelScope</a> 官网，进入「我的 Notebook」</li><li>选择 GPU 环境（24G 显存足够运行 DeepSeek-R1 的 LoRA 微调）</li><li>镜像选择官方默认 Pytorch 镜像，预装必要驱动，开箱即用</li><li>启动后点击「查看 Notebook」进入网页代码编辑器</li><li>注意：超过一小时无操作会自动关闭，需定期操作或设置自动刷新</li></ol><h3 id="核心依赖库安装" tabindex="-1"><a class="header-anchor" href="#核心依赖库安装"><span>核心依赖库安装</span></a></h3><p>离开 ModelScope 官方镜像时需安装：</p><ul><li><strong>transformers</strong>：大模型基础设施</li><li><strong>peft</strong>：管理 LoRA 适配器参数</li><li><strong>bitsandbytes</strong>：量化工具，节省显存</li></ul><p>安装时可使用国内镜像源，提升下载速度。</p><h2 id="三、代码实战步骤" tabindex="-1"><a class="header-anchor" href="#三、代码实战步骤"><span>三、代码实战步骤</span></a></h2><h3 id="_1-工作区整理" tabindex="-1"><a class="header-anchor" href="#_1-工作区整理"><span>1. 工作区整理</span></a></h3><ul><li>在文件浏览器右键新建文件夹，用于存放训练模型、日志和数据集</li><li>进入该文件夹后，新建 Jupyter Notebook（相较 .py 脚本，可分块运行、容错率高，适合边学边练）</li></ul><h3 id="_2-加载模型并测试" tabindex="-1"><a class="header-anchor" href="#_2-加载模型并测试"><span>2. 加载模型并测试</span></a></h3><ul><li>在 ModelScope 模型库找到版本，通过 SDK 下载到本地</li><li>模型默认存放在 <code>.cache/modelscope/models/deepseek-ai/</code>，需通过终端（<code>ls -a</code>、<code>cd</code>）找到绝对路径并替换代码中的变量</li><li>有 GPU 时保留相关配置，无独显则删除</li></ul><h3 id="_3-制作数据集" tabindex="-1"><a class="header-anchor" href="#_3-制作数据集"><span>3. 制作数据集</span></a></h3><ul><li>准备问答数据（如 50 条唱歌技巧问答），转换为 JSON 格式（一行一个 JSON 对象）</li><li>将问题和答案拼接，通过代码直接定义数据集（数据量少时更直观）</li></ul><h3 id="_4-拆分数据集" tabindex="-1"><a class="header-anchor" href="#_4-拆分数据集"><span>4. 拆分数据集</span></a></h3><p>按比例拆分为训练集和测试集（如 50 条 → 45 条训练 + 5 条测试），避免模型死记硬背，确保真正理解知识。</p><h3 id="_5-tokenizer-处理" tabindex="-1"><a class="header-anchor" href="#_5-tokenizer-处理"><span>5. Tokenizer 处理</span></a></h3><ul><li>拼接问题和答案为一句话</li><li>进行 tokenize 分词，设置 <code>max_length</code> 对数据进行截断或补齐，统一数据长度以便 GPU 处理</li></ul><h3 id="_6-量化设置" tabindex="-1"><a class="header-anchor" href="#_6-量化设置"><span>6. 量化设置</span></a></h3><p>通过代码对模型进行量化（如 8bit 量化），压缩模型体积一半以上，显著降低显存占用。牺牲少量精度，但不影响整体效果。</p><h3 id="_7-lora-设置" tabindex="-1"><a class="header-anchor" href="#_7-lora-设置"><span>7. LoRA 设置</span></a></h3><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><strong>r</strong>（秩）</td><td>决定 Adapter 参数容量，值越大学习能力越强但显存越高，轻量级微调设为 8 或 16 性价比高</td></tr><tr><td><strong>alpha</strong>（缩放因子）</td><td>通常设为 r 的两倍，控制微调对原模型的影响程度</td></tr><tr><td><strong>task_type</strong></td><td>指定为语言模型对话生成</td></tr></tbody></table><p>设置后仅训练约 <strong>0.06%</strong> 的参数，其余参数冻结。</p><h3 id="_8-训练参数配置与执行" tabindex="-1"><a class="header-anchor" href="#_8-训练参数配置与执行"><span>8. 训练参数配置与执行</span></a></h3><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td><code>output_dir</code></td><td>训练成果保存路径</td></tr><tr><td><code>num_train_epochs</code></td><td>训练轮次，数据量少需多轮，数据量大则 1～3 轮即可</td></tr><tr><td><code>per_device_train_batch_size</code></td><td>每次送入显卡的数据条数，显存溢出时可减小为 2 或 1</td></tr><tr><td><code>fp16</code></td><td>开启半精度训练，显存占用砍半，训练速度翻倍</td></tr></tbody></table><p>配置完成后执行训练，关键输出文件为 <code>adapter_model.safetensors</code>（Adapter 参数）和 <code>adapter_config.json</code>（配置说明）。</p><h2 id="四、微调技能的价值与应用" tabindex="-1"><a class="header-anchor" href="#四、微调技能的价值与应用"><span>四、微调技能的价值与应用</span></a></h2><p>微调的核心价值在于<strong>举一反三</strong>，可根据不同数据将模型打造成特定领域专家：</p><ul><li>替换为公司产品手册 → 金牌客服</li><li>替换为法律条文 → 法律顾问</li><li>替换为 Python 代码库 → 编程助手</li></ul><p>2026 年，会调用 API 的人众多，而能根据业务需求完成模型微调的人才是行业稀缺资源。掌握从数据清洗到模型微调的全流程，是 AI 工程师的基本功。</p>',38)]))}]]),r=JSON.parse('{"path":"/zh/posts/daily/fine_tunning.html","title":"Fine Tuning 微调与 LoRA","lang":"zh-CN","frontmatter":{"icon":"pen-to-square","date":"2026-02-01T00:00:00.000Z","category":["Learning Records"],"tag":["Notes"],"description":"Fine Tuning 微调与 LoRA 一、微调与 LoRA 的底层逻辑 什么是微调 可以将预训练模型比作刚毕业的全能本科生，具备广泛知识但缺乏行业特定业务能力。微调就是通过行业数据训练，使其从通才转变为懂业务的专才，让模型掌握公司业务或行业黑话。 LoRA 的原理 LoRA（Low-Rank Adaptation）的核心逻辑是：冻结原模型参数，不修...","head":[["meta",{"property":"og:url","content":"https://crc011220.github.io/zh/posts/daily/fine_tunning.html"}],["meta",{"property":"og:site_name","content":"Ruochen Chen"}],["meta",{"property":"og:title","content":"Fine Tuning 微调与 LoRA"}],["meta",{"property":"og:description","content":"Fine Tuning 微调与 LoRA 一、微调与 LoRA 的底层逻辑 什么是微调 可以将预训练模型比作刚毕业的全能本科生，具备广泛知识但缺乏行业特定业务能力。微调就是通过行业数据训练，使其从通才转变为懂业务的专才，让模型掌握公司业务或行业黑话。 LoRA 的原理 LoRA（Low-Rank Adaptation）的核心逻辑是：冻结原模型参数，不修..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-02-08T02:58:44.000Z"}],["meta",{"property":"article:tag","content":"Notes"}],["meta",{"property":"article:published_time","content":"2026-02-01T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2026-02-08T02:58:44.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Fine Tuning 微调与 LoRA\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2026-02-01T00:00:00.000Z\\",\\"dateModified\\":\\"2026-02-08T02:58:44.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Ruochen Chen\\"}]}"]]},"headers":[{"level":2,"title":"一、微调与 LoRA 的底层逻辑","slug":"一、微调与-lora-的底层逻辑","link":"#一、微调与-lora-的底层逻辑","children":[{"level":3,"title":"什么是微调","slug":"什么是微调","link":"#什么是微调","children":[]},{"level":3,"title":"LoRA 的原理","slug":"lora-的原理","link":"#lora-的原理","children":[]},{"level":3,"title":"LoRA 的三大优势","slug":"lora-的三大优势","link":"#lora-的三大优势","children":[]}]},{"level":2,"title":"二、环境准备","slug":"二、环境准备","link":"#二、环境准备","children":[{"level":3,"title":"使用 ModelScope 免费云端算力","slug":"使用-modelscope-免费云端算力","link":"#使用-modelscope-免费云端算力","children":[]},{"level":3,"title":"核心依赖库安装","slug":"核心依赖库安装","link":"#核心依赖库安装","children":[]}]},{"level":2,"title":"三、代码实战步骤","slug":"三、代码实战步骤","link":"#三、代码实战步骤","children":[{"level":3,"title":"1. 工作区整理","slug":"_1-工作区整理","link":"#_1-工作区整理","children":[]},{"level":3,"title":"2. 加载模型并测试","slug":"_2-加载模型并测试","link":"#_2-加载模型并测试","children":[]},{"level":3,"title":"3. 制作数据集","slug":"_3-制作数据集","link":"#_3-制作数据集","children":[]},{"level":3,"title":"4. 拆分数据集","slug":"_4-拆分数据集","link":"#_4-拆分数据集","children":[]},{"level":3,"title":"5. Tokenizer 处理","slug":"_5-tokenizer-处理","link":"#_5-tokenizer-处理","children":[]},{"level":3,"title":"6. 量化设置","slug":"_6-量化设置","link":"#_6-量化设置","children":[]},{"level":3,"title":"7. LoRA 设置","slug":"_7-lora-设置","link":"#_7-lora-设置","children":[]},{"level":3,"title":"8. 训练参数配置与执行","slug":"_8-训练参数配置与执行","link":"#_8-训练参数配置与执行","children":[]}]},{"level":2,"title":"四、微调技能的价值与应用","slug":"四、微调技能的价值与应用","link":"#四、微调技能的价值与应用","children":[]}],"git":{"createdTime":1770434182000,"updatedTime":1770519524000,"contributors":[{"name":"Ruochen Chen","email":"ruocchen1220@gmail.com","commits":2}]},"readingTime":{"minutes":3.95,"words":1184},"filePathRelative":"zh/posts/daily/fine_tunning.md","localizedDate":"2026年2月1日","excerpt":"\\n<h2>一、微调与 LoRA 的底层逻辑</h2>\\n<h3>什么是微调</h3>\\n<p>可以将预训练模型比作刚毕业的全能本科生，具备广泛知识但缺乏行业特定业务能力。<strong>微调</strong>就是通过行业数据训练，使其从通才转变为懂业务的专才，让模型掌握公司业务或行业黑话。</p>\\n<h3>LoRA 的原理</h3>\\n<p><strong>LoRA</strong>（Low-Rank Adaptation）的核心逻辑是：冻结原模型参数，不修改模型「大脑」，而是在模型层间插入可训练的低秩矩阵（Adapter 适配器参数）。如同给教科书贴便利贴，新增知识写在便利贴上，模型推理时同时参考原模型和新增参数。</p>","autoDesc":true}')}}]);