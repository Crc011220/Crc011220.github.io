"use strict";(self.webpackChunkpersonalweb=self.webpackChunkpersonalweb||[]).push([[2091],{6262:(i,s)=>{s.A=(i,s)=>{const a=i.__vccOpts||i;for(const[i,e]of s)a[i]=e;return a}},8148:(i,s,a)=>{a.r(s),a.d(s,{comp:()=>n,data:()=>l});var e=a(641);const t={},n=(0,a(6262).A)(t,[["render",function(i,s){return(0,e.uX)(),(0,e.CE)("div",null,s[0]||(s[0]=[(0,e.Fv)('<h1 id="ai-api-framework-for-java" tabindex="-1"><a class="header-anchor" href="#ai-api-framework-for-java"><span>AI API framework for Java</span></a></h1><h2 id="spring-ai-vs-langchain4j" tabindex="-1"><a class="header-anchor" href="#spring-ai-vs-langchain4j"><span>Spring AI vs. Langchain4J</span></a></h2><table><thead><tr><th>Dimension</th><th>Spring AI</th><th>LangChain4j</th></tr></thead><tbody><tr><td>Technology Stack Binding</td><td>Strongly dependent on the Spring ecosystem</td><td>No framework dependency, can be used independently</td></tr><tr><td>Applicable Scenarios</td><td>Rapid integration of Spring Boot applications with single models</td><td>Multi-model (dynamic model) platforms</td></tr></tbody></table><h2 id="langchain4j" tabindex="-1"><a class="header-anchor" href="#langchain4j"><span>Langchain4J</span></a></h2><h3 id="functional-call" tabindex="-1"><a class="header-anchor" href="#functional-call"><span>Functional Call</span></a></h3><ul><li>For example:</li></ul><ol><li>加入回调方法：</li></ol><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">@</span><span style="--shiki-light:#A626A4;--shiki-dark:#E5C07B;">Service</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">public</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> class</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> ToolsService</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    @</span><span style="--shiki-light:#A626A4;--shiki-dark:#E5C07B;">Tool</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;How many names are there in Melbourne?&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">)</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    public</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> Integer</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> changshaNameCount</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        @</span><span style="--shiki-light:#A626A4;--shiki-dark:#E5C07B;">P</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;name&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">) </span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#383A42;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;"> name</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span></span>\n<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">        System</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">out</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">println</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(name);</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">        return</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    }</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>ToolsService is configured as a bean</li><li>@Tool is used to tell AI which dialogue calls this method</li><li>@P(&quot;name&quot;) is used to tell AI what information needs to be extracted from the dialogue when calling the method, here the name is extracted</li></ul><ol start="2"><li>Combine with the configuration of tools through AiService, here using the Assistant configured in the previous dialogue memory</li></ol><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">public</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> interface</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> Assistant</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> {</span></span>\n<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">    String</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> chat</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#383A42;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;"> message</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> // 流式响应</span></span>\n<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">    TokenStream</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> stream</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">String</span><span style="--shiki-light:#383A42;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;"> message</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">@</span><span style="--shiki-light:#A626A4;--shiki-dark:#E5C07B;">Bean</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">public</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> Assistant</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> assistant</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">(</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">ChatLanguageModel</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> qwenChatModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">                           StreamingChatLanguageModel</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> qwenStreamingChatModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>\n<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">                           ToolsService</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> toolsService) {</span></span>\n<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">    ChatMemory</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> chatMemory </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> MessageWindowChatMemory</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">withMaxMessages</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span>\n<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">    Assistant</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> assistant </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> AiServices</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">builder</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">Assistant</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">class</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">chatLanguageModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(qwenChatModel)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">streamingChatLanguageModel</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(qwenStreamingChatModel)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">tools</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(toolsService)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">chatMemory</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(chatMemory)</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        .</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">build</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">();</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> assistant</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>if more tool is needed, just add more @Tool annotation to the ToolsService</li></ul><h3 id="rag-retrieval-augment-generation" tabindex="-1"><a class="header-anchor" href="#rag-retrieval-augment-generation"><span>RAG (Retrieval-Augment-Generation)</span></a></h3><ul><li>Function call and system message can improve the user experience.</li><li>But if huge amount of data is involved, RAG can provide a more comprehensive and accurate response.</li></ul><h3 id="vector-database-and-embedding" tabindex="-1"><a class="header-anchor" href="#vector-database-and-embedding"><span>Vector Database and Embedding</span></a></h3><ul><li>Vectors are usually used for similarity search, such as semantic one-dimensional vectors, which can represent the semantic similarity of words or phrases. For example, &quot;hello&quot; and &quot;nice to meet you&quot; can be represented by a one-dimensional vector to indicate their semantic closeness.</li><li>However, for more complex objects, such as dogs, similarity search cannot be done through a single dimension. In this case, we need to extract multiple features, such as color, size, breed, etc., and represent each feature as a dimension of the vector, thus forming a multi-dimensional vector. For example, a brown small Teddy dog can be represented by a multi-dimensional vector [brown, small, Teddy dog].</li><li>If more accurate retrieval is needed, we definitely need more dimensions of vectors, forming a space of more dimensions. In a multi-dimensional vector space, similarity retrieval becomes more complex. We need to use some algorithms, such as cosine similarity or Euclidean distance, to calculate the similarity between vectors. The vector database will help me achieve this.</li><li>In Langchain4j, Embedding Store represents the vector database, which stores the vectors of words or phrases. <a href="https://docs.langchain4j.dev/integrations/embedding-stores/" target="_blank" rel="noopener noreferrer">Comparison table of all supported Embedding Stores</a></li></ul><h4 id="document-parser" tabindex="-1"><a class="header-anchor" href="#document-parser"><span>Document Parser</span></a></h4><p>If you want to develop a knowledge base system, these materials may be in various files, such as word, txt, pdf, image, html, etc., so langchain4j also provides different document parsers:</p><ul><li>TextDocumentParser from the langchain4j module&#39;s TextDocumentParser, it can parse files in plain text format (e.g. TXT, HTML, MD, etc.).</li><li>ApachePdfBoxDocumentParser from langchain4j-document-parser-apache-pdfbox, it can parse PDF files.</li><li>ApachePoiDocumentParser from langchain4j-document-parser-apache-poi, can parse MS Office file formats (e.g. DOC, DOCX, PPT, PPTX, XLS, XLSX, etc.).</li><li>ApacheTikaDocumentParser from the langchain4j-document-parser-apache-tika module, can automatically detect and parse almost all existing file formats.</li><li>For example, if I want to read a txt:</li></ul><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">Path</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> documentPath </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> Paths</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">get</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">VectorTest</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">class</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">getClassLoader</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">().</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">getResource</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;example.txt&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">).</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">toURI</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">());</span></span>\n<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">DocumentParser</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> documentParser </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;"> new</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> TextDocumentParser</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">()</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">;</span></span>\n<span class="line"><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;">Document</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;"> document </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> FileSystemDocumentLoader</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">loadDocument</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(documentPath, documentParser);</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="document-splitter" tabindex="-1"><a class="header-anchor" href="#document-splitter"><span>Document Splitter</span></a></h4><p>Since the text is read and then needs to be divided into one segment at a time (chunk), chunking is for better semantic unit splitting, so that more accurate semantic similarity searches can be performed later, and LLM&#39;s token limit can be avoided. langchain4j also provides different document splitters:</p><table><thead><tr><th>Driver Type</th><th>Matching Ability</th><th>Applicable Scenario</th></tr></thead><tbody><tr><td>DocumentByCharacterSplitter</td><td>No delimiter splitting</td><td>Strictly split by character count (not recommended, may cause sentence breaks)</td></tr><tr><td>DocumentByRegexSplitter</td><td>Regular expression splitting</td><td>Split by custom regular expression</td></tr><tr><td>DocumentByParagraphSplitter</td><td>Remove large blank content</td><td>Process consecutive line breaks (such as paragraph separation) (\\s*\\R?\\s*)</td></tr><tr><td>DocumentByLineSplitter</td><td>Remove single line break surrounding whitespace, replace with a single line break</td><td>(\\s*\\R\\s*) Example: <br> Input text: &quot;This is line one.\\n\\tThis is line two.&quot; <br> Using \\s*\\R\\s* to replace with a single line break: &quot;This is line one.\\nThis is line two.&quot;</td></tr><tr><td>DocumentByWordSplitter</td><td>Remove consecutive blank characters.</td><td>\\s+ Example: <br> Input text: &quot;Hello World&quot; <br> Using \\s+ to replace with a single space: &quot;Hello World&quot;</td></tr><tr><td>DocumentBySentenceSplitter</td><td>Split by sentence</td><td>A class from the Apache OpenNLP library, used to detect sentence boundaries in text. It can recognize punctuation marks (such as periods, question marks, exclamation marks, etc.) whether they mark the end of a sentence, thereby dividing a longer text string into multiple sentences.</td></tr></tbody></table>',23)]))}]]),l=JSON.parse('{"path":"/posts/ai/javaai.html","title":"AI API framework for Java","lang":"en-US","frontmatter":{"icon":"pen-to-square","date":"2025-04-08T00:00:00.000Z","category":["Learning Records"],"tag":["AI"],"description":"AI API framework for Java Spring AI vs. Langchain4J Langchain4J Functional Call For example: 加入回调方法： ToolsService is configured as a bean @Tool is used to tell AI which dialogue...","head":[["meta",{"property":"og:url","content":"https://crc011220.github.io/posts/ai/javaai.html"}],["meta",{"property":"og:site_name","content":"Richard Chen"}],["meta",{"property":"og:title","content":"AI API framework for Java"}],["meta",{"property":"og:description","content":"AI API framework for Java Spring AI vs. Langchain4J Langchain4J Functional Call For example: 加入回调方法： ToolsService is configured as a bean @Tool is used to tell AI which dialogue..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2025-04-21T00:31:33.000Z"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:published_time","content":"2025-04-08T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-04-21T00:31:33.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"AI API framework for Java\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-04-08T00:00:00.000Z\\",\\"dateModified\\":\\"2025-04-21T00:31:33.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Richard Chen\\"}]}"]]},"headers":[{"level":2,"title":"Spring AI vs. Langchain4J","slug":"spring-ai-vs-langchain4j","link":"#spring-ai-vs-langchain4j","children":[]},{"level":2,"title":"Langchain4J","slug":"langchain4j","link":"#langchain4j","children":[{"level":3,"title":"Functional Call","slug":"functional-call","link":"#functional-call","children":[]},{"level":3,"title":"RAG (Retrieval-Augment-Generation)","slug":"rag-retrieval-augment-generation","link":"#rag-retrieval-augment-generation","children":[]},{"level":3,"title":"Vector Database and Embedding","slug":"vector-database-and-embedding","link":"#vector-database-and-embedding","children":[]}]}],"git":{"createdTime":1744793783000,"updatedTime":1745195493000,"contributors":[{"name":"Ruochen Chen","email":"ruocchen1220@gmail.com","commits":2}]},"readingTime":{"minutes":2.65,"words":795},"filePathRelative":"posts/ai/javaai.md","localizedDate":"April 8, 2025","excerpt":"\\n<h2>Spring AI vs. Langchain4J</h2>\\n<table>\\n<thead>\\n<tr>\\n<th>Dimension</th>\\n<th>Spring AI</th>\\n<th>LangChain4j</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td>Technology Stack Binding</td>\\n<td>Strongly dependent on the Spring ecosystem</td>\\n<td>No framework dependency, can be used independently</td>\\n</tr>\\n<tr>\\n<td>Applicable Scenarios</td>\\n<td>Rapid integration of Spring Boot applications with single models</td>\\n<td>Multi-model (dynamic model) platforms</td>\\n</tr>\\n</tbody>\\n</table>","autoDesc":true}')}}]);