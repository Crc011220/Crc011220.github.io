"use strict";(self.webpackChunkpersonalweb=self.webpackChunkpersonalweb||[]).push([[6557],{4697:(e,a,s)=>{s.r(a),s.d(a,{comp:()=>o,data:()=>n});var i=s(641);const t={},o=(0,s(6262).A)(t,[["render",function(e,a){return(0,i.uX)(),(0,i.CE)("div",null,a[0]||(a[0]=[(0,i.Fv)('<h1 id="message-queue" tabindex="-1"><a class="header-anchor" href="#message-queue"><span>Message Queue</span></a></h1><h2 id="_1-how-does-rabbitmq-ensure-message-delivery-without-loss" tabindex="-1"><a class="header-anchor" href="#_1-how-does-rabbitmq-ensure-message-delivery-without-loss"><span>1. <strong>How does RabbitMQ ensure message delivery without loss?</strong></span></a></h2><ul><li><strong>Answer</strong>: We use RabbitMQ to ensure data dual-write consistency between MySQL and Redis, which requires us to implement high availability for messages. Specific measures include: <ol><li>Enable producer acknowledgment to ensure messages are delivered to the queue; if there is an error, log it and fix the data.</li><li>Enable persistence to ensure messages are not lost in the queue before consumption; persistence needs to be applied to the exchange, queue, and the message itself.</li><li>Enable automatic acknowledgment for consumers and set retry counts. For example, we set 3 retries; if it fails, the message is sent to an exception exchange for manual processing.</li></ol></li></ul><h2 id="_2-how-to-solve-the-problem-of-duplicate-message-consumption-in-rabbitmq" tabindex="-1"><a class="header-anchor" href="#_2-how-to-solve-the-problem-of-duplicate-message-consumption-in-rabbitmq"><span>2. <strong>How to solve the problem of duplicate message consumption in RabbitMQ?</strong></span></a></h2><ul><li><strong>Answer</strong>: We have encountered the issue of duplicate message consumption, and the solution is: <ul><li>Set the consumer to automatic acknowledgment mode. If the service crashes before acknowledgment, it may consume the same message again after restarting.</li><li>Check the existence of data in the database using a unique business identifier. If it does not exist, process the message; if it exists, ignore it to avoid duplicate consumption.</li></ul></li></ul><h2 id="_3-do-you-know-any-other-solutions" tabindex="-1"><a class="header-anchor" href="#_3-do-you-know-any-other-solutions"><span>3. <strong>Do you know any other solutions?</strong></span></a></h2><ul><li><strong>Answer</strong>: Yes, this is an idempotency issue, which can be solved by: <ul><li>Using Redis distributed locks or database locks to ensure the idempotency of operations.</li></ul></li></ul><h2 id="_4-are-you-familiar-with-dead-letter-exchanges-in-rabbitmq-have-you-heard-of-rabbitmq-delayed-queues" tabindex="-1"><a class="header-anchor" href="#_4-are-you-familiar-with-dead-letter-exchanges-in-rabbitmq-have-you-heard-of-rabbitmq-delayed-queues"><span>4. <strong>Are you familiar with dead letter exchanges in RabbitMQ? (Have you heard of RabbitMQ delayed queues?)</strong></span></a></h2><ul><li><strong>Answer</strong>: Yes, we use RabbitMQ to implement delayed queues in our project, mainly through dead letter exchanges and TTL (Time-To-Live) to achieve this. <ul><li>If a message times out and is not consumed, it becomes a dead letter, and the queue can bind to a dead letter exchange to implement the delay function.</li><li>Another method is to install the RabbitMQ dead letter plugin to simplify configuration, specifying it as a dead letter exchange when declaring the exchange and setting the message timeout.</li></ul></li></ul><h2 id="_5-if-there-are-1-million-messages-piled-up-in-the-mq-how-to-solve-it" tabindex="-1"><a class="header-anchor" href="#_5-if-there-are-1-million-messages-piled-up-in-the-mq-how-to-solve-it"><span>5. <strong>If there are 1 million messages piled up in the MQ, how to solve it?</strong></span></a></h2><ul><li><strong>Answer</strong>: If there is message accumulation, the following measures can be taken: <ol><li>Increase the consumption capacity of consumers, such as using multithreading.</li><li>Increase the number of consumers, adopting a work queue model to allow multiple consumers to consume the same queue in parallel.</li><li>Expand the queue capacity by using RabbitMQ&#39;s lazy queues, which support storing millions of messages directly on disk rather than in memory.</li></ol></li></ul><h2 id="_6-are-you-familiar-with-rabbitmq-s-high-availability-mechanism" tabindex="-1"><a class="header-anchor" href="#_6-are-you-familiar-with-rabbitmq-s-high-availability-mechanism"><span>6. <strong>Are you familiar with RabbitMQ&#39;s high availability mechanism?</strong></span></a></h2><ul><li><strong>Answer</strong>: Our project uses a RabbitMQ cluster in the production environment, adopting a mirrored queue model with a one-master, multiple-slave structure. <ul><li>The master node handles all operations and synchronizes to the slave nodes. If the master node crashes, a slave node can take over as the master, but care must be taken to ensure data synchronization integrity.</li></ul></li></ul><h2 id="_7-how-to-solve-data-loss-issues" tabindex="-1"><a class="header-anchor" href="#_7-how-to-solve-data-loss-issues"><span>7. <strong>How to solve data loss issues?</strong></span></a></h2><ul><li><strong>Answer</strong>: Use an arbitration queue in a master-slave mode, implementing strong consistency data synchronization based on the Raft protocol to simplify configuration and enhance data security.</li></ul><h2 id="_8-how-does-kafka-ensure-messages-are-not-lost" tabindex="-1"><a class="header-anchor" href="#_8-how-does-kafka-ensure-messages-are-not-lost"><span>8. <strong>How does Kafka ensure messages are not lost?</strong></span></a></h2><ul><li><strong>Answer</strong>: Kafka ensures messages are not lost through the following measures: <ol><li>Producers send messages using asynchronous callbacks and set retry mechanisms to handle network issues.</li><li>In the Broker, through replication mechanisms, set the acks parameter to all to ensure messages are confirmed in all replicas.</li><li>Consumers manually commit the offsets of successfully consumed messages to avoid data loss or duplicate consumption that may occur with automatic commits.</li></ol></li></ul><h2 id="_9-how-to-solve-the-problem-of-duplicate-message-consumption-in-kafka" tabindex="-1"><a class="header-anchor" href="#_9-how-to-solve-the-problem-of-duplicate-message-consumption-in-kafka"><span>9. <strong>How to solve the problem of duplicate message consumption in Kafka?</strong></span></a></h2><ul><li><strong>Answer</strong>: The following methods can solve the problem of duplicate consumption in Kafka: <ul><li>Disable automatic offset commits and manually control the timing of offset commits.</li><li>Ensure the idempotency of message consumption, for example, by using a unique primary key or distributed locks.</li></ul></li></ul><h2 id="_10-how-does-kafka-ensure-message-order" tabindex="-1"><a class="header-anchor" href="#_10-how-does-kafka-ensure-message-order"><span>10. <strong>How does Kafka ensure message order?</strong></span></a></h2><ul><li><strong>Answer</strong>: Kafka does not guarantee message order by default, but it can be achieved through the following methods: <ul><li>Store messages in the same partition by specifying the partition number or using the same business key.</li></ul></li></ul><h2 id="_11-are-you-familiar-with-kafka-s-high-availability-mechanism" tabindex="-1"><a class="header-anchor" href="#_11-are-you-familiar-with-kafka-s-high-availability-mechanism"><span>11. <strong>Are you familiar with Kafka&#39;s high availability mechanism?</strong></span></a></h2><ul><li><strong>Answer</strong>: Kafka&#39;s high availability is mainly achieved through the following mechanisms: <ul><li>Cluster deployment with multiple broker instances, ensuring that single points of failure do not affect overall service.</li><li>Replication mechanisms, where each partition has multiple replicas, with a leader and followers. If the leader fails, a new leader is elected from the followers.</li></ul></li></ul><h2 id="_12-can-you-explain-the-isr-in-the-replication-mechanism" tabindex="-1"><a class="header-anchor" href="#_12-can-you-explain-the-isr-in-the-replication-mechanism"><span>12. <strong>Can you explain the ISR in the replication mechanism?</strong></span></a></h2><ul><li><strong>Answer</strong>: ISR (In-Sync Replicas) refers to the followers that are in sync with the leader. <ul><li>When the leader fails, a new leader is elected from the ISR first, as they have higher data consistency.</li></ul></li></ul><h2 id="_13-are-you-familiar-with-kafka-s-data-cleanup-mechanism" tabindex="-1"><a class="header-anchor" href="#_13-are-you-familiar-with-kafka-s-data-cleanup-mechanism"><span>13. <strong>Are you familiar with Kafka&#39;s data cleanup mechanism?</strong></span></a></h2><ul><li><strong>Answer</strong>: Kafka&#39;s data cleanup includes: <ul><li>Cleanup based on message retention time.</li><li>Cleanup based on topic data size, allowing for the configuration of the deletion of the oldest messages.</li></ul></li></ul><h2 id="_14-do-you-know-about-high-performance-design-in-kafka" tabindex="-1"><a class="header-anchor" href="#_14-do-you-know-about-high-performance-design-in-kafka"><span>14. <strong>Do you know about high-performance design in Kafka?</strong></span></a></h2><ul><li><strong>Answer</strong>: High-performance design in Kafka includes: <ul><li>Message partitioning to enhance data processing capabilities.</li><li>Sequential read and write to improve disk operation efficiency.</li><li>Page caching to reduce disk access.</li><li>Zero-copy to minimize data copying and context switching.</li><li>Message compression to reduce IO load.</li><li>Batching messages to lower network overhead.</li></ul></li></ul>',29)]))}]]),n=JSON.parse('{"path":"/posts/interview/5.html","title":"Message Queue","lang":"en-US","frontmatter":{"icon":"pen-to-square","date":"2024-11-21T00:00:00.000Z","category":["Learning Records"],"tag":["Technical Interview"],"description":"Message Queue 1. How does RabbitMQ ensure message delivery without loss? Answer: We use RabbitMQ to ensure data dual-write consistency between MySQL and Redis, which requires us...","head":[["meta",{"property":"og:url","content":"https://crc011220.github.io/personalweb/personalweb/posts/interview/5.html"}],["meta",{"property":"og:site_name","content":"Richard Chen"}],["meta",{"property":"og:title","content":"Message Queue"}],["meta",{"property":"og:description","content":"Message Queue 1. How does RabbitMQ ensure message delivery without loss? Answer: We use RabbitMQ to ensure data dual-write consistency between MySQL and Redis, which requires us..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2024-11-21T12:08:12.000Z"}],["meta",{"property":"article:tag","content":"Technical Interview"}],["meta",{"property":"article:published_time","content":"2024-11-21T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-11-21T12:08:12.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Message Queue\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-11-21T00:00:00.000Z\\",\\"dateModified\\":\\"2024-11-21T12:08:12.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Richard Chen\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"1. How does RabbitMQ ensure message delivery without loss?","slug":"_1-how-does-rabbitmq-ensure-message-delivery-without-loss","link":"#_1-how-does-rabbitmq-ensure-message-delivery-without-loss","children":[]},{"level":2,"title":"2. How to solve the problem of duplicate message consumption in RabbitMQ?","slug":"_2-how-to-solve-the-problem-of-duplicate-message-consumption-in-rabbitmq","link":"#_2-how-to-solve-the-problem-of-duplicate-message-consumption-in-rabbitmq","children":[]},{"level":2,"title":"3. Do you know any other solutions?","slug":"_3-do-you-know-any-other-solutions","link":"#_3-do-you-know-any-other-solutions","children":[]},{"level":2,"title":"4. Are you familiar with dead letter exchanges in RabbitMQ? (Have you heard of RabbitMQ delayed queues?)","slug":"_4-are-you-familiar-with-dead-letter-exchanges-in-rabbitmq-have-you-heard-of-rabbitmq-delayed-queues","link":"#_4-are-you-familiar-with-dead-letter-exchanges-in-rabbitmq-have-you-heard-of-rabbitmq-delayed-queues","children":[]},{"level":2,"title":"5. If there are 1 million messages piled up in the MQ, how to solve it?","slug":"_5-if-there-are-1-million-messages-piled-up-in-the-mq-how-to-solve-it","link":"#_5-if-there-are-1-million-messages-piled-up-in-the-mq-how-to-solve-it","children":[]},{"level":2,"title":"6. Are you familiar with RabbitMQ\'s high availability mechanism?","slug":"_6-are-you-familiar-with-rabbitmq-s-high-availability-mechanism","link":"#_6-are-you-familiar-with-rabbitmq-s-high-availability-mechanism","children":[]},{"level":2,"title":"7. How to solve data loss issues?","slug":"_7-how-to-solve-data-loss-issues","link":"#_7-how-to-solve-data-loss-issues","children":[]},{"level":2,"title":"8. How does Kafka ensure messages are not lost?","slug":"_8-how-does-kafka-ensure-messages-are-not-lost","link":"#_8-how-does-kafka-ensure-messages-are-not-lost","children":[]},{"level":2,"title":"9. How to solve the problem of duplicate message consumption in Kafka?","slug":"_9-how-to-solve-the-problem-of-duplicate-message-consumption-in-kafka","link":"#_9-how-to-solve-the-problem-of-duplicate-message-consumption-in-kafka","children":[]},{"level":2,"title":"10. How does Kafka ensure message order?","slug":"_10-how-does-kafka-ensure-message-order","link":"#_10-how-does-kafka-ensure-message-order","children":[]},{"level":2,"title":"11. Are you familiar with Kafka\'s high availability mechanism?","slug":"_11-are-you-familiar-with-kafka-s-high-availability-mechanism","link":"#_11-are-you-familiar-with-kafka-s-high-availability-mechanism","children":[]},{"level":2,"title":"12. Can you explain the ISR in the replication mechanism?","slug":"_12-can-you-explain-the-isr-in-the-replication-mechanism","link":"#_12-can-you-explain-the-isr-in-the-replication-mechanism","children":[]},{"level":2,"title":"13. Are you familiar with Kafka\'s data cleanup mechanism?","slug":"_13-are-you-familiar-with-kafka-s-data-cleanup-mechanism","link":"#_13-are-you-familiar-with-kafka-s-data-cleanup-mechanism","children":[]},{"level":2,"title":"14. Do you know about high-performance design in Kafka?","slug":"_14-do-you-know-about-high-performance-design-in-kafka","link":"#_14-do-you-know-about-high-performance-design-in-kafka","children":[]}],"git":{"createdTime":1732190892000,"updatedTime":1732190892000,"contributors":[{"name":"Ruochen Chen","email":"ruocchen1220@gmail.com","commits":1}]},"readingTime":{"minutes":3.04,"words":912},"filePathRelative":"posts/interview/5.md","localizedDate":"November 21, 2024","excerpt":"\\n<h2>1. <strong>How does RabbitMQ ensure message delivery without loss?</strong></h2>\\n<ul>\\n<li><strong>Answer</strong>: We use RabbitMQ to ensure data dual-write consistency between MySQL and Redis, which requires us to implement high availability for messages. Specific measures include:\\n<ol>\\n<li>Enable producer acknowledgment to ensure messages are delivered to the queue; if there is an error, log it and fix the data.</li>\\n<li>Enable persistence to ensure messages are not lost in the queue before consumption; persistence needs to be applied to the exchange, queue, and the message itself.</li>\\n<li>Enable automatic acknowledgment for consumers and set retry counts. For example, we set 3 retries; if it fails, the message is sent to an exception exchange for manual processing.</li>\\n</ol>\\n</li>\\n</ul>","autoDesc":true}')},6262:(e,a)=>{a.A=(e,a)=>{const s=e.__vccOpts||e;for(const[e,i]of a)s[e]=i;return s}}}]);