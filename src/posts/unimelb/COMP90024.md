---
icon: pen-to-square
date: 2025-03-02
category:
  - Learning Records
tag:
  - Unimelb
---

# Cluster and Cloud Computing (COMP90024)

## Week 1

### Cloud Characteristics
– On-demand self-service . A consumer can provision computing
capabilities as needed without requiring human interaction with
each service provider.
– Networked access . Capabilities are available over the network and
accessed through standard mechanisms that promote use by
heterogeneous client platforms.
- Resource pooling . The provider's computing resources are pooled to
serve multiple consumers using a multi-tenant model potentially
with different physical and virtual resources that can be
dynamically assigned and reassigned according to consumer
demand.
– Rapid elasticity . Capabilities can be elastically provisioned and
released, in some cases automatically, to scale rapidly upon
demand.
– Measured service . Cloud systems automatically control and
optimize resource use by leveraging a metering capability at some
level of abstraction appropriate to the type of service.

### Grid Computing

## Week 2

### Horizontal and Vertical Scaling
- Horizontal scaling refers to adding more resources to a system, easy to add more, cost not so high.
- Vertical scaling refers to increasing the resources of a system, more complex, cost high.


![Amdhal vs. Gustafson's Law](Amdhal_vs_Gustafsons_Law.png)

### Categories of Flynn's Taxonomy

| Type | Full Name | Instruction Stream | Data Stream | Example |
|-------|-----------|---------------------|-------------|---------|
| **SISD** | Single Instruction, Single Data | Single | Single | Traditional single-core CPU |
| **SIMD** | Single Instruction, Multiple Data | Single | Multiple | GPU, vector processors |
| **MISD** | Multiple Instruction, Single Data | Multiple | Single | Fault-tolerant systems (rare) |
| **MIMD** | Multiple Instruction, Multiple Data | Multiple | Multiple | Multi-core CPUs, distributed systems |

---
### Approaches for Parallelism (where and how)
– Explicit (openMP / MPI) vs Implicit parallelism
– Hardware
– Operating System
– Software/Applications
– Some or all of these

:::info
Message Passing Interface (MPI) is a standardized and portable message-passing system designed to function on a wide range of parallel computers.
:::

### Erroneous Assumptions of Distributed Systems
1. The network is reliable
2. Latency is zero
3. Bandwidth is infinite
4. The network is secure
5. Topology doesn't change
6. There is one administrator
7. Transport cost is zero
8. The network is homogeneous
9. Time is ubiquitous