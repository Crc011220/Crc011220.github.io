---
icon: pen-to-square
date: 2025-06-19
category:
  - Learning Records
tag:
  - Unimelb
---

# Machine Learning
| Algorithm                | Type            | Generative/Discriminative | Linear/Non-linear | Notes                                                                 |
|--------------------------|-----------------|---------------------------|-------------------|-----------------------------------------------------------------------|
| Naive Bayes              | Classification  | Generative                | Linear            | Assumes feature independence, uses Bayes' theorem                     |
| Logistic Regression      | Classification  | Discriminative            | Linear            | Uses sigmoid function, mainly for binary classification               |
| Decision Trees           | Classification  | Discriminative            | Non-linear        | Handles both numerical and categorical features                       |
| SVM                      | Classification  | Discriminative            | Linear/Non-linear | Uses kernel trick for non-linear, finds optimal hyperplane            |
| k-NN                     | Classification  | Discriminative            | Non-linear        | Instance-based, sensitive to feature scaling                          |
| Neural Networks          | Classification  | Discriminative            | Non-linear        | Can model complex patterns, requires large datasets                   |
| Linear Regression        | Regression      | Discriminative            | Linear            | Predicts continuous values, sensitive to multicollinearity            |
| k-Means                  | Clustering      | -                         | Linear            | Unsupervised, sensitive to initial centroids and outliers             |
| PCA                      | Dimensionality Reduction | -                  | Linear            | Unsupervised, maximizes variance, does not consider class labels      |
| Hierarchical Clustering  | Clustering      | -                         | Non-linear        | Unsupervised, builds nested clusters, linkage methods affect results  |
| Perceptron               | Classification  | Discriminative            | Linear            | Simple model, only for linearly separable data                        |
| Multi-Layer Perceptron   | Classification/Regression | Discriminative   | Non-linear        | Can solve XOR problem, uses backpropagation for training              |

# Introduction
- An instance is a single exemplar from the data, consisting of a bundle of (possibly unknown) attribute values (feature values) (and, in the case of supervised ML, a class value). ä¸€è¡Œæ•°æ®
- An feature (attribute) is a single measurement of some aspect of an instance, for example, the frequency of some event related to this instance, or the label of some meaningful category. æ¯ä¸ªåˆ—ä¸Šçš„ç‰¹å¾ã€
- label(concepts) refers to the output variable that a machine learning model predicts or classifies. æœ€åä¸€åˆ—çš„æ ‡ç­¾ã€

| é¡¹ç›®       | Supervised Learningï¼ˆç›‘ç£å­¦ä¹ ï¼‰                                                                         | Semi-supervised Learningï¼ˆåŠç›‘ç£å­¦ä¹ ï¼‰                                                        | Unsupervised Learningï¼ˆæ— ç›‘ç£å­¦ä¹ ï¼‰                                                  |
| -------- | ------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------- |
| **å®šä¹‰**   | ä½¿ç”¨å¸¦æ ‡ç­¾çš„æ•°æ®è®­ç»ƒæ¨¡å‹                                                                                      | ä½¿ç”¨å°‘é‡å¸¦æ ‡ç­¾ + å¤§é‡æœªæ ‡è®°æ•°æ®                                                                      | ä½¿ç”¨æœªæ ‡è®°æ•°æ®å‘ç°ç»“æ„æˆ–æ¨¡å¼                                                                |
| **è®­ç»ƒæ•°æ®** | å…¨éƒ¨æ•°æ®éƒ½æœ‰æ ‡ç­¾ (x, y)                                                                                   | éƒ¨åˆ†æ•°æ®æœ‰æ ‡ç­¾ï¼Œå…¶ä½™æ²¡æœ‰                                                                           | æ‰€æœ‰æ•°æ®éƒ½æ²¡æœ‰æ ‡ç­¾                                                                     |
| **ç›®æ ‡**   | å­¦ä¹ ä»è¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„å‡½æ•°                                                                                     | åˆ©ç”¨æœªæ ‡è®°æ•°æ®è¾…åŠ©æå‡ç›‘ç£å­¦ä¹ æ€§èƒ½                                                                      | æŒ–æ˜æ•°æ®çš„éšè—ç»“æ„ã€èšç±»æˆ–é™ç»´                                                               |
| **ä¼˜ç‚¹**   | - æ€§èƒ½å¥½ï¼Œé¢„æµ‹å‡†ç¡®<br>- æ˜“äºè¯„ä¼°                                                                              | - é™ä½æ ‡æ³¨æˆæœ¬<br>- åˆ©ç”¨æ›´å¤šæ•°æ®<br>- ä»‹äºä¸¤è€…ä¹‹é—´                                                       | - æ— éœ€äººå·¥æ ‡æ³¨<br>- å¯å‘ç°æ½œåœ¨ç»“æ„                                                         |
| **ç¼ºç‚¹**   | - éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®<br>- æˆæœ¬é«˜                                                                               | - æ¨¡å‹è¾ƒå¤æ‚ï¼Œéš¾ä»¥è°ƒä¼˜<br>- ä¾èµ–æ ‡ç­¾è´¨é‡                                                               | - æ²¡æœ‰æ˜ç¡®çš„è¯„ä¼°æ ‡å‡†<br>- ç»“æœä¸ä¸€å®šå¯è§£é‡Š                                                     |
| **å¸¸è§ç®—æ³•** | - Logistic Regression<br>- Decision Trees <br>- Naive Bayes<br>- SVM<br>- k-NN<br>- Neural Networks | - Self-Training<br>- Active Learning | - k-Means<br>- PCA<br>- Hierarchical Clustering |
| **åº”ç”¨åœºæ™¯** | - å›¾åƒè¯†åˆ«<br>- æ–‡æœ¬åˆ†ç±»<br>- åŒ»ç–—è¯Šæ–­                                                                        | - åŒ»ç–—å½±åƒåˆ†æï¼ˆæ ‡ç­¾ç¨€ç¼ºï¼‰<br>- ç½‘ç»œå®‰å…¨<br>- å­¦æœ¯æ–‡æœ¬åˆ†ç±»                                                   | - å®¢æˆ·åˆ†ç¾¤<br>- å¼‚å¸¸æ£€æµ‹<br>- æ¨èç³»ç»Ÿé™ç»´                                                  |
| **æ ‡ç­¾ä¾èµ–** | é«˜                                                                                                 | ä¸­ç­‰                                                                                     | æ—                                                                              |
| **å­¦ä¹ ç­–ç•¥** | æ‹Ÿåˆæ ‡ç­¾é¢„æµ‹                                                                                            | ç»“åˆç›‘ç£ä¸æ— ç›‘ç£çš„æ–¹å¼                                                                            | åˆ©ç”¨ç›¸ä¼¼æ€§ã€è·ç¦»ã€å¯†åº¦ç­‰è‡ªç»„ç»‡ç»“æ„                                                             |

| æ•°æ®ç±»å‹/ç®—æ³•                     | Nominalï¼ˆç±»åˆ«ï¼Œæ— é¡ºåºï¼‰    | Ordinalï¼ˆç±»åˆ«ï¼Œæœ‰é¡ºåºï¼‰   | Numericï¼ˆæ•°å€¼å‹ï¼‰ |
| --------------------------- | ------------------ | ----------------- | ------------ |
| **Logistic Regression**     | âŒï¼ˆéœ€ One-Hot ç¼–ç ï¼‰    | âš ï¸ï¼ˆå»ºè®®ç”¨æ•´æ•°ï¼Œä½†å°å¿ƒçº¿æ€§å…³ç³»ï¼‰ | âœ…ï¼ˆå¤©ç„¶æ”¯æŒï¼‰      |
| **Decision Trees**          | âœ…ï¼ˆç›´æ¥æ”¯æŒï¼‰            | âœ…ï¼ˆé¡ºåºå¯å½±å“åˆ’åˆ†ï¼‰        | âœ…ï¼ˆå¤©ç„¶æ”¯æŒï¼‰      |
| **Naive Bayes** | âœ…ï¼ˆéå¸¸é€‚åˆï¼Œå¦‚å¤šé¡¹å¼NBï¼‰  | âš ï¸ï¼ˆå¯å½“ä½œ nominal å¤„ç†ï¼Œä½†æœ‰é¡ºåºä¿¡æ¯æœªè¢«åˆ©ç”¨ï¼‰ | âœ…ï¼ˆéœ€ä½¿ç”¨é«˜æ–¯NBï¼‰   |
| **SVM**                     | âŒï¼ˆéœ€ One-Hot æˆ–æ•°å€¼ç¼–ç ï¼‰ | âš ï¸ï¼ˆå¯è½¬æ•°å€¼ï¼Œä½†å½±å“å¤§ï¼‰     | âœ…            |
| **k-NN**                    | âš ï¸ï¼ˆå¯ç¼–ç ä½†è·ç¦»è®¡ç®—è¦å°å¿ƒï¼‰    | âš ï¸ï¼ˆé¡ºåºå¯ç¼–ç ï¼Œä»éœ€è°¨æ…ï¼‰    | âœ…            |
| **Neural Networks**         | âŒï¼ˆéœ€ç‹¬çƒ­ç¼–ç æˆ–åµŒå…¥ï¼‰        | âš ï¸ï¼ˆç”¨åµŒå…¥æˆ–æ•°å€¼ï¼Œä½†æ³¨æ„è¯¯å¯¼ï¼‰  | âœ…            |
| **k-Means**                 | âŒï¼ˆä¸é€‚åˆéæ•°å€¼æ•°æ®ï¼‰        | âš ï¸ï¼ˆå¯å°è¯•ç¼–ç ï¼Œä½†ä¸æ¨èï¼‰    | âœ…ï¼ˆå¿…é¡»æ˜¯æ•°å€¼å‹ï¼‰    |
| **PCA**                     | âŒï¼ˆä»…é™æ•°å€¼å‹ï¼‰           | âŒï¼ˆä¸å¯ç”¨äºç±»åˆ«ï¼‰         | âœ…ï¼ˆå¿…é¡»æ˜¯æ•°å€¼å‹ï¼‰    |
| **Hierarchical Clustering** | âš ï¸ï¼ˆéœ€è·ç¦»å®šä¹‰ï¼Œç¼–ç åå¯ç”¨ï¼‰    | âš ï¸ï¼ˆé¡ºåºç¼–ç æœ‰æ—¶åˆç†ï¼‰      | âœ…ï¼ˆå¸¸è§ä½¿ç”¨ï¼‰      |
 
## å“ªäº›ç®—æ³•æ•æ„Ÿäºæ•°å€¼èŒƒå›´ï¼Ÿ

âœ… å—å½±å“ï¼šSVM, k-NN, PCA, æ¢¯åº¦ä¸‹é™ç±»æ¨¡å‹ï¼ˆå¦‚é€»è¾‘å›å½’ã€ç¥ç»ç½‘ç»œï¼‰

âŒ ä¸æ•æ„Ÿï¼šå†³ç­–æ ‘ã€éšæœºæ£®æ—ã€æœ´ç´ è´å¶æ–¯

| æ–¹æ³•                | ä¹Ÿå«                        | ä½œç”¨               | æ•°å­¦å½¢å¼                                         |
| ----------------- | ------------------------- | ---------------- | -------------------------------------------- |
| **Scaling**       | Min-Max Scaling           | ç»Ÿä¸€æ•°å€¼èŒƒå›´ï¼ˆä¸æ”¹å˜åˆ†å¸ƒå½¢çŠ¶ï¼‰  | $x' = \frac{x - \min(x)}{\max(x) - \min(x)}$ |
| **Normalization** | Standardization / Z-score | ç»Ÿä¸€åˆ†å¸ƒå½¢çŠ¶ï¼ˆå˜ä¸ºå‡å€¼0æ–¹å·®1ï¼‰ | $x' = \frac{x - \mu}{\sigma}$                |



# KNN
classification and regression
## ç®—æ³•
- Choose k: Decide the number of nearest neighbors (k).
- Compute Distance: Measure the distance between the test instance and all training instances (e.g., Euclidean distance, Manhattan distance, or Cosine similarity).
- Find Nearest Neighbors: Select the k closest training instances.
- Predict the Output:
  - For classification, use majority voting or weighted voting among the k neighbors.
  - For regression, take the average or weighted average of the k neighbors' values.

## è·ç¦»è®¡ç®—
- Majority class voting: é€‰æ‹©å‡ºç°æ¬¡æ•°æœ€å¤šçš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœï¼Œä¸ç®¡è¿œè¿‘weightéƒ½ä¸€æ ·
- inverse distance weighting: æ ¹æ®è·ç¦»çš„å€’æ•°åŠ æƒï¼Œè·ç¦»è¶Šè¿‘æƒé‡è¶Šå¤§ 1/d+Îµ
- Inverse linear distance weighting $$w_j = \frac{d_3 - d_j}{d_3 - d_1}$$
   - d_3 is the distance of the farthest neighbor (Here is 3NN)
   - d_j is the distance of the j-th neighbor ä»–æ˜¯ç¬¬å‡ è¿œçš„é‚£ä¸ªé‚»å±…çš„distance æ¯”å¦‚ç¬¬äºŒè¿œçš„è·ç¦»æ˜¯4 å°±å¡«4
- Cosine similarity: è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„å¤¹è§’ä½™å¼¦å€¼ï¼Œå€¼è¶Šå¤§è¶Šç›¸ä¼¼ 
   - cosine similarity = dot product / (magnitude of x * magnitude of y) $$\cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|}$$
   - magnitude of x = sqrt(x1^2 + x2^2 + ... + xn^2)
   - cosine distance = 1 - cosine similarity
      - high distance means low similarity
## Kçš„é€‰æ‹©
- å¦‚æœkå¤ªå°ï¼Œæ¨¡å‹ä¼šè¿‡æ‹Ÿåˆï¼Œå› ä¸ºæ¨¡å‹ä¼šè¿‡åº¦ä¾èµ–äºæœ€è¿‘çš„é‚»å±…ï¼Œå¯¼è‡´æ¨¡å‹å¯¹å™ªå£°æ•æ„Ÿ
- å¦‚æœkå¤ªå¤§ï¼Œæ¨¡å‹ä¼šæ¬ æ‹Ÿåˆï¼Œå› ä¸ºæ¨¡å‹ä¼šå¿½ç•¥ç‰¹å¾å·®å¼‚ï¼Œå¯¼è‡´æ¨¡å‹å¯¹å™ªå£°ä¸æ•æ„Ÿ
   - å¦‚æœk=Nï¼Œ	å¿½ç•¥ç‰¹å¾å·®å¼‚ï¼Œé€€åŒ–æˆå¤šæ•°ç±»æŠ•ç¥¨æ³•


# Probability
- marginal probability: åªå…³æ³¨æŸä¸€ä¸ªå˜é‡çš„æ¦‚ç‡ï¼Œå¿½ç•¥ï¼ˆè¾¹ç¼˜åŒ–ï¼‰å…¶ä»–å˜é‡ 
- conditional probability: åœ¨ç»™å®šå…¶ä»–å˜é‡çš„æƒ…å†µä¸‹ï¼ŒæŸä¸€ä¸ªå˜é‡çš„æ¦‚ç‡
- joint probability: ä¸¤ä¸ªäº‹ä»¶åŒæ—¶å‘ç”Ÿçš„æ¦‚ç‡
- disjoint events: ä¸¤ä¸ªäº‹ä»¶ä¸èƒ½åŒæ—¶å‘ç”Ÿ
- Bayes' theorem: 
   $$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$
   - P(A|B) is the probability of A given B
   - P(B|A) is the probability of B given A
   - P(A) is the probability of A
   - P(B) is the probability of B

# Decision Trees
classification and regression

handle numerical and categorical features
- 0-R
   - ç›´æ¥é¢„æµ‹æœ€é¢‘ç¹çš„ç±»
- 1-R(decision stump)
   - é€‰æ‹©æœ€å°‘çš„error countçš„feature, ç„¶åæ ¹æ®é€‰æ‹©çš„featureè¿›è¡Œé¢„æµ‹
- Information Gain (for classification)ï¼šchoose the attribute that has th largest difference between the entropy of the class distribution at the parent node, and the average entropy across its daughter nodes (weighted by the fraction of instances at each node)

$$
IG(A|R) = H(R) - \sum_{i \in A} P(A = i) H(A = i)
$$


$$
IG(O) = H(R) - MI(O)
$$

   - In this dataset, we have **6 instances total**â€”**3 Y** and **3 N**. The entropy at the **top level** of our tree is:

$$
H(R) = - \left[ \frac{3}{6} \log_2 \frac{3}{6} + \frac{3}{6} \log_2 \frac{3}{6} \right]
$$

   - average entropyï¼ˆä¹Ÿå°±æ˜¯MI Mean Informationï¼‰: sum the calculated entropy at each daughter multiplied by the fraction of instances at that daughter
   - æœ€ç»ˆé€‰æ‹©æœ€é«˜çš„IGçš„featureè¿›è¡Œsplitï¼Œpureçš„nodeå°±ç›´æ¥åœï¼Œå¦‚æœä¸€ä¸ªå­é›†ä¸æ˜¯çº¯çš„ï¼ˆå³å…¶ä¸­çš„æ ·æœ¬ä¸å…¨å±äºåŒä¸€ç±»åˆ«ï¼‰ï¼Œé‚£ä¹ˆå°±éœ€è¦ç»§ç»­åˆ†è£‚ï¼Œç›´åˆ°è¾¾åˆ°åœæ­¢æ¡ä»¶ä¸ºæ­¢ã€‚


- Gain Ratio (for classification)
   $$
   GR(A|R) = \frac{IG(A|R)}{SplitInfo(A|R)}
   $$
$$SI(o) = - \left[ \frac{2}{6} \log_2 \frac{2}{6} + \frac{1}{6} \log_2 \frac{1}{6} + \frac{3}{6} \log_2 \frac{3}{6} \right] \approx 1.459$$
- æ¯”å¦‚è¯´outlooké‡Œæœ‰ä¸¤ä¸ªsï¼Œä¸€ä¸ªnï¼Œä¸‰ä¸ªqï¼Œsplitinfoå¦‚ä¸Š
- IGæœ‰high-arity biasï¼Œæ‰€ä»¥éœ€è¦ç”¨gain ratioæ¥è§£å†³


# Naive Bayes
primarily for classification
1. **Calculate Prior Probabilities**: Compute the probability of each class based on the training data.  
2. **Compute Likelihood**: Estimate the probability of features given each class using the conditional probability formula.  
3. **Apply Bayesâ€™ Theorem**: Use Bayes' rule to compute the posterior probability for each class. 
4. **Classify**: Assign the class with the highest posterior probability to the new instance.

compute example å“ªä¸ªå¤§é€‰å“ªä¸ª å¦‚æœæœ‰ä¸ç¡®å®šçš„attriuteå°±è·³è¿‡è®¡ç®—ä»–

**N:**  $P(N) \times P(\text{Temp} = h \mid N) \times P(\text{Wind} = F \mid N) = \frac{1}{2} \times \frac{2}{3} \times \frac{1}{3} = \frac{1}{9}$

**Y:**  $P(Y) \times P(\text{Temp} = h \mid N) \times P(\text{Wind} = F \mid N) = \frac{1}{2} \times \frac{1}{3} \times 1 = \frac{1}{6}$


## Elipson-Smoothing
- Instead of using zero values, we replace them with a small positive constant Îµ, which allows us to avoid complete probability collapse

## Laplace Smoothing
- Î±=1 é¢˜ç›®ä¼šç»™
- åˆ†å­åŠ 1ï¼Œåˆ†æ¯åŠ ç±»åˆ«æ•°*Î±, æ¯”å¦‚ä¸€ä¸ªoutlooké‡Œé¢æœ‰ä¸‰ä¸ªç±»åˆ«x,y,zï¼Œé‚£ä¹ˆåˆ†æ¯åŠ 3
- åˆ«å¿˜äº†æœ‰äº›æ¦‚ç‡æ˜¯0çš„å…¶å®ä»–åˆ†æ¯ä¸æ˜¯0


# Linear Regression
goal is to find the linear equation that best fits the data, aka minimise the loss function 
$$ y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \dots + \beta_nx_n + \epsilon $$

- **$y$**: Dependent variable (what you're trying to predict).
- **$x_1, x_2, \dots, x_n$**: Independent variables (features or predictors).
- **$\beta_0$**: Intercept (the value of $y$ when all $x$ values are 0).
- **$\beta_1, \beta_2, \dots, \beta_n$**: Coefficients (the change in $y$ for a one-unit change in each $x$).
- **$\epsilon$**: Error term (difference between the actual and predicted values).

Independent variables being highly correlated with each other, makes the model's predictions unstable 

## MSE, RMSE, MAE
- If outliers are a concern, RMSE is more sensitive and should be analyzed carefully.
- If we want a more interpretable measure, MAE is often preferred.
- MSE is useful in optimisation tasks, as it provides a continuous loss function for training models.

## Gradient Descent
- for finding the optimum parameters for a loss function (such as MSE), we first need to calculate the partial derivatives of the loss function (MSE).

$$MSE(\beta) = \mathcal{L}(\beta) = \frac{1}{N} \sum_{i} (y_i - \hat{y}_i)^2 = \frac{1}{N} \sum_{i} (y_i - x_i^T \beta)^2$$

- The partial derivative of the MSE  loss function would be: $$\frac{\partial \mathcal{L}}{\partial \beta_k} = -\frac{2}{N} \sum_{i} x_{ik} (y_i - x_i^T \beta_k)$$

- åˆå§‹å‡½æ•°å¯ä»¥éšä¾¿é€‰ï¼ŒThen, use **Gradient Descent** method to find the $\beta$ that minimises the loss (MSE) in an iterative fashion.
$$
\beta_k^{j+1} = \beta_k^j + \Delta \beta_k^j, \quad \text{with} \quad \Delta \beta_k^j = - \eta  \frac{\partial \mathcal{L}}{\partial \beta_k^j}
$$
- è®°ä½ beta0æ˜¯å¸¸æ•° æ‰€ä»¥ä»–çš„xæ˜¯1
- learning rate is too high, the algorithm may overshoot the minimum and fail to converge.
- learning rate is too low, the algorithm may converge slowly. 
   - If weâ€™re in the first few steps and MSE is increasing, then we can start again with a different initial guess and/or learning rate.
   - After several iterations, if the decrease in the MSE becomes negligible, indicating that the gradient is nearly zero, we consider the algorithm to have converged; alternatively, if higher accuracy is desired, we can reduce the learning rate on our current estimate of Î² to further refine the solution.

# Logistic Regression
classification problem, mainly for binary classification, cannot handle non-linear 

may overfit when A large number of features relative to the number of training examples. ç‰¹å¾æ•°é‡è¿œå¤§äºè®­ç»ƒæ ·æœ¬æ•°é‡

sigmoid function: $$ \sigma(z) = \frac{1}{1 + e^{-z}} $$

In **Logistic Regression**, we are regressing (predicting) the **probability** that an input belongs to a certain class.

The **Logistic Regression model** is:

$$
P(Y=1 | X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n)}}
$$

Where:
- $P(Y=1 | X)$ is the **probability** of the data point being in **Class 1**.
- $X_1, X_2, ... X_n$ are the **input features**.
- $\beta_0, \beta_1, ... \beta_n$ are the **coefficients** learned from the data.
- è®°ä½ æ°¸è¿œå…ˆæ‰¾class1çš„æ¦‚ç‡ ä¸€èˆ¬sigmoidå‡½æ•°æ˜¯0.5ä¸ºåˆ†ç•Œçº¿ å¤§äº0.5å°±æ˜¯1 å°äº0.5å°±æ˜¯0 ç„¶åclass0çš„æ¦‚ç‡å°±æ˜¯1-class1çš„æ¦‚ç‡

## Gradient Descent
$$
\sigma(x_A; \beta) = \sigma(0.2+(0.3\times1+(-2.2)\times0+3.3\times1+(-0.2)\times5))=0.94
$$
å…ˆç®—å‡ºæ‰€æœ‰çš„Xa,Xb,Xc,Xd,Xeçš„sigma(x_i; \beta) ç„¶åè¿›è¡Œæ›´æ–°å‚æ•°


$$
\beta_1 = \beta_1 - \eta \sum_{i \in \{A,B,C,D,E\}} (\sigma(x_i; \beta) - y_i) x_{1i}
$$
## Odds
$$
\text{Odds} = \frac{P(Y=1)}{P(Y=0)}
$$
compare the likelihood of the event happening versus not happening

## Scalling

Scaling is important in logistic regression (and many other machine learning models) for the following reasons:

1. **Improves Model Performance** Logistic regression uses gradient-based optimisation (e.i., Gradient Descent) to find the optimal weights. When features have different scales (e.g., `Sun` values range from 0 to 7 while `IBM` is just 0 or 2), the optimisation can become inefficient or converge slowly.
2. **Prevents Certain Features from Dominating** In this dataset, the `Sun` feature ranges from 0 to 7, while others like `IBM` only take values from {0, 2}. Without scaling, the model might assign too much importance to `Sun` just because of its larger values, even if it's not the most important predictor.
3. **Better Numerical Stability** Logistic regression calculates logits (linear combination of features and weights), which are then passed through the sigmoid function. If the feature values are too large, it can lead to numerical instability (e.g., extremely large or small values in exponentiation).

## Use Logistic Regression as multi-class classification
- One-vs-All 
   - train a separate binary logistic regression classifier for each class. Each classifier distinguishes one class from all other classes.
- Softmax Regression
   - generalizes the binary logistic regression model to handle multiple classes simultaneously

# SVM
**classification** and **regression** tasks. It works by finding the optimal hyperplane that best separates the data into different classes while maximising the margin (distance between the hyperplane and the nearest data points from each class, called support vectors).

In real-world data, perfect linear separation is often impossible due to noise or overlap between classes. To handle this, soft-margin SVM introduces slack variables ($\xi$) and a penalty parameter ($C$):

Soft-margin SVM introduces **slack variables** ($\xi_i$) to allow margin violations and misclassifications when the data is not linearly separable.
- If $\xi_i = 0$, the point is correctly classified and outside the margin.
- If $0 < \xi_i \leq 1$, the point is within the margin but still correctly classified.
- If $\xi_i > 1$, the point is misclassified.

å¦‚æœæ²¡æœ‰slackå˜é‡ï¼Œé‚£ä¹ˆæ•°æ®å¿…é¡»å®Œå…¨çº¿æ€§å¯åˆ†ï¼Œå¦åˆ™æ— æ³•æ‰¾åˆ°è¶…å¹³é¢ã€‚

**Penalty for Slack ($C$)**
- The penalty parameter $C$ controls how much we penalize large $\xi_i$ values.
- **Higher $C$**: Less tolerance for margin violations, leading to a more complex model that prioritizes correct classification. model overfit data
- **Lower $C$**: More tolerance for margin violations, resulting in a softer boundary that generalizes better. model underfit data

The SVM optimization problem with slack variables is:

$$
\min \frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i
$$

subject to:

$$
y_i (w \cdot x_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0
$$

where:
- $w$ is the weight vector,
- $b$ is the bias term,
- $y_i$ are the class labels ($\pm1$),
- $x_i$ are the feature vectors.

SVM Classification Rule:
- If $f(x) \geq 0$, classify as **Class 1**.
- If $f(x) < 0$, classify as **Class 0**.

## Application
- Multi-class classification
- Rating
- Ranking
- Structured prediction

# Evaluation
## Split data into train, validation, test
- **Basic problems?** A simple **train-test split** (e.g., 80-20) usually works.
- **Need hyperparameter tuning?** Use a **train-validation-test split** (e.g., 70-15-15).
- **Imbalanced data?** Make sure to use **stratification**.
   - stratification ensures that each subset of data has the same proportion of different categories

## Why split data into train, validation, test
- To Make Sure Our Model Actually Learns (and Not Just Memorizes)
- To Get a Fair Performance Estimate
- To Tune the Model Without Cheating (validation set)
- To Handle Class Imbalanceså½“ä¸€ä¸ªæ•°æ®é‡Œä¸€ç±»è¿œè¿œè¶…è¿‡å¦ä¸€ç±» Fairly (stratified sampling)

## Confusion Matrix
- True Positive (TP): Predicted positive, actually positive.
- True Negative (TN): Predicted negative, actually negative.
- False Positive (FP): Predicted positive, actually negative. 
   - The false positives (FP) are those items that we attempted to classify as being of class d, but they were actually of some other class æœ¬æ¥ä¸æ˜¯dä½†æ˜¯è¢«åˆ†æˆäº†d
- False Negative (FN): Predicted negative, actually positive. 
   - false negatives (FN): those items that were actually of class d, but we classified as being of some other class æœ¬æ¥æ˜¯dä½†æ˜¯è¢«åˆ†æˆäº†åˆ«çš„

Confusion matrix isn't just for binary classificationâ€”it also works for **multi-class classification**. In this case, the matrix expands to accommodate all possible class predictions.

For a problem with *three classes* (e.g., Cat, Dog, and Rabbit), the confusion matrix might look like this:

| **Actual / Predicted** | **Predicted: Cat** | **Predicted: Dog** | **Predicted: Rabbit** |
|----------------------|----------------|----------------|----------------|
| **Actual: Cat**     | **Correct: Cat** | Cat misclassified as Dog | Cat misclassified as Rabbit |
| **Actual: Dog**     | Dog misclassified as Cat | **Correct: Dog** | Dog misclassified as Rabbit |
| **Actual: Rabbit**  | Rabbit misclassified as Cat | Rabbit misclassified as Dog | **Correct: Rabbit** |

- *Diagonal values*  represent correct classifications.
- *Off-diagonal values* are *errors*, where one class is misclassified as another.

## Holdout vs. Cross-Validation
**1. Holdout Evaluation**  
- split dataset randomly into **training and test sets**â€”typically something like **80% for training and 20% for testing**.  
- Train the model on the training set, then test it on the test set once.  
- The test set gives an estimate of how the model will perform on new data. 

**2. Cross-Validation**  
- Instead of just one train-test split, you split the dataset into $K$ equal-sized parts (folds) (e.g., K=5 or 10).  
- Train the model K times, each time using $K-1$ folds for training** and one fold for testing.  
- The final performance score is the **average** across all runs.  
- kå¤ªå¤§ï¼Œè®¡ç®—é‡å¤ªå¤§ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆï¼Œkå¤ªå°ï¼Œæ–¹å·®å¤ªå¤§ï¼Œå®¹æ˜“æ¬ æ‹Ÿåˆ

**When Should You Use Holdout vs. Cross-Validation?**
| Scenario | Holdout | Cross-Validation |
|----------|--------|------------------|
| Large dataset (millions of records) | âœ… Works well | âŒ Too slow |
| Small dataset (few thousand samples) | âŒ Might not be reliable | âœ… More accurate |
| Need fast evaluation | âœ… Quick & simple | âŒ Computationally heavy |
| Hyperparameter tuning | âŒ Risky (prone to overfitting) | âœ… More stable |
| Deep learning models (large compute cost) | âœ… Saves time | âŒ Too expensive |

----

## Accuracy, Precision, Recall, F1-Score
å•ç”¨accuracyå¯èƒ½ä¸å‡†ç¡®ï¼Œå› ä¸ºæ•°æ®ä¸å¹³è¡¡ï¼Œæ¯”å¦‚99%çš„æ ·æœ¬æ˜¯0ï¼Œ1%çš„æ ·æœ¬æ˜¯1ï¼Œé‚£ä¹ˆå¦‚æœæ¨¡å‹å…¨éƒ¨é¢„æµ‹0ï¼Œaccuracyä¹Ÿæ˜¯99%ï¼Œä½†æ˜¯è¿™ä¸ªæ¨¡å‹å…¶å®å¾ˆå·®ã€‚

Precision/Recall are typically in an inverse relationship, so we need to balance them.
- Precision: True Positives / (True Positives + False Positives)
   - é¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼Œå®é™…ä¸ºæ­£çš„æ¯”ä¾‹ï¼Œè¶Šé«˜è¶Šå¥½
- Recall: True Positives / (True Positives + False Negatives)
   - åœ¨æ‰€æœ‰å®é™…ä¸ºæ­£ç±»çš„æ ·æœ¬ä¸­ï¼Œæœ‰å¤šå°‘è¢«æˆåŠŸè¯†åˆ«ï¼Œè¶Šé«˜è¶Šå¥½

F1-Score: 2 * (Precision * Recall) / (Precision + Recall)

## Compute for entire model
- **Macro Averaging**: Computes the precision and recall **independently for each class** and then takes their **unweighted average**. This treats all classes **equally**, regardless of their size.  
- **Micro Averaging**: Aggregates the contributions of **all classes** before calculating precision and recall. This approach **weights** larger classes more heavily and gives an overall system performance measure.  
- **Weighted Averaging**: Similar to macro averaging, but each class is **weighted by its support** (i.e., the number of instances in that class). This helps when classes are **imbalanced**.  

**When to Use Macro vs. Micro Averaging?**  è€ƒè™‘weight ç”¨micro ä¸è€ƒè™‘ç”¨macro ç°å®ä¸­microå¤š
- If we want to *prioritize small classes* and ensure each class is given **equal importance**, **macro averaging** is the better choice.  
- If we care more about *overall system performance*, where larger classes influence the results more (common in real-world applications like fraud detection), **micro averaging** is preferable. 

| Aspect | Model Bias | Evaluation Bias |
|--------|------------|----------------|
| **Definition** | Errors due to incorrect assumptions in the model | Errors due to incorrect evaluation methods |
| **Cause** | Model is too simple or incorrectly structured | Test set is biased or inappropriate metrics are used |
| **Effect** | Leads to **underfitting** (poor learning) | Leads to **misleading performance metrics** |
| **Example** | Using a linear model for a nonlinear problem | Evaluating a fraud detection model with only non-fraud cases in the test set |
| **Solution** | Use a more flexible complex model, add more features | Use fair test sets, proper metrics, and cross-validation |

|      | Model Variance (æ¨¡å‹æ–¹å·®) | Evaluation Variance (è¯„ä¼°æ–¹å·®) |
| ---- | --------------------- | -------------------------- |
| æ„ä¹‰   | æ¨¡å‹è¾“å‡ºéšè®­ç»ƒé›†ä¸åŒè€Œæ³¢åŠ¨çš„ç¨‹åº¦      | æ€§èƒ½è¯„ä¼°ç»“æœéšæµ‹è¯•é›†æˆ–åˆ’åˆ†ä¸åŒè€Œæ³¢åŠ¨çš„ç¨‹åº¦      |
| å…³æ³¨ç‚¹  | æ¨¡å‹æœ¬èº«çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›         | è¯„ä¼°æŒ‡æ ‡çš„ç¨³å®šæ€§å’Œå¯ä¿¡åº¦               |
| é«˜æ–¹å·®è§£å†³æ–¹æ³• | ç®€åŒ–æ¨¡å‹ã€å¢åŠ æ•°æ®ã€æ­£åˆ™åŒ–         | ä½¿ç”¨äº¤å‰éªŒè¯ã€å¤šæ¬¡é‡å¤å®éªŒ              |


| æƒ…å†µ           | Train Error | Test Error | é—®é¢˜    | è§£å†³åŠæ³•             |
| ------------ | ----------- | ---------- | ----- | ---------------- |
| Underfitting (high bias) | é«˜           | é«˜          | æ¨¡å‹å¤ªç®€å• | å¢åŠ å¤æ‚åº¦, add more feature, boosting |
| Overfitting (high variance)  | ä½           | é«˜          | æ¨¡å‹å¤ªå¤æ‚ | å‡å°‘å¤æ‚åº¦, reduce feature, add more traning data, bagging  |
| ç†æƒ³çŠ¶æ€         | ä½           | ä½          | æ¨¡å‹åˆé€‚  | âœ… æ— éœ€ä¿®æ”¹           |

| æ¨¡å‹æƒ…å†µ     | åå·®bias | æ–¹å·®variance | é”™è¯¯ç±»å‹          |
| -------- | -- | -- | ------------- |
| ç®€å•æ¨¡å‹ï¼ˆçº¿æ€§ï¼‰ | é«˜  | ä½  | æ¬ æ‹Ÿåˆï¼ˆUnderfitï¼‰ |
| å¤æ‚æ¨¡å‹ï¼ˆæ·±ç½‘ï¼‰ | ä½  | é«˜  | è¿‡æ‹Ÿåˆï¼ˆOverfitï¼‰  |
| é€‚ä¸­æ¨¡å‹     | ä½  | ä½  | æ³›åŒ–å¥½ âœ…         |

# Feature Selection
better performance (too many feature overfitting), faster training, more interpretable model

1. *Filter Methods* â€“ These use statistical techniques to rank and select features before training a model.  
   - Example: Mutual Information, Chi-Square Test, Correlation.  
      - Mutual Informationå¤§ï¼Œè¯´æ˜è¿™ä¸ªç‰¹å¾å’Œç›®æ ‡å˜é‡ä¹‹é—´çš„å…³ç³»å¾ˆå¼ºï¼Œæ‰€ä»¥è¿™ä¸ªç‰¹å¾å¾ˆé‡è¦ã€‚ best attribute for classificationã€‚
      -  Mutual Information is another name for Information Gain

2. *Wrapper Methods* â€“ These test different subsets of features by training models and evaluating their performance.  
   - Example: Recursive Feature Elimination (RFE)ï¼š iteratively remove less important features and select the most relevant ones for a given model 
3. *Embedded Methods* â€“ These select features automatically while training the model.  
   - Example: Decision Tree feature importance.

| æ–¹æ³•ç±»å‹            | æ ¸å¿ƒæ€æƒ³                         | æ˜¯å¦ä¾èµ–æ¨¡å‹  | ä¼˜ç‚¹                     | ç¼ºç‚¹                     | ä¸¾ä¾‹                                      |
| --------------- | ---------------------------- | ------- | ---------------------- | ---------------------- | --------------------------------------- |
| **Filter æ–¹æ³•**   | ç‹¬ç«‹äºæ¨¡å‹ï¼Œæ ¹æ®ç»Ÿè®¡æŒ‡æ ‡ï¼ˆå¦‚ç›¸å…³æ€§ï¼‰å¯¹ç‰¹å¾è¿›è¡Œæ’åºå’Œé€‰æ‹© | âŒ ä¸ä¾èµ–æ¨¡å‹ | å¿«é€Ÿã€æ¨¡å‹æ— å…³ã€é€‚åˆé«˜ç»´æ•°æ®         | å¿½ç•¥ç‰¹å¾ä¹‹é—´çš„äº¤äº’ã€ä¸å…·ä½“æ¨¡å‹æ€§èƒ½ä¸ä¸€å®šç›¸å…³ | äº’ä¿¡æ¯ï¼ˆMutual Infoï¼‰ã€å¡æ–¹æ£€éªŒï¼ˆChi-Squareï¼‰ã€ç›¸å…³ç³»æ•°ç­‰ |
| **Wrapper æ–¹æ³•**  | ä½¿ç”¨æ¨¡å‹è¯„ä¼°ä¸åŒç‰¹å¾å­é›†çš„æ•ˆæœï¼Œé€‰æ‹©æœ€ä¼˜ç»„åˆ       | âœ… ä¾èµ–æ¨¡å‹  | é€šå¸¸é€‰æ‹©æ•ˆæœæ›´å¥½çš„ç‰¹å¾å­é›†ï¼Œè€ƒè™‘ç‰¹å¾ä¹‹é—´äº¤äº’ | è®¡ç®—æˆæœ¬é«˜ã€å®¹æ˜“è¿‡æ‹Ÿåˆ            | é€’å½’ç‰¹å¾æ¶ˆé™¤ï¼ˆRFEï¼‰ã€å‰å‘/åå‘é€‰æ‹©                     |
| **Embedded æ–¹æ³•** | åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œç‰¹å¾é€‰æ‹©ä¸å­¦ä¹ è¿‡ç¨‹ä¸€ä½“åŒ–  | âœ… å¼ºä¾èµ–æ¨¡å‹ | è®­ç»ƒæ•ˆç‡è¾ƒé«˜ï¼Œèƒ½è‡ªåŠ¨é€‰æ‹©ç‰¹å¾ã€é€‚åº”æ¨¡å‹    | ä¾èµ–å…·ä½“æ¨¡å‹ç»“æ„ï¼ˆå¦‚çº¿æ€§ã€æ­£åˆ™åŒ–ï¼‰ï¼›éš¾ä»¥æ³›åŒ– | Lasso å›å½’ã€å†³ç­–æ ‘ç‰¹å¾é‡è¦æ€§ã€æ­£åˆ™åŒ–é€»è¾‘å›å½’               |




| æ–¹æ³•                       | æ ¸å¿ƒæ€æƒ³                      | å¸¸è§é—®é¢˜                       | è§£å†³æ–¹æ¡ˆ                           |
| ------------------------ | ------------------------- | -------------------------- | ------------------------------ |
| **Forward Selection**    | ä»æ— åˆ°æœ‰ï¼Œé€æ­¥**åŠ å…¥**æœ€æœ‰ç”¨çš„ç‰¹å¾ï¼ˆè´ªå¿ƒç­–ç•¥ï¼‰ | å¯èƒ½é”™è¿‡æ›´ä¼˜çš„ç‰¹å¾ç»„åˆï¼›å‰ä¸€æ­¥é€‰é”™åæ— æ³•å›å¤´     | ä½¿ç”¨äº¤å‰éªŒè¯è¯„ä¼°æ¯ä¸€æ­¥ï¼›ç»“åˆåµŒå…¥å¼æ–¹æ³•è¾…åŠ©é€‰æ‹©        |
| **Backward Elimination** | ä»å…¨ä½“å¼€å§‹ï¼Œé€æ­¥**åˆ é™¤**æœ€æ— ç”¨çš„ç‰¹å¾      | åˆå§‹æ¨¡å‹åŒ…å«æ‰€æœ‰ç‰¹å¾ï¼Œè®¡ç®—å¼€é”€å¤§ï¼›æ˜“å—å¤šé‡å…±çº¿æ€§å½±å“ | åœ¨åˆæ­¥è¿‡æ»¤åä½¿ç”¨ï¼›é…åˆæ­£åˆ™åŒ–ï¼ˆå¦‚ Ridgeï¼‰å‡å°‘å…±çº¿æ€§å½±å“ |

# PCA
unsupervised learning

Principal Component Analysis (PCA) is a linear dimensionality reduction technique that transforms a dataset into a lower-dimensional space by projecting it onto the directions (principal components) that maximize variance. These directions are orthogonal (uncorrelated) and ordered by the amount of original data variance they capture.


Formally, given a dataset $X \in \mathbb{R}^{n \times d}$, where $n$ is the number of observations and $d$ is the number of features, PCA seeks to find a new set of orthogonal axes, called **principal components**, onto which the data can be projected such that:


The first principal component corresponds to the direction of maximum variance in the data.

Each subsequent component captures the highest remaining variance under the constraint of being orthogonal to all previous components.

## Covariance Matrix
- åæ–¹å·®çŸ©é˜µ æ˜¯æè¿°æ•°æ®å„ç‰¹å¾ä¹‹é—´æ–¹å·®å’Œåæ–¹å·®çš„çŸ©é˜µï¼Œåæ˜ ç‰¹å¾é—´çš„ç›¸å…³æ€§ã€‚
- ç‰¹å¾å€¼eigenvalue æ˜¯åæ–¹å·®çŸ©é˜µçš„å›ºæœ‰å±æ€§ï¼Œä»£è¡¨æ•°æ®æ²¿å¯¹åº”ç‰¹å¾å‘é‡æ–¹å‘çš„æ–¹å·®å¤§å°ã€‚
- åœ¨ PCA ä¸­ï¼Œé€šè¿‡å¯¹åæ–¹å·®çŸ©é˜µæ±‚ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œæ‰¾åˆ°å¯¹åº”æœ€å¤§ç‰¹å¾å€¼çš„ç‰¹å¾å‘é‡ï¼Œå®ç°æœ‰æ•ˆé™ç»´ã€‚
- n samples and d features, covariance matrix is a `d x d` matrix
- compute covariance matrix æ€»ä¹˜æ³•æ¬¡æ•°æ˜¯`n*d^2`
## PCAç¼ºç‚¹
PCA does not know about class labels

PCA maximizes variance

Notice: do dimensionality reduction (and feature selection) inside cross-validation, only applied to the training set



# Perceptron
- æ‰¾å†³ç­–è¾¹ç•Œ classification and regression
- only can do linear
- åªèƒ½ä¼ æ•°å­—

## Perceptron learning rule
$$\theta_j^{(t)} \leftarrow \theta_j^{(t-1)} + \eta \left( y^{(i)} - \hat{y}^{(i, t)} \right) x_j^{(i)}$$

where $\eta$ is the learning rate, $y^{(i)}$ is the true label, $\hat{y}^{(i, t)}$ is the predicted label at time $t$, $x_j^{(i)}$ is the $j$-th feature of the $i$-th sample, and $\theta_j^{(t)}$ is the weight of the $j$-th feature at time $t$, $\theta_j^{(t-1)}$ is the weight of the $j$-th feature at time $t-1$ ç°æœ‰çš„weight

å…ˆè®¡ç®—$\hat{y}$ï¼Œå¦‚æœyå’Œ$\hat{y}$ä¸€æ ·ï¼Œå°±è¯´æ˜è¿™ä¸ªweightæ˜¯å¥½çš„ï¼Œä¸éœ€è¦æ›´æ–°ã€‚

ç›´åˆ°æŸä¸€è½®æƒé‡ ä¸å†å˜åŒ–ï¼ˆæ‰€æœ‰æ ·æœ¬éƒ½æ­£ç¡®åˆ†ç±»ï¼‰ä¸ºæ­¢


| ç‰¹æ€§    | Perceptron | Multi-Layer Perceptron (MLP) |
| ----- | ---------- | ---------------------------- |
| å±‚æ•°    | å•å±‚         | å¤šå±‚ï¼ˆè‡³å°‘å«ä¸€ä¸ªéšè—å±‚ï¼‰                 |
| èƒ½åŠ›    | çº¿æ€§åˆ†ç±»       | éçº¿æ€§åˆ†ç±»ã€å¤šç§ä»»åŠ¡                   |
| æ¿€æ´»å‡½æ•°  | step function | ReLUã€Sigmoidã€tanh            |
| è¡¨è¾¾èƒ½åŠ›  | å¼±          | å¼º                            |
| æƒé‡æ›´æ–°æ–¹å¼       | æ‰‹åŠ¨è§„åˆ™ï¼ˆPerceptron Ruleï¼‰ | åŸºäºå¯¼æ•°çš„åå‘ä¼ æ’­                |


# Multi-Layer Perceptron
- æ‰¾å†³ç­–è¾¹ç•Œ
- can do non-linear classification, regression

### Example
è¿™ä¸ªä¾‹å­æ˜¯ç”¨**æ„ŸçŸ¥å™¨ï¼ˆPerceptronï¼‰ç½‘ç»œ**æ¥å­¦ä¹ **å¼‚æˆ–ï¼ˆXORï¼‰å‡½æ•°**ï¼Œå¹¶è¯¦ç»†å±•ç¤ºäº†æƒé‡æ›´æ–°çš„å…¨è¿‡ç¨‹ã€‚

---

## ğŸŒŸèƒŒæ™¯çŸ¥è¯†

* \*\*æ„ŸçŸ¥å™¨ï¼ˆPerceptronï¼‰\*\*æ˜¯ä¸€ç§æœ€åŸºæœ¬çš„ç¥ç»å…ƒæ¨¡å‹ã€‚
* XOR ä¸èƒ½ç”¨å•å±‚æ„ŸçŸ¥å™¨è§£å†³ï¼Œå› ä¸ºå®ƒæ˜¯**éçº¿æ€§å¯åˆ†**çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿™é‡Œç”¨ä¸¤å±‚ï¼š

  * **ç¬¬ä¸€å±‚**ï¼šä¸¤ä¸ªæ„ŸçŸ¥å™¨ï¼Œä¸€ä¸ªè®¡ç®— AND (`pâ‚`)ï¼Œä¸€ä¸ªè®¡ç®— OR (`pâ‚‚`)
  * **ç¬¬äºŒå±‚**ï¼šç”¨ `pâ‚` å’Œ `pâ‚‚` çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œè®­ç»ƒä¸€ä¸ªæ„ŸçŸ¥å™¨æ¥æ¨¡æ‹Ÿ XOR

---

## ğŸ”¢ è¾“å…¥æ•°æ®

æˆ‘ä»¬æœ‰ 4 ä¸ªè¾“å…¥æ•°æ®ç‚¹ï¼Œå¯¹åº” `xâ‚ XOR xâ‚‚`ï¼š

|  # | xâ‚ | xâ‚‚ | pâ‚ = AND(xâ‚,xâ‚‚) | pâ‚‚ = OR(xâ‚,xâ‚‚) | y = XOR(xâ‚,xâ‚‚) |
| -: | -- | -- | --------------- | -------------- | -------------- |
|  1 | 1  | 0  | 0               | 1              | 1              |
|  2 | 0  | 1  | 0               | 1              | 1              |
|  3 | 1  | 1  | 1               | 1              | 0              |
|  4 | 0  | 0  | 0               | 0              | 0              |

---

## ğŸ§  ç¬¬äºŒå±‚æ„ŸçŸ¥å™¨

æˆ‘ä»¬ç”¨ `pâ‚` å’Œ `pâ‚‚` çš„è¾“å‡ºä½œä¸ºè¾“å…¥ï¼Œè¾“å…¥å½¢å¼ä¸ºï¼š

```
P = <-1, pâ‚, pâ‚‚>
```

å…¶ä¸­ `-1` æ˜¯ä¸ºäº†è¡¨ç¤ºåç½®ï¼ˆbiasï¼‰ï¼Œå¯¹åº”æƒé‡ `Î¸â‚€`

åˆå§‹åŒ–å‚æ•°ï¼š

```
Î¸ = <Î¸â‚€, Î¸â‚, Î¸â‚‚> = <0, 0, 0>
```

---

## ğŸ” æƒé‡æ›´æ–°è¿‡ç¨‹

* ä½¿ç”¨**æ„ŸçŸ¥å™¨ç®—æ³•**ï¼ˆPerceptron Learning Ruleï¼‰ï¼š

  ```
  Î¸ â† Î¸ + Î·(y - Å·)P
  ```

  * å­¦ä¹ ç‡ Î· = 0.1
  * Å· æ˜¯å½“å‰æ¨¡å‹çš„é¢„æµ‹ï¼ˆ0 æˆ– 1ï¼‰ï¼Œç”± z = Î¸Â·P å†³å®š
  * ç”¨ç¡¬é˜ˆå€¼å‡½æ•° f(z)ï¼šz > 0 â†’ Å·=1ï¼Œå¦åˆ™ Å·=0

---

### ğŸ§® Epochï¼ˆè®­ç»ƒè½®æ¬¡ï¼‰è§£é‡Šï¼š

#### Epoch 1:

* å¯¹æ¯ä¸ªæ ·æœ¬è¾“å…¥å‘é‡ Pï¼Œè®¡ç®— zï¼Œé¢„æµ‹ Å·
* å¦‚æœ Å· â‰  yï¼Œå°±è°ƒæ•´æƒé‡
* ä¾‹å¦‚ï¼š

  * ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼šP = âŸ¨-1, 0, 1âŸ©ï¼Œz = 0 â†’ Å· = 0ï¼Œè€Œ y = 1

    * æ‰€ä»¥æ›´æ–° Î¸ â† Î¸ + 0.1 Ã— (1 - 0) Ã— âŸ¨-1, 0, 1âŸ© â†’ Î¸ = âŸ¨-0.1, 0, 0.1âŸ©

ä½ å¯ä»¥åœ¨æ¯ä¸€è¡Œçœ‹åˆ° z çš„è®¡ç®—ã€é¢„æµ‹ã€æ˜¯å¦æ›´æ–°ï¼Œä»¥åŠæ–°çš„æƒé‡ã€‚

---

## âœ… æ”¶æ•›æ¡ä»¶

å½“æ‰€æœ‰æ ·æœ¬éƒ½è¢«æ­£ç¡®åˆ†ç±»ï¼ˆå³æ²¡æœ‰æƒé‡æ›´æ–°ï¼‰æ—¶ï¼Œè¯´æ˜æ¨¡å‹å·²ç»**æ”¶æ•›**ã€‚

åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ**ç¬¬ 4 æ¬¡ Epoch**åæƒé‡ä¸å†æ›´æ–°ï¼Œæ‰€ä»¥è®­ç»ƒå®Œæˆã€‚

---

## ğŸ æœ€ç»ˆæƒé‡

è®­ç»ƒç»“æŸåï¼Œç¬¬äºŒå±‚çš„æƒé‡å‚æ•°ä¸ºï¼š

```
Î¸ = <0, -0.2, 0.1>
```

è§£é‡Šå¦‚ä¸‹ï¼š

* `Î¸â‚€ = 0` â†’ åç½®é¡¹
* `Î¸â‚ = -0.2` â†’ ä¸ AND(pâ‚) ç›¸ä¹˜
* `Î¸â‚‚ = 0.1` â†’ ä¸ OR(pâ‚‚) ç›¸ä¹˜

---

## ğŸ§  æ€»ç»“

é€šè¿‡ç¬¬ä¸€å±‚æå–äº†ç®€å•çš„é€»è¾‘ç‰¹å¾ï¼ˆAND å’Œ ORï¼‰ï¼Œç¬¬äºŒå±‚ç»„åˆè¿™ä¸¤ä¸ªç‰¹å¾å­¦ä¹ æ›´å¤æ‚çš„ XORã€‚

è¿™ç§ç»“æ„ä½“ç°äº†ï¼š

> **â€œç»„åˆç®€å•é€»è¾‘ï¼Œå®ç°å¤æ‚å†³ç­–â€**

---

## Feature Learning
ç”±ç¥ç»ç½‘ç»œç›´æ¥ä»åŸå§‹æ•°å€¼æ•°æ®ä¸­è‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤ºã€‚

ç‰¹å¾ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œæ˜¯æ¨¡å‹å†…éƒ¨ä¸€å±‚å±‚â€œæŠ½è±¡â€å‡ºæ¥çš„ï¼Œå¯¹ç›®æ ‡ä»»åŠ¡æœ‰ç”¨ã€‚

ä¹Ÿå«Representation Learningï¼ˆè¡¨ç¤ºå­¦ä¹ ï¼‰ã€‚

ä¼˜ç‚¹ï¼šå‡å°‘äº†äººå·¥ç‰¹å¾è®¾è®¡çš„éœ€æ±‚ã€‚

ä»£ä»·ï¼šéœ€è¦æ›´å¤šå‚æ•°è°ƒä¼˜ï¼ˆæ¯”å¦‚ç½‘ç»œå±‚æ•°ã€æ¿€æ´»å‡½æ•°ã€å­¦ä¹ ç‡ç­‰ï¼‰ã€‚

## activation function
- sigmoid:
$$
\sigma(z) = \frac{1}{1 + e^{-z}}
$$
- tanh:
$$
\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}
$$
- ReLU: Helps to delete unnecessary weights
$$
\text{ReLU}(z) = \max(0, z)
$$
- step function cannot be used for backpropagation because it is not differentiable at 0

## output function
- binary classification: sigmoid or step function
- multi-class classification: softmax
$$
\text{softmax}(z) = \frac{e^{z_i}}{\sum_{j=1}^n e^{z_j}}
$$

## loss function
- binary classification: cross-entropy
$$
L(y, \hat{y}) = -[y \log(\hat{y}) + (1-y) \log(1-\hat{y})]
$$
- multi-class classification: cross-entropy

$$
L(y, \hat{y}) = -\sum_{i=1}^n y_i \log(\hat{y_i})
$$

- regression: MSE


# Backpropagation
compute the partial derivatives of the error with respect to each weight in the network.

sequence: Compute the error, propagate the error backwards, update weights.

| ç¬¦å·                  | æ„ä¹‰                                   |
| ------------------- | ------------------------------------ |
| $\theta_{ji}^{(l)}$ | ç¬¬ $l$ å±‚ä¸­ï¼Œä»ç¬¬ $i$ ä¸ªç¥ç»å…ƒåˆ°ç¬¬ $j$ ä¸ªç¥ç»å…ƒçš„æƒé‡   |
| ä¸Šæ ‡ $l$              | è¿™ä¸€å±‚çš„ç¼–å·ï¼ˆä»è¾“å…¥åˆ°è¾“å‡ºé€å±‚é€’å¢ï¼‰                   |
| ä¸‹æ ‡ $i, j$           | ç¬¬ $i$ ä¸ªç¥ç»å…ƒæ˜¯**è¾“å…¥æº**ï¼Œç¬¬ $j$ ä¸ªç¥ç»å…ƒæ˜¯**ç›®æ ‡** |

- use MSE for loss function


In neural networks with backpropagation, we want to minimise the error of our network by finding the optimum weights ($\theta_{ij}$) for our network. To do so, we want to find the relation (dependency) between the error and the weights in each layer. Therefore, we use the derivatives of our error function.

$$
\theta_{jk}^{(l)} \leftarrow \theta_{jk}^{(l)} + \Delta \theta_{jk}^{(l)}
$$

where:

$$
\Delta \theta_{jk}^{(l)} = -\eta \frac{\partial E}{\partial \theta_{jk}^{(l)}} = \eta \, \delta_k^{(l)} a_j^{(l)}
$$

and

$$
\delta_k^{(l)} =  g'(z_k) (y - a_k^{(l)}) =  (1 - \sigma (z_k^{(l)})) \sigma (z_k^{(l)}) (y - a_k^{(l)})\quad \text {for the last layer}
$$

or

$$
\delta_k^{(l)} = g'(z_k) \theta_{kj}^{(l+1)} \delta_j^{(l+1)} =\sigma(z_k^{(l)}) (1 - \sigma(z_k^{(l)})) \theta_{kj}^{(l+1)} \delta_j^{(l+1)} \quad \text{for the layer before}
$$
| ç¬¦å·  | å«ä¹‰          | å¤‡æ³¨        |
| --- | ----------- | --------- |
| `z` | åŠ æƒå’Œï¼ˆLinearï¼‰ | è¿˜æ²¡â€œæ¿€æ´»â€çš„è¾“å…¥ |
| `a` | æ¿€æ´»åçš„è¾“å‡º      | å¯ä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ |
- biaæ˜¯è¦ä¹˜çš„

![backprop.png](back.png)

# Generative vs. Discriminative
discriminative approaches model a function to predict y from x, generative approaches model a distribution of x and y

åˆ¤åˆ«å¼æ˜¯â€œåˆ†è¾¨â€å‡ºç±»åˆ«ï¼Œå­¦çš„æ˜¯åˆ†ç±»è¾¹ç•Œï¼›

ç”Ÿæˆå¼æ˜¯â€œç”Ÿæˆâ€æ•°æ®ï¼Œå­¦çš„æ˜¯æ•°æ®çš„åˆ†å¸ƒã€‚

ä¸»è¦é’ˆå¯¹æœ‰ç›‘ç£å­¦ä¹ ä¸­çš„åˆ†ç±»å’Œå›å½’ä»»åŠ¡

| æ–¹é¢    | ç”Ÿæˆå¼æ¨¡å‹ (Generative) | åˆ¤åˆ«å¼æ¨¡å‹ (Discriminative) |               |
| ----- | ------------------ | ---------------------- | ------------- |
| ä½œç”¨    | å¯ä»¥ç”Ÿæˆæ•°æ®ï¼Œä¹Ÿå¯ä»¥åˆ†ç±»       | åªèƒ½åˆ†ç±»                   |               |
| åˆ†ç±»ç­–ç•¥  | é€šè¿‡è´å¶æ–¯å…¬å¼è®¡ç®—åéªŒæ¦‚ç‡      | ç›´æ¥é¢„æµ‹ç±»åˆ«                 |               |
| æ¨¡å‹å¤æ‚åº¦ | é€šå¸¸æ›´å¤æ‚              | é€šå¸¸è¾ƒç®€å•                  |               |
| è®­ç»ƒæ•ˆç‡  | é€šå¸¸è¾ƒä½               | é€šå¸¸è¾ƒé«˜                   |               |
| é€‚ç”¨åœºæ™¯  | éœ€è¦ç†è§£æ•°æ®ç”Ÿæˆè¿‡ç¨‹ã€ç”Ÿæˆæ ·æœ¬    | çº¯ç²¹åˆ†ç±»ä»»åŠ¡                 |               |
| ä»£è¡¨ç®—æ³•  | æœ´ç´ è´å¶æ–¯ | é€»è¾‘å›å½’ã€SVMã€ç¥ç»ç½‘ç»œ, å†³ç­–æ ‘, linear regression, kNN        |               |

# Unsupervised Learning
## K-Means
unsupervised learning, no labels

### ç®—æ³•æ­¥éª¤
- Selecting K cluster centres (centroids) randomly  
- Assigning each data point to the nearest centroid
- Updating the centroids based on the average position of points in each cluster
- Repeating the process until centroids stop changing significantly

### K-Meansç¼ºç‚¹
- éœ€è¦æ‰‹åŠ¨é€‰æ‹©Kå€¼
- å¯¹åˆå§‹å€¼æ•æ„Ÿ
- ä¸èƒ½å¤„ç†éåœ†å½¢æ•°æ®
- å¯¹å¼‚å¸¸å€¼æ•æ„Ÿ

æ‰¾Kå¯ä»¥ç”¨elbow method: Look for a point where the reduction in WCSS significantly slows down = the Elbow point

## evaluate the goodness of a clustering structure without relying on external information (i.e., unsupervised evaluation) 
### Cluster cohesion (compactness, tightness)
- Intra-cluster distance: distances between instances inside each cluster
- WCSS: within-cluster sum of squares
   - æ¯ä¸ªclusterå†…éƒ¨ï¼Œæ‰€æœ‰ç‚¹åˆ°clusterä¸­å¿ƒçš„è·ç¦»çš„å¹³æ–¹å’Œ
   - è¶Šå°è¶Šå¥½

### Cluster separation (isolation, distinctiveness)
- Inter-cluster distances: the degree to which clusters are distinct or well-separated from each other
- BCSS: between-cluster sum of squares
   - clusterä¹‹é—´è·ç¦»çš„å¹³æ–¹å’Œ
   - è¶Šå¤§è¶Šå¥½
å¥½çš„clusterè¦æœ‰high cohesion and high separation è¯´æ˜æ¯ä¸ªå›¢å†…éƒ¨å¾ˆç´§å¯†ï¼Œå›¢å’Œå›¢ä¹‹é—´å¾ˆåˆ†æ•£

Calinski-Harabasz Index:
$$
\text{CH} = \frac{\text{BCSS}}{\text{WCSS}} \times \frac{N - k}{k - 1}
$$
- BCSS: between-cluster sum of squares
- WCSS: within-cluster sum of squares
- N: total number of data points
- k: number of clusters
- Higher values indicate better clustering quality

## Supervised Clustering evaluation
Homogeneity measures whether each **cluster contains only data points from a single true class**. If a cluster consists of instances that all belong to the same externally supplied label, the clustering is considered highly homogeneous. This can be evaluated using metrics like Entropy and Purity.
$$
homogenity = 1 - H(Ytrue|Ypred) / H(Ytrue)
$$

Completeness measures whether **all instances of a given true class are assigned to the same cluster**. A high completeness score means that the clustering effectively groups all instances of a particular class together in one cluster.
$$
completeness = 1 - H(Ypred|Ytrue) / H(Ypred)
$$
Homogeneity alone can be misleading. It only checks whether all instances within a cluster share the same label but does not ensure that instances of the same class are grouped together.


## Hierarchical Clustering

### Linkage Method
| **é“¾æ¥æ–¹æ³•**                     | **å®šä¹‰**                 | **ä¼˜ç‚¹**                           | **ç¼ºç‚¹**                                              | **é€‚ç”¨åœºæ™¯**                    |
| ---------------------------- | ---------------------- | -------------------------------- | --------------------------------------------------- | --------------------------- |
| **Single Linkage** ï¼ˆæœ€è¿‘è·ç¦»æ³•ï¼‰   | ä¸¤ä¸ªç°‡é—´è·ç¦»æ˜¯å®ƒä»¬æœ€æ¥è¿‘çš„ä¸¤ä¸ªç‚¹ä¹‹é—´çš„è·ç¦»  | - èƒ½å‘ç°ä»»æ„å½¢çŠ¶çš„ç°‡<br>- è®¡ç®—ç®€å•ï¼Œé€‚åˆå™ªå£°è¾ƒå°‘çš„æ•°æ®  | - å®¹æ˜“äº§ç”Ÿâ€œé“¾çŠ¶æ•ˆåº”â€ï¼ˆChaining effectï¼‰ï¼Œå¯¼è‡´ä¸è‡ªç„¶çš„é•¿æ¡å½¢ç°‡<br>- å¯¹å™ªå£°æ•æ„Ÿ | - å¸Œæœ›å‘ç°éçƒçŠ¶ç°‡æ—¶<br>- éœ€è¦è¿æ¥è¾ƒæ¾æ•£ç»“æ„æ—¶ |
| **Complete Linkage** ï¼ˆæœ€è¿œè·ç¦»æ³•ï¼‰ | ä¸¤ä¸ªç°‡é—´è·ç¦»æ˜¯å®ƒä»¬æœ€è¿œçš„ä¸¤ä¸ªç‚¹ä¹‹é—´çš„è·ç¦»   | - ç°‡å†…ç´§å¯†ï¼Œç°‡è¾¹ç•Œæ¸…æ™°<br>- æŠ‘åˆ¶é“¾çŠ¶æ•ˆåº”ï¼Œå¾—åˆ°è¾ƒç´§å‡‘çš„ç°‡ | - å¯¹ç¦»ç¾¤ç‚¹æ•æ„Ÿ<br>- å¯èƒ½å¯¼è‡´è¾ƒå°çš„ç°‡ï¼Œè¢«å­¤ç«‹çš„ç‚¹å¯èƒ½æ— æ³•åˆå¹¶                  | - éœ€è¦å¾—åˆ°ç´§å‡‘ã€åˆ†ç¦»è‰¯å¥½ç°‡æ—¶             |
| **Average Linkage** ï¼ˆå¹³å‡è·ç¦»æ³•ï¼‰  | ä¸¤ä¸ªç°‡é—´è·ç¦»æ˜¯ä¸¤ä¸ªç°‡æ‰€æœ‰ç‚¹å¯¹ä¹‹é—´è·ç¦»çš„å¹³å‡å€¼ | - æŠ˜ä¸­æ–¹æ³•ï¼Œé¿å…äº†æœ€è¿‘å’Œæœ€è¿œè·ç¦»æ³•çš„æç«¯<br>- ç¨³å®šæ€§è¾ƒå¥½ | - è®¡ç®—é‡å¤§ï¼Œå°¤å…¶æ•°æ®é‡å¤§æ—¶<br>- ç»“æœä¾èµ–äºç°‡å†…çš„ç‚¹åˆ†å¸ƒ                     | - éœ€è¦å¹³è¡¡ç°‡çš„ç´§å¯†æ€§å’Œåˆ†ç¦»æ€§æ—¶            |
| **Centroid Linkage** ï¼ˆè´¨å¿ƒè·ç¦»æ³•ï¼‰ | ä¸¤ä¸ªç°‡é—´è·ç¦»æ˜¯ä¸¤ä¸ªç°‡è´¨å¿ƒä¹‹é—´çš„è·ç¦»      | - è®¡ç®—å¿«é€Ÿ<br>- ç›´æ¥ä½¿ç”¨ç°‡ä¸­å¿ƒç‚¹(è¦è®¡ç®—å¾—å‡ºï¼šæ€»å’Œ/æ•°é‡)ï¼Œç›´è§‚æ˜“ç†è§£       | - å¯èƒ½å¯¼è‡´ç°‡åˆå¹¶åè´¨å¿ƒâ€œç§»åŠ¨â€ï¼Œå‡ºç°â€œé€†è½¬â€ç°è±¡ï¼ˆéå•è°ƒæ€§ï¼‰ï¼Œå¯¼è‡´ç»“æœä¸ç¨³å®š             | - å¯¹çƒçŠ¶ç°‡æ•ˆæœè¾ƒå¥½<br>- é€‚åˆå¯¹è´¨å¿ƒæ•æ„Ÿçš„åº”ç”¨  |


### Agglomerative Clustering
- bottom-up approach
- Start with each data point as a separate cluster
- Merge the two closest clusters until only one cluster remains

### Divisive Clustering
- top-down approach
- Start with one, all-inclusive cluster
- At each step, split a cluster until each cluster contains a point (or there are k clusters)


# Semi-Supervised Learning
utilizes a small set of labeled data together with a large amount of unlabeled data to improve model performance
## Self-Training
assume that **similar instances are likely to have the same label**
### ç®—æ³•æ­¥éª¤
1. Train the learner on the currently labeled instances.
2. Use the learner to predict the labels of the unlabeled instances.
3. Where the learner is very confident, add newly labeled instances to the training set.
4. Repeat until all instances are labeled, or no new instances can be labeled confidently.

### Confidence Threshold
- å¤ªä½ï¼šæ¨¡å‹ä¼šè¿‡åº¦æ‹Ÿåˆ å¯èƒ½ä¼šå¯¼è‡´é”™è¯¯æ ‡ç­¾çš„ä¼ æ’­ ä¸ç¨³å®š e.g. 0.4-0.5
- å¤ªé«˜ï¼šæ¨¡å‹ä¼šæ¬ æ‹Ÿåˆ å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹æ— æ³•å­¦ä¹ åˆ°æ­£ç¡®çš„æ ‡ç­¾ å­¦ä¹ é€Ÿåº¦å¾ˆæ…¢ e.g. over 0.8


## Active Learning
assume that **instances near class boundaries are the most informative for learning**, ask human to label the most informative instances

## Query Strategy
| **ç­–ç•¥åç§°**            | **æè¿°**                                                                 | **ä¼˜ç‚¹**                                      | **ç¼ºç‚¹**                                      |
| ------------------- | -------------------------------------------------------------------- | ----------------------------------------- | ----------------------------------------- |
| **ä¸ç¡®å®šæ€§é‡‡æ ·**        | é€‰æ‹©æ¨¡å‹æœ€ä¸ç¡®å®šçš„å®ä¾‹                                                        | - èƒ½å¤Ÿå¿«é€Ÿè¯†åˆ«æ¨¡å‹ä¸ç¡®å®šåŒºåŸŸ<br>- æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ› | - å¯èƒ½å¯¼è‡´è¿‡åº¦é‡‡æ ·ä¸ç¡®å®šåŒºåŸŸ<br>- éœ€è¦è®¡ç®—ä¸ç¡®å®šæ€§ |
| - æœ€ä¸è‡ªä¿¡          | é€‰æ‹©æœ€å¯èƒ½ç±»åˆ«çš„é¢„æµ‹æ¦‚ç‡æœ€å°çš„æ ·æœ¬(ä¸€è¡Œé‡Œé¢é€‰æœ€å¤§çš„åˆ—å’Œå…¶ä»–è¡Œé‡Œæœ€å¤§çš„åˆ—æ¯”ï¼Œé€‰æœ€å°)                                               | - ç®€å•æ˜“è¡Œ<br>- é€‚åˆäºŒåˆ†ç±»é—®é¢˜                  | - å¯¹å¤šåˆ†ç±»é—®é¢˜æ•ˆæœæœ‰é™                         |
| - è¾¹ç¼˜é‡‡æ ·          | é€‰æ‹©ä¸¤ä¸ªæœ€å¯èƒ½ç±»åˆ«æ¦‚ç‡å·®æœ€å°çš„æ ·æœ¬ï¼ˆé€‰ä¸€è¡Œé‡Œä¸¤åˆ—ç›¸å‡æœ€å°çš„ï¼‰                                               | - èƒ½æ›´å¥½åœ°å¤„ç†å¤šåˆ†ç±»é—®é¢˜                        | - è®¡ç®—å¤æ‚åº¦è¾ƒé«˜                              |
| - ç†µé‡‡æ ·            | é€‰æ‹©é¢„æµ‹æ¦‚ç‡ç†µå€¼æœ€é«˜çš„æ ·æœ¬                                                     | - èƒ½æ•æ‰æ•´ä½“ä¸ç¡®å®šæ€§ä¿¡æ¯                        | - è®¡ç®—å¤æ‚åº¦é«˜<br>- éœ€è¦ç†µçš„è®¡ç®—                |
| **å§”å‘˜ä¼šæŸ¥è¯¢**         | è®­ç»ƒå¤šä¸ªæ¨¡å‹åœ¨åŒä¸€æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œé€‰æ‹©æ¨¡å‹ä¹‹é—´å·®å¼‚æœ€å¤§çš„å®ä¾‹                        | - èƒ½å¤Ÿæ•æ‰æ¨¡å‹é—´çš„ä¸ä¸€è‡´æ€§<br>- æé«˜æ¨¡å‹çš„é²æ£’æ€§ | - éœ€è¦è®­ç»ƒå¤šä¸ªæ¨¡å‹<br>- è®¡ç®—å¤æ‚åº¦é«˜             |

# Ensemble Learning
works when:
- learners to correct each otherâ€™s mistake relies on the assumption of **errors being uncorrelated**
- The base classifiers are reasonably accurate (better than chance)

## Bagging
- involves training multiple instances of the same algorithm on different subsets of the data and averaging the predictions. å¹³å‡æ‰æ¯ä¸€ä¸ªæ¨¡å‹ æŠ•ç¥¨
- e.g. Random Forest

| ç‰¹æ€§                           | éšæœºæ£®æ—æè¿°                                |
| ---------------------------- | ------------------------------------- |
| æ ·æœ¬æ“ä½œ (instance manipulation) | ä½¿ç”¨ bootstrap æ–¹æ³•å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæœ‰æ”¾å›é‡‡æ ·ï¼Œç”Ÿæˆå¤šæ£µæ ‘çš„è®­ç»ƒé›† |
| ç‰¹å¾æ“ä½œ (feature manipulation)  | æ¯ä¸ªèŠ‚ç‚¹éšæœºé€‰æ‹©ä¸€éƒ¨åˆ†ç‰¹å¾ï¼Œå¢å¼ºæ¨¡å‹å¤šæ ·æ€§                 |
| æ–¹å·® vs åå·®                     | ä¸»è¦é™ä½æ–¹å·®ï¼ˆå‡å°‘è¿‡æ‹Ÿåˆï¼‰ï¼Œå¯¹åå·®å½±å“ä¸å¤§                 |
| å•æ£µæ ‘çš„å¯è§£é‡Šæ€§                     | é«˜ï¼Œå¯ä»¥æ¸…æ¥šåœ°è§£é‡Šé¢„æµ‹è·¯å¾„                         |
| æ•´ä½“æ¨¡å‹çš„å¯è§£é‡Šæ€§                    | è¾ƒä½ï¼Œéš¾ä»¥è§£é‡Šå¤šä¸ªæ ‘æŠ•ç¥¨çš„æ•´ä½“é¢„æµ‹é€»è¾‘                   |


## Stacking
- combines multiple models (often of different types) into a meta-model to learn how to best combine the predictions. æŠŠæ¯ä¸€ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœä½œä¸ºè¾“å…¥ï¼Œè®­ç»ƒä¸€ä¸ªmeta-modelæ¥å­¦ä¹ å¦‚ä½•æœ€å¥½åœ°ç»“åˆè¿™äº›é¢„æµ‹ç»“æœ
   - After the base classifiers have been trained on the training set, they are used to make predictions on the validation set. The meta-classifier then uses these predictions as input to learn how to combine them in order to make an overall prediction.
   - The meta-classifier is trained on the validation set, using the predictions from the base classifiers as input, and the true labels of the validation set as the target variable

## Boosting
- involves adding ensemble members sequentially that correct the predictions made by prior models and outputs a weighted average of the predictions é¡ºåºè®­ç»ƒ ä¸€ä¸ªæ¨¡å‹ä¿®å¤ä¸Šä¸€ä¸ªæ¨¡å‹çš„é”™è¯¯
- higher weights to better-performing base learners è¡¨ç°å¥½çš„æ¨¡å‹æƒé‡æ›´é«˜



# Anomaly Detection
Supervised methods require labeled datasets containing **both normal and anomalous instances** to train predictive models.

Unsupervised methods, on the other hand, do **not require labeled data** and instead identify anomalies based on deviations from learned patterns in the data.

Semi-supervised methods use a combination of **labeled and unlabeled data** to build models that can detect anomalies.

| æ–¹æ³•ç±»åˆ«                        | æ ¸å¿ƒæ€æƒ³                 | å…¸å‹ç®—æ³•/ç¤ºä¾‹                              | ä¼˜åŠ¿             | å±€é™              |
| --------------------------- | -------------------- | ------------------------------------ | -------------- | --------------- |
| **Proximity-based**ï¼ˆåŸºäºè·ç¦»ï¼‰   | å¼‚å¸¸ç‚¹ä¸å…¶ä»–ç‚¹è·ç¦»è¾ƒè¿œ          | k-NN å¼‚å¸¸æ£€æµ‹ã€LOF (Local Outlier Factor) | æ˜“ç†è§£ï¼Œç›´è§‚æœ‰æ•ˆ       | å¯¹é«˜ç»´æ•°æ®æ•ˆæœå·®ï¼Œä¾èµ–è·ç¦»åº¦é‡ |
| **Statistical-based**ï¼ˆåŸºäºç»Ÿè®¡ï¼‰ | å¼‚å¸¸å€¼åç¦»æ€»ä½“çš„ç»Ÿè®¡åˆ†å¸ƒï¼ˆå¦‚å‡å€¼ã€æ–¹å·®ï¼‰ | z-score, Grubbs' test, Gaussianæ¨¡å‹    | ç†è®ºæ‰å®ï¼Œé€‚åˆæ•°å€¼å‹æ•°æ®   | ä¾èµ–åˆ†å¸ƒå‡è®¾ï¼Œå¯¹éæ­£æ€åˆ†å¸ƒæ— æ•ˆ |
| **Density-based**ï¼ˆåŸºäºå¯†åº¦ï¼‰     | å¼‚å¸¸ç‚¹æ‰€å¤„åŒºåŸŸå¯†åº¦æ˜æ˜¾ä½äºå…¶ä»–ç‚¹     | LOF, DBSCAN, Isolation Forestï¼ˆéƒ¨åˆ†ï¼‰    | èƒ½å‘ç°å±€éƒ¨å¼‚å¸¸ï¼Œé€‚åˆå¤æ‚æ•°æ® | å¯†åº¦ä¼°è®¡æˆæœ¬è¾ƒé«˜ï¼Œå‚æ•°æ•æ„Ÿ   |
| **Clustering-based**ï¼ˆåŸºäºèšç±»ï¼‰  | å¼‚å¸¸ç‚¹ä¸å±äºä»»ä½•èšç±»æˆ–ç¦»èšç±»ä¸­å¿ƒå¾ˆè¿œ   | K-Means, DBSCAN, K-Medoids           | æ˜“äºå¯è§†åŒ–ï¼Œèƒ½ç»“åˆæ— ç›‘ç£å­¦ä¹  | èšç±»è´¨é‡å½±å“å¤§ï¼Œéš¾å¤„ç†å°ç°‡å¼‚å¸¸ |


#### Semi-supervised Learning â€“ Good for ambiguous cases (e.g., platypus)
- Train a classifier (e.g., Naive Bayes, Logistic Regression) on known animal categories.
- Identify anomalies by looking at:
  - **High-entropy predictions**: e.g., platypusé¸­å˜´å…½ = 35% mammal, 35% bird, 30% amphibian.
  - **Low-confidence predictions** across all classes: e.g., dragon.
- To improve reliability:
  - Use an **ensemble of classifiers**.
  - Flag instances where multiple models show uncertainty.

#### Unsupervised Learning â€“ Best for true anomalies (e.g., dragon)
- Ignore labels; use clustering methods (e.g., K-means).
- Flag animals that:
  - Are **far from all cluster centroids**.
  - Form **small or isolated clusters**.
- Improve robustness:
  - Run clustering multiple times with different `K` values and seeds.
  - Use **voting** or **aggregate distance scores** to decide anomalies.

# Fairness
- Equal Opportunity: å¯¹äºæ‰€æœ‰çœŸå®æ ‡ç­¾ä¸ºæ­£ç±»ï¼ˆy = 1ï¼‰çš„äººï¼Œä¸è®ºå…¶å±äºå“ªä¸ªå—ä¿æŠ¤ç¾¤ä½“ï¼Œéƒ½æœ‰ç›¸åŒçš„è¢«æ¨¡å‹é¢„æµ‹ä¸ºæ­£ç±»ï¼ˆÅ· = 1ï¼‰çš„æ¦‚ç‡ã€‚
- Predictive Parity: model provides similar predictive outcomes for all demographic groups
# å¸¸è§è®¡ç®—æŒ‡æ ‡ (Common Metrics)

## è·ç¦»åº¦é‡ (Distance Metrics)

### 1. æ¬§å‡ é‡Œå¾—è·ç¦» (Euclidean Distance)
æœ€å¸¸ç”¨çš„è·ç¦»åº¦é‡ï¼Œè®¡ç®—ä¸¤ç‚¹é—´çš„ç›´çº¿è·ç¦»
$$d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}$$

**ä¾‹å­**: ç‚¹A(1,2), ç‚¹B(4,6)
$$d(A,B) = \sqrt{(1-4)^2 + (2-6)^2} = \sqrt{9 + 16} = 5$$

### 2. æ›¼å“ˆé¡¿è·ç¦» (Manhattan Distance)
ä¹Ÿå«åŸå¸‚è¡—åŒºè·ç¦»ï¼Œè®¡ç®—å„ç»´åº¦å·®å€¼çš„ç»å¯¹å€¼ä¹‹å’Œ
$$d(x, y) = \sum_{i=1}^{n} |x_i - y_i|$$

**ä¾‹å­**: ç‚¹A(1,2), ç‚¹B(4,6)
$$d(A,B) = |1-4| + |2-6| = 3 + 4 = 7$$


- å½“ p=1 æ—¶ï¼Œå°±æ˜¯æ›¼å“ˆé¡¿è·ç¦»
- å½“ p=2 æ—¶ï¼Œå°±æ˜¯æ¬§å‡ é‡Œå¾—è·ç¦»

### 3. ä½™å¼¦ç›¸ä¼¼åº¦ (Cosine Similarity)
è®¡ç®—ä¸¤ä¸ªå‘é‡å¤¹è§’çš„ä½™å¼¦å€¼ï¼Œå€¼è¶Šå¤§è¶Šç›¸ä¼¼
$$\cos(\theta) = \frac{A \cdot B}{\|A\| \|B\|} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \sqrt{\sum_{i=1}^{n} B_i^2}}$$

**ä½™å¼¦è·ç¦»**: $d = 1 - \cos(\theta)$

**ä¾‹å­**: å‘é‡A(3,4), å‘é‡B(1,2)
- ç‚¹ç§¯: $A \cdot B = 3Ã—1 + 4Ã—2 = 11$
- æ¨¡é•¿: $\|A\| = \sqrt{3^2 + 4^2} = 5$, $\|B\| = \sqrt{1^2 + 2^2} = \sqrt{5}$
- ä½™å¼¦ç›¸ä¼¼åº¦: $\cos(\theta) = \frac{11}{5\sqrt{5}} = \frac{11}{5\sqrt{5}} â‰ˆ 0.982$


---

## åˆ†ç±»è¯„ä¼°æŒ‡æ ‡ (Classification Metrics)

### åŸºç¡€æŒ‡æ ‡
ä»æ··æ·†çŸ©é˜µè®¡ç®—ï¼š
- **å‡†ç¡®ç‡ (Accuracy)**: $\frac{TP + TN}{TP + TN + FP + FN}$
- **ç²¾ç¡®ç‡ (Precision)**: $\frac{TP}{TP + FP}$ (é¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­çœŸæ­£ä¸ºæ­£çš„æ¯”ä¾‹)
- **å¬å›ç‡ (Recall/Sensitivity)**: $\frac{TP}{TP + FN}$ (çœŸæ­£ä¸ºæ­£çš„æ ·æœ¬ä¸­è¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹)
- **ç‰¹å¼‚æ€§ (Specificity)**: $\frac{TN}{TN + FP}$ (çœŸæ­£ä¸ºè´Ÿçš„æ ·æœ¬ä¸­è¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹)
- **F1åˆ†æ•°**: $F_1 = \frac{2 \times Precision \times Recall}{Precision + Recall}$

### å¤šåˆ†ç±»è¯„ä¼°
- **å®å¹³å‡ (Macro Average)**: æ¯ä¸ªç±»åˆ«å•ç‹¬è®¡ç®—æŒ‡æ ‡ï¼Œç„¶åå–å¹³å‡
- **å¾®å¹³å‡ (Micro Average)**: å°†æ‰€æœ‰ç±»åˆ«çš„TPã€FPã€FNæ±‡æ€»åè®¡ç®—
- **åŠ æƒå¹³å‡ (Weighted Average)**: æŒ‰å„ç±»åˆ«æ ·æœ¬æ•°é‡åŠ æƒå¹³å‡

---

## å›å½’è¯„ä¼°æŒ‡æ ‡ (Regression Metrics)

### 1. å‡æ–¹è¯¯å·® (MSE - Mean Squared Error)
$$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

### 2. å‡æ–¹æ ¹è¯¯å·® (RMSE - Root Mean Squared Error)
$$RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$

### 3. å¹³å‡ç»å¯¹è¯¯å·® (MAE - Mean Absolute Error)
$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$

---


## Z-Score
$$Z = \frac{X - \mu}{\sigma}$$

## Standard Deviation
$$
\sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2}
$$

