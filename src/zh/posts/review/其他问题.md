---
icon: pen-to-square
date: 2025-07-24
category:
  - Learning Records
tag:
  - Review
---

# 其他问题

## MySQL Buffer Pool里都有什么？
MySQL 的 Buffer Pool（缓冲池）是 InnoDB 存储引擎中**最核心的内存区域**，主要用于缓存磁盘上的数据页，加速数据读写。

| 类型                | 说明/作用                         |
|-------------------|-------------------------------|
| 数据页（Data Page）     | 存储表的实际数据行                   |
| 索引页（Index Page）    | 存储 B+ 树索引节点                   |
| Undo 页             | 存储回滚日志，支持事务和 MVCC           |
| Change Buffer 页      | 缓存二级索引的变更操作，提升插入效率         |
| 自适应哈希索引         | 热点数据自动生成哈希索引，加速查询           |
| 锁信息               | 记录锁定信息，支持并发控制                |
| 数据字典信息           | 缓存表结构、索引结构等元数据               |


## Redis底层相关数据结构了解吗？

| 底层结构       | 主要用途/描述                | 典型应用类型         | 优点                         | 缺点                      | 适用场景/切换条件                  |
|--------------|-------------------------|------------------|----------------------------|-------------------------|-----------------------------|
| SDS          | 动态字符串存储                | string、key      | 安全高效，支持二进制（图片），长度可变         | 仅适合字符串             | 所有字符串、key 名称               |
| ziplist      | 紧凑连续内存，存小对象           | list、hash、zset | 占用内存小，遍历快                 | 插入/删除慢，数据多时效率低      | 元素数量少且小（如list<8、元素<64B）|
| listpack     | 新一代紧凑结构，比ziplist更高效    | stream、list     | 更省空间，结构简单                  | 只适合小数据量             | stream entries、list小数据量        |
| quicklist    | ziplist/listpack链表混合体        | list            | 插入/删除快，遍历快，省内存           | 结构复杂                  | list主力实现，数据量大或有频繁操作   |
| intset       | 整数集合，内存连续              | set             | 占用小，查找快                     | 只支持整数，数量有限         | set全为整数且数量少（<512）         |
| dict         | 哈希表，key-value结构           | hash、set、zset  | 查找/插入/删除快，扩容灵活             | 内存占用大，哈希冲突需处理      | hash/大set/zset、key管理           |
| skiplist     | 多层链表，支持有序和范围查找        | zset            | 查找/插入/删除O(logN)，有序遍历快        | 内存占用大，结构复杂          | zset大数据量，需排序/范围查找        |
| 链表         | 节点指针串联，插入/删除快          | 早期list         | 插入/删除快，双向遍历                 | 内存碎片多，查找慢            | 早期list实现，现已被quicklist替代     |
| bitmap       | 位数组，布尔状态存储             | 签到、活跃统计     | 占用极小，适合大规模布尔统计             | 只适合0/1状态，操作需位运算      | 签到、活跃用户、布隆过滤器           |
| HyperLogLog  | 概率型基数统计                  | UV（Unique Visitor）、去重         | 极省内存，统计大规模唯一数               | 只能估算，不能存具体元素        | UV、去重计数                      |

- **压缩结构（ziplist、listpack）**：适合小数据量，省空间。
- **链表/quicklist/skiplist**：适合大数据量，插入/删除/查找高效。
- **dict/intset**：哈希表和整数集合，分别适合大/小数据量的hash、set。
- **bitmap/HyperLogLog**：特殊统计场景，极省内存。
- **SDS**：所有字符串和key的底层实现。

## 可以基于UDP实现可靠通信吗？HTTP3知道吗？

虽然 UDP（User Datagram Protocol）本身是**无连接、不可靠**的协议（不保证数据到达、不保证顺序、不重传），但**可以在应用层或传输层之上，通过额外机制实现可靠通信**，常见方法有：

- **序列号**：每个数据包加上序号，接收方可检测丢包、乱序。
- **确认应答（ACK）**：接收方收到数据后回发确认，发送方未收到ACK则重传。
- **超时重传**：发送方在超时未收到ACK时重发数据包。
- **滑动窗口**：支持流量控制和有序传输。
- **校验和**：保证数据完整性。
- **拥塞控制**：防止网络拥堵。

**实际例子**：  
- 许多实时音视频、游戏、定制协议（如 TFTP、QUIC）都在 UDP 上实现了可靠性机制。
- 你可以把“可靠的UDP”理解为“自定义的TCP”。

**HTTP/3 就是基于 UDP 实现可靠通信的典型代表。**

- **HTTP/3** 是新一代 HTTP 协议，底层基于 **QUIC** 协议。
- **QUIC**（Quick UDP Internet Connections）是 Google 推出的基于 UDP 的传输层协议，**实现了可靠传输、拥塞控制、顺序保证、加密等功能**，本质上是“用UDP实现的更快的TCP+TLS”。
- HTTP/3 用 QUIC 替代了 TCP，解决了 TCP 的队头阻塞、慢启动等问题，连接建立更快，抗丢包能力更强，适合现代互联网和移动场景。

**UDP 本身不可靠，但可以通过协议设计实现可靠通信。**

**HTTP/3 就是用 UDP + QUIC 实现可靠、高效、安全的 Web 通信。**


## 项目是基于HTTP吗，为什么要基于HTTP来做，TCP不行吗？
| 对比项         | HTTP（基于TCP之上的应用层协议）         | 直接用TCP（传输层协议）           |
|--------------|------------------------------------|-------------------------------|
| 协议层级        | 应用层（基于TCP）                        | 传输层                         |
| 通用性/标准化     | 标准化，全球通用，跨平台、跨语言                | 需自定义协议，通用性差                |
| 开发难度        | 易用，框架/工具丰富，开发效率高                  | 需自行处理数据格式、分包、粘包、重传等，开发难度大 |
| 兼容性         | 浏览器、APP、API、第三方服务等原生支持             | 需自定义客户端/服务端，兼容性差           |
| 网络穿透        | 80/443端口易穿透防火墙/代理                    | 其他端口常被封锁，穿透难                 |
| 安全性         | 支持HTTPS（加密、认证），安全性高                  | 需自定义加密/认证，安全性难保障            |
| 生态/工具       | 丰富（Postman、curl、API网关、负载均衡等）         | 工具少，需自研                         |
| 适用场景        | Web开发、API、微服务、移动端、第三方集成等           | 游戏、物联网、金融等高性能/定制场景         |
| 典型应用        | 网站、RESTful API、微服务、Web应用等                | 游戏服务器、实时通信、专用协议等            |

- **HTTP**：开发效率高、通用性强、易于集成和维护，是Web和API开发的首选。
- **TCP**：更底层，适合对性能、实时性有极高要求且能自定义协议的特殊场景。
- **绝大多数项目选HTTP，是因为它标准化、易用、安全、兼容性好，极大提升开发效率和系统可维护性。**

## 如果要在分布式中保持强一致性和最终一致性分别有什么做法？

### 一、强一致性（Strong Consistency）

**定义**：  
所有节点对同一份数据的读写顺序一致，任何时刻读到的数据都是最新的，像单机一样。

**常见实现方式：**

| 方案/协议         | 简要说明                                               | 典型应用场景           |
|----------------|----------------------------------------------------|-------------------|
| 两段式提交（2PC）    | 事务协调者分两阶段通知所有参与者提交或回滚，保证所有节点要么都成功要么都失败         | 分布式数据库、分布式事务   |
| 三段式提交（3PC）    | 在2PC基础上增加预提交阶段，进一步降低阻塞风险                         | 理论为主，实际较少用      |
| Paxos/Raft等一致性协议 | 多节点投票达成一致后再提交，保证分布式系统状态同步                         | 分布式一致性存储、分布式锁 |
| 分布式锁           | 通过ZooKeeper、Redis等实现全局锁，保证同一时刻只有一个节点能操作关键资源           | 订单扣减、唯一性约束      |
| 单主写入           | 只允许一个主节点写入，其他节点只读，保证写入顺序一致                           | 主从数据库、分布式缓存    |

### 二、最终一致性（Eventual Consistency）

**定义**：  
系统不要求实时一致，只要经过一段时间，所有节点最终能达到一致状态。

**常见实现方式：**

| 方案/协议         | 简要说明                                               | 典型应用场景           |
|----------------|----------------------------------------------------|-------------------|
| 消息队列+异步补偿     | 业务操作先写本地，异步通过消息队列通知其他系统，失败后可重试或补偿                 | 电商订单、库存扣减      |
| TCC（Try-Confirm-Cancel） | 业务分为三步：预留资源、确认提交、取消补偿，允许部分失败后补偿                    | 金融、支付、库存等      |
| Saga模式         | 将大事务拆分为多个本地事务，每步有补偿操作，保证最终一致性                           | 微服务长事务           |
| 本地消息表         | 业务操作和消息写入同一数据库事务，消息异步投递，保证消息可靠送达                     | 订单、支付等           |
| 定时任务/对账       | 定期扫描、对账、补偿，修正不一致的数据                                   | 账务、积分、库存等      |

### 总结

| 一致性类型   | 典型方案/协议           | 适用场景/特点                  |
|----------|--------------------|---------------------------|
| 强一致性    | 2PC、3PC、Paxos、Raft、分布式锁 | 事务性强、金融、订单、核心数据         |
| 最终一致性   | 消息队列、TCC、Saga、本地消息表、定时补偿 | 高可用、可容忍短暂不一致、异步业务场景    |


## Redis的事务了解吗，Redis的事务和MySQL的事务最大的区别在什么地方？
### 1. Redis 的事务

- **基本命令**：MULTI（开启事务）、EXEC（提交事务）、DISCARD（放弃事务）、WATCH（乐观锁）。
- **执行方式**：  
  - MULTI 后输入的一系列命令会被依次入队，等 EXEC 时一次性、顺序性地执行。
  - 事务中的命令**不会中途打断**，但也**不会回滚**。
- **特性**：
  - **原子性**：事务内的命令要么全部执行，要么都不执行（如果用 DISCARD 放弃）。
  - **不保证隔离性**：事务执行前后，其他客户端可以修改数据（除非用 WATCH 实现乐观锁）。
  - **无回滚**：事务中某条命令出错（如语法错），整个事务会被丢弃；但如果是运行时错误（如类型错误），其他命令仍会执行，**不会回滚**。
  - **不支持持久锁定**：没有行级锁、表级锁。

### 2. MySQL 的事务

- **基本命令**：BEGIN/START TRANSACTION、COMMIT、ROLLBACK。
- **执行方式**：  
  - 事务内的 SQL 语句在提交前对外不可见，提交后才生效。
- **特性**（ACID）：
  - **原子性**（Atomicity）：要么全部成功，要么全部失败。
  - **一致性**（Consistency）：事务前后数据完整性不被破坏。
  - **隔离性**（Isolation）：并发事务互不干扰（支持多种隔离级别）。
  - **持久性**（Durability）：提交后数据永久保存。

### 3. 最大区别

| 对比项         | Redis 事务                         | MySQL 事务                         |
|--------------|----------------------------------|----------------------------------|
| 原子性         | 只保证命令队列的原子性，不保证单条命令的原子性 | 保证整个事务的原子性                    |
| 隔离性         | 无法保证，除非用 WATCH 实现乐观锁           | 支持多种隔离级别，强隔离性                  |
| 回滚/错误处理     | 不支持回滚，命令出错不会自动撤销已执行命令      | 支持回滚，出错可撤销整个事务                  |
| 持久性         | 依赖持久化配置（RDB/AOF），不如MySQL强         | 强持久性，写入磁盘保证数据不丢失                |
| 锁机制         | 无锁，乐观锁（WATCH）                   | 支持行锁、表锁等多种锁机制                    |
| 适用场景        | 高性能、简单原子操作、缓存、计数等             | 复杂业务逻辑、强一致性要求的数据操作               |

**一句话总结**：  
> Redis 事务不支持回滚和强隔离，主要保证命令的批量顺序执行；MySQL 事务支持完整的ACID特性，能保证强一致性和回滚，是“真正的数据库事务”。

## 毒性反转是什么？是哪一层的概念？

**毒性反转**（Poison Reverse）是一种用于**防止路由环路**的机制，常见于**距离矢量路由协议**（如RIP）。

- 当路由器A通过路由器B到达某个网络X时，A会告诉B：“我到X的距离是无穷大（不可达）”，即“把这条路‘毒死’”。
- 这样可以防止B再把到X的路由信息传回A，避免A、B之间形成路由环路。
- **属于网络层（第三层，Network Layer**的路由协议机制。
- 主要用于RIP等距离矢量型路由协议。

**简要记忆**：  
毒性反转是网络层的路由环路防止机制，常用于RIP协议。

## 死锁和OOM如何排查

| 问题类型 | 排查工具/方法                  | 关键点/建议                         |
|--------|--------------------------|-------------------------------|
| 死锁    | jstack、jconsole、Arthas、日志分析 | 查锁等待链、加锁顺序、避免嵌套锁、可视化分析      |
| OOM    | jmap、jvisualvm、MAT、GC日志      | 导出堆快照、分析大对象/泄漏、优化内存参数、代码审查 |

## 布隆过滤器的原理？什么情况下是误判？
- **布隆过滤器（Bloom Filter）**是一种**空间效率极高的概率型数据结构**，用于判断一个元素是否在集合中。
  - 结构：一个很长的二进制位数组（bit array）+ 多个独立的哈希函数。
- **添加元素**：将元素分别用k个哈希函数计算，得到k个位置，把这些位置的bit都置为1。
- **查询元素**：同样用k个哈希函数计算k个位置，只要有一个bit为0，说明元素一定不在集合中；如果都为1，则“可能在集合中”。
- **误判（假阳性，False Positive）**：布隆过滤器可能会把“不在集合中的元素”误判为“在集合中”。
- 原因：不同元素经过哈希后可能落在同一组bit上，导致查询时所有bit都为1，但其实这些1是其他元素置的。
- **不会出现“假阴性”**：即不会把“实际在集合中的元素”误判为“不在集合中”。

**简要记忆**：  
布隆过滤器通过多个哈希函数和位数组判断元素是否存在，可能出现“误判存在”，但不会漏判已存在的元素。

## JWT组成部分有哪些，怎么配合拦截器实现校验和刷新的，拦截器是怎么做的？

| 步骤         | 说明/作用                         |
|------------|-------------------------------|
| JWT组成      | Header、Payload、Signature    |
| 校验流程      | 拦截器获取token，校验签名和过期，放行或拒绝 |
| 刷新机制      | 检查token快过期时刷新，或用refresh token换新token |
| 拦截器实现     | preHandle中解析校验token，失败返回401/403 |

| 项目类型               | 推荐用法                    | 原因/说明          |
| ------------------ | ----------------------- | -------------- |
| 不用 Spring Security | 拦截器（HandlerInterceptor） | 简单好用，控制请求前置逻辑  |
| 用 Spring Security  | 自定义过滤器（Filter）          | 更标准，能控制认证与授权流程 |

- 如果你用了 Spring Security，那应该在过滤器链中处理 JWT，因为：
  - 拦截器晚于过滤器执行，无法控制 Spring Security 的认证过程
  - Spring Security 本身就有过滤器链机制，用来处理认证、授权、异常等


> JWT由Header、Payload、Signature三部分组成。拦截器通过解析和校验JWT实现接口安全控制，并可结合刷新机制保证用户体验和安全。拦截器一般在preHandle中校验token，校验通过放行，否则拒绝访问。

## 拦截器和过滤器有什么区别？

| 对比项     | 过滤器（Filter）                | 拦截器（Interceptor）           |
|----------|----------------------------|---------------------------|
| 所属层级    | Servlet规范/容器                | Web框架（如Spring MVC）         |
| 作用范围    | 所有请求（包括静态资源）             | 仅Controller相关请求            |
| 典型用途    | 编码、日志、权限、XSS、CORS等         | 登录校验、权限、业务日志、数据预处理等    |
| 实现接口    | javax.servlet.Filter           | org.springframework.web.servlet.HandlerInterceptor |
| 配置方式    | web.xml/@WebFilter注解           | Spring配置类/注解               |
| 执行时机    | Servlet前后                   | Controller前后                 |
| 静态资源拦截  | 可以                         | 默认不拦截                     |

**简要记忆**：  
- **过滤器**：Servlet层，作用广，适合通用处理。  
- **拦截器**：框架层，作用于业务控制，适合业务相关的请求处理。

| 阶段         | 类型                     | 方法 / 行为       |
| ---------- | ---------------------- | ------------- |
| 请求到达服务器    |                        |               |
| 🚦 过滤器前置处理 | `Filter#doFilter()`（前） | 比拦截器先执行       |
| 🛡 拦截器前置处理 | `preHandle()`          | 控制请求是否继续      |
| 🧭 控制器方法执行 | `@Controller`          | 业务逻辑处理        |
| 🛡 拦截器后置处理 | `postHandle()`         | 控制器执行完但视图未渲染  |
| 🛡 拦截器完成处理 | `afterCompletion()`    | 请求完全结束，适合释放资源 |
| 🚦 过滤器收尾处理 | `Filter#doFilter()`（后） | 最后执行          |
| 响应返回客户端        |                        |               |

## ThreadLocalMap 的 key 为什么是弱引用？
- **防止内存泄漏**。
- ThreadLocalMap 的 key 是 ThreadLocal 对象的弱引用（WeakReference），value 是强引用。
- 如果 key（ThreadLocal对象）没有外部强引用，GC 时会被回收，避免 ThreadLocal 对象“遗留”在 ThreadLocalMap 里，导致 value 永远无法访问和回收，造成内存泄漏。

- 如果 key 是强引用，即使外部不再使用 ThreadLocal 对象，ThreadLocalMap 还持有它，GC 也不会回收，value 也不会被清理，**内存泄漏风险极大**。
- 用弱引用后，ThreadLocal 对象没外部引用时，key 会被GC回收，ThreadLocalMap 里的 entry 的 key 变成 null，虽然 value 还在，但下次访问/设置/扩容时会自动清理这些“key为null”的 entry，释放 value。

| 设计点         | 作用/好处                         |
|--------------|-------------------------------|
| key用弱引用      | ThreadLocal对象无引用时能被GC回收，防止内存泄漏 |
| value用强引用    | 保证数据可用，直到手动remove或key被回收         |

> ThreadLocalMap 的 key 用弱引用，是为了防止 ThreadLocal 对象失去外部引用后无法被GC，避免内存泄漏。ThreadLocalMap 的 key 用弱引用能缓解但不能彻底避免内存泄漏，正确做法是用完 ThreadLocal 后及时 remove()。


## MySQL锁的原理

### 1. MySQL 常见锁类型

| 锁类型         | 说明/作用                         | 典型应用场景           |
|--------------|-------------------------------|-------------------|
| 全局锁         | 锁住整个数据库实例                   | 备份、维护等           |
| 表级锁         | 锁住整张表                         | MyISAM、DDL操作      |
| 行级锁         | 锁住单行数据                         | InnoDB、事务操作      |
| 意向锁         | 标记表中某些行将被加锁，辅助行锁管理           | InnoDB              |
| 间隙锁         | 锁定索引区间，防止幻读                   | InnoDB、可重复读隔离级别 |
| 临键锁         | 行锁+间隙锁的组合，防止插入/幻读              | InnoDB              |

### 2. 不同存储引擎的锁实现

#### MyISAM（表级锁）

- 只支持表级锁（读锁、写锁），不支持行级锁。
- 读写互斥，写锁独占，适合读多写少场景。

#### InnoDB（行级锁、表级锁、意向锁、间隙锁）

- **行级锁**：通过索引实现，锁定某一行数据，支持高并发。
- **表级锁**：如`LOCK TABLES`命令。
- **意向锁**：事务加行锁前，先加意向锁，标记本事务要对哪些行加锁，便于表锁和行锁兼容。
- **间隙锁/临键锁**：**防止幻读**，锁定索引区间，保证可重复读。

### 3. 行级锁的实现原理（InnoDB）

- **基于索引实现**：InnoDB 的行锁是加在索引上的，而不是加在物理行上。
- **加锁方式**：
  - **共享锁（S锁）**：允许多个事务读同一行，不能写。
  - **排他锁（X锁）**：允许事务修改/删除一行，其他事务不能读写。
- **加锁粒度**：
  - 精确到索引记录，非索引列加锁会退化为表锁。
- **锁的存储**：
  - InnoDB 通过**锁信息结构**在内存中维护锁状态，挂在事务对象上。

### 4. 间隙锁/临键锁的实现原理

- **间隙锁（Gap Lock）**：锁定一个区间，防止其他事务在该区间插入新记录，解决幻读问题。
- **临键锁（Next-Key Lock）**：锁定当前索引记录+区间，防止并发插入/幻读。
- 只有在 **可重复读（REPEATABLE READ）**隔离级别下才会自动加间隙锁/临键锁。

### 5. 意向锁的实现原理

- **表级的标记锁**，用于标记事务将要对表中哪些行加锁。
- 便于表锁和行锁的兼容与冲突检测，提高加锁效率。

### 6. 死锁检测与处理

- InnoDB 支持**自动死锁检测**，发现死锁会主动回滚部分事务，释放锁资源。

### 总结

| 锁类型     | 实现方式/原理                | 适用场景/优缺点                |
|----------|------------------------|--------------------------|
| 表级锁     | MyISAM/DDL，整表加锁         | 实现简单，粒度大，冲突多，适合读多写少      |
| 行级锁     | InnoDB，基于索引加锁          | 粒度小，支持高并发，开销大，死锁风险        |
| 意向锁     | 表级标记，辅助行锁管理         | 提高加锁效率，便于表锁与行锁兼容           |
| 间隙锁/临键锁 | 锁定索引区间，防止幻读           | 解决幻读，影响并发性能，只有可重复读隔离级别下用 |

> MySQL 锁分为表级锁、行级锁、意向锁、间隙锁等。InnoDB 的行锁是基于索引实现的，支持高并发和事务隔离。间隙锁和临键锁用于防止幻读。意向锁用于优化表锁和行锁的兼容。InnoDB 支持自动死锁检测和回滚。

## 深拷贝和浅拷贝的区别？

| 拷贝类型   | 含义                                                         | 影响/特点                      |
|---------|------------------------------------------------------------|----------------------------|
| 浅拷贝   | 只复制对象的**引用**，不复制引用对象本身。新对象和原对象**共享内部子对象**。           | 改变子对象会互相影响，顶层对象是新，底层对象是同一个 |
| 深拷贝   | 复制对象**以及其引用的所有子对象**，完全独立。新对象和原对象**没有任何共享部分**。      | 改变任何一方都不会影响另一方，完全独立           |

- **浅拷贝**：适合对象结构简单、内部无可变引用类型，或只需复制顶层对象时。
- **深拷贝**：适合对象复杂、包含可变引用类型，且需要完全独立副本时。

> 浅拷贝只复制引用，深拷贝连引用对象本身都复制，深拷贝更彻底，互不影响。

## 知道协程吗？

| 对比项     | 进程（Process）         | 线程（Thread）           | 协程（Coroutine）         |
|----------|---------------------|---------------------|----------------------|
| 概念      | 操作系统资源分配的最小单位  | 程序执行的最小单位，属于进程 | 用户态的轻量级线程/可暂停函数 |
| 是否有独立内存 | 有，进程间内存隔离         | 共享进程内存空间           | 共享线程/进程内存空间      |
| 创建/切换开销 | 最大                  | 较大                  | 极小（用户态切换）         |
| 调度方式    | 操作系统调度             | 操作系统调度             | 程序/用户态调度           |
| 通信方式    | 进程间通信（IPC）         | 共享内存、同步机制         | 共享内存、消息传递         |
| 并发性     | 真并发（多核可并行）        | 真并发（多核可并行）        | 单线程内并发（伪并发）      |
| 适用场景    | 高隔离、高可靠、独立服务      | 高并发、并行计算           | 高并发、IO密集、异步编程     |
| 数量      | 少（资源消耗大）           | 多（受限于系统资源）         | 可成千上万（极轻量）        |
| 典型语言/支持 | 所有操作系统             | 所有主流语言/系统           | Python、Go、JS等原生支持    |

- **进程**：最重，资源隔离最强，开销最大，适合独立服务。
- **线程**：比进程轻，能并发执行，资源共享，适合并行计算。
- **协程**：最轻，用户态切换，适合高并发、IO密集，单线程内实现并发。

> 进程最重，线程较轻，协程最轻；进程/线程由操作系统调度，协程由程序调度，协程适合高并发和异步场景。


## Spring中事务嵌套事务是怎么处理的？
- Spring 通过**事务传播行为（Propagation）**来控制“事务中套事务”的行为。
- 常见传播属性：
  - `REQUIRED`（默认）：如果当前有事务，就加入当前事务；没有就新建一个事务。
  - `REQUIRES_NEW`：每次都新建一个新事务，原事务挂起。
  - `NESTED`：嵌套事务，内层回滚不影响外层（需底层数据库支持）。
  - 其他还有 SUPPORTS、NOT_SUPPORTED、MANDATORY、NEVER 等。

### 如何保证事务不会出问题？

#### 1）同一个类内直接调用，事务可能**不会生效**！
- Spring 的事务是基于 AOP 代理实现的，**只有通过代理对象调用，事务才会生效**。
- 如果在同一个类里直接调用另一个 `@Transactional` 方法，实际上不会经过代理，内层事务注解失效，**事务传播属性不会生效**。比如：
```java
// outer()直接调用inner()，inner()的事务注解不会生效，只有outer()的事务生效。
@Service
public class MyService {
    @Transactional
    public void outer() {
        inner(); // 直接调用，事务注解无效
    }

    @Transactional
    public void inner() {
        // 这里的事务注解不会生效
    }
}

// 只有通过Spring容器管理的代理对象去调用@Transactional方法，Spring才能拦截到方法调用，事务才会生效。
// 通常做法是：把内层事务方法放到另一个Spring Bean里，通过注入调用。
@Service
public class InnerService {
    @Transactional
    public void inner() {
        // 事务生效
    }
}

@Service
public class OuterService {
    @Autowired
    private InnerService innerService;

    @Transactional
    public void outer() {
        innerService.inner(); // 通过代理对象调用，事务生效
    }
}
```
**解决办法：**
- 让内层事务方法在**不同的类**，通过 Spring 容器注入调用，确保走代理。

#### 2）合理设置传播属性

- 如果希望内外方法共用一个事务（默认），用 `REQUIRED`。
- 如果希望内外方法各自独立，互不影响，用 `REQUIRES_NEW`。
- 如果需要嵌套事务（部分回滚），用 `NESTED`（需数据库支持）。

### 总结

| 场景/方式                | 事务传播属性         | 事务行为说明                                   |
|----------------------|------------------|------------------------------------------|
| 默认（REQUIRED）         | REQUIRED         | 内外方法共用一个事务，任何一个异常都整体回滚                |
| 新事务（REQUIRES_NEW）    | REQUIRES_NEW     | 内外方法各自独立，内层异常只回滚自己，外层不受影响            |
| 嵌套事务（NESTED）        | NESTED           | 内层异常只回滚自己，外层可选择是否回滚（需数据库支持）         |
| 同类内直接调用            | 任意              | 事务传播属性失效，内层事务注解无效，需通过代理对象调用         |

> Spring 事务中套事务时，要通过事务传播属性（如REQUIRED、REQUIRES_NEW、NESTED）控制事务边界。注意同类内直接调用不会生效，需通过代理对象调用。合理设置传播属性和调用方式，才能保证事务不会出现问题。

## IOC介绍 循环依赖如何解决？交给spring会不会出现内存溢出问题？

### 1. IOC 介绍

- **IOC（Inversion of Control，控制反转）**：把对象的创建和依赖关系的维护交给容器（如Spring），而不是在代码中手动new对象。
- **核心思想**：对象不再自己管理依赖，而是由容器统一注入（依赖注入，DI）。
- **好处**：解耦、易扩展、易测试、便于管理对象生命周期。

### 2. Spring 循环依赖如何解决？

- **循环依赖**：A依赖B，B又依赖A，构成闭环。
- **Spring的三级缓存机制**可以解决**单例Bean的构造器循环依赖**（即构造方法无参或只依赖属性注入的情况）：

  1. **singletonObjects**：一级缓存，存放完全初始化好的单例Bean。
  2. **earlySingletonObjects**：二级缓存，存放早期暴露的Bean（未完成依赖注入）。
  3. **singletonFactories**：三级缓存，存放Bean工厂对象（ObjectFactory），用于创建早期Bean引用。

- **解决流程**：
  - 创建A时，发现需要B，先把A的“半成品”放到三级缓存。
  - 创建B时，发现需要A，从三级缓存拿到A的“半成品”引用，完成依赖注入。
  - 最终A、B都能被正确创建。

- **注意**：只能解决**单例、属性注入**的循环依赖，**构造器注入的循环依赖无法解决**，会抛出异常。

### 3. 交给Spring会不会出现内存溢出问题？

- **正常情况下不会**。Spring的三级缓存机制会在Bean创建完成后清理缓存，避免内存泄漏。
- **但如果循环依赖链过长、Bean数量极大，或有自定义Bean生命周期管理不当，可能导致内存占用升高，极端情况下有OOM风险**。
- **常见OOM原因**：
  - 循环依赖链过长，Bean未及时释放。
  - Bean作用域为prototype（原型），Spring不管理其生命周期，容易内存泄漏。
  - 代码中有静态变量、线程等持有Bean引用，导致GC无法回收。

> IOC是控制反转，Spring通过依赖注入管理对象和依赖。Spring用三级缓存机制解决单例Bean的属性注入循环依赖，不能解决构造器注入的循环依赖。正常情况下不会导致内存溢出，但如果循环依赖链过长或Bean管理不当，极端情况下可能OOM。


## ICMP是什么知道吗？
是一种网络层协议，用于在主机、路由器之间传递控制消息和差错信息。

## AtomicXXX类底层如何实现的？

以 Java 的 `AtomicInteger`（atomicxxx）为例，底层实现主要依赖于**CAS（Compare And Swap，比较并交换）**原语和**CPU指令**，实现无锁的原子操作。

### CAS（Compare And Swap）原理

- **CAS** 是一种原子操作指令，流程如下：
  1. 读取变量的当前值（假设为A）。
  2. 比较当前值是否等于期望值（A）。
  3. 如果相等，则将变量值更新为新值（B）；否则不做任何操作。
  4. 整个过程是原子的，不会被线程切换中断。

- **伪代码：**
  ```
  if (value == expected) {
      value = newValue;
      return true;
  } else {
      return false;
  }
  ```

### Java AtomicInteger 的底层实现

- `AtomicInteger` 内部用 `Unsafe` 类的 `compareAndSwapInt` 方法实现原子加法等操作。
- 该方法最终会调用**CPU的原子指令**（如 x86 的 `LOCK CMPXCHG`）。
- 以 `incrementAndGet()` 为例，底层是一个自旋CAS循环：

  ```java
  public final int incrementAndGet() {
      for (;;) {
          int current = get();
          int next = current + 1;
          if (compareAndSet(current, next))
              return next;
      }
  }
  ```

- 如果CAS失败（变量被其他线程修改），会不断重试，直到成功。

> atomicxxx底层通过CAS原语和CPU原子指令实现无锁原子操作，保证并发安全。

## OOM这种可以被catch吗，哪些可以？
- 可以被catch，因为 OOM（java.lang.OutOfMemoryError）是 Error 的子类，理论上可以用 catch (Throwable t) 或 catch (Error e) 或 catch (OutOfMemoryError e) 捕获。
- 但**不建议捕获和处理 OOM，因为 OOM 通常表示JVM已经无法分配内存，系统处于极不稳定状态**，继续运行可能导致更多不可预期的问题（如线程无法创建、对象无法分配、GC失效等）。

## 动态代理的底层原理？
> 动态代理通过运行时生成代理类，**JDK代理基于接口+反射，CGLIB代理基于继承+字节码增强**，方法调用最终由代理逻辑统一处理。

## 多线程中的异常如何处理？

### 1. 普通线程的异常处理

- **线程run()方法内的异常不会抛到主线程**，如果不捕获，异常会导致该线程终止，但不会影响其他线程。
- **最佳实践**：在run()方法内部用try-catch捕获并处理异常，避免线程意外终止。

**示例：**
```java
new Thread(() -> {
    try {
        // 业务代码
    } catch (Exception e) {
        // 记录日志、报警、补偿等
    }
}).start();
```

### 2. 线程池中的异常处理

- **execute()提交的任务**：如果任务抛出异常，异常会被吞掉，不会抛到主线程，也不会有任何提示。
- **submit()提交的任务**：异常会被封装在Future中，只有调用get()时才会抛出ExecutionException。

**示例：**
```java
// execute方式
executor.execute(() -> {
    throw new RuntimeException("error"); // 异常被吞掉
});

// submit方式
Future<?> future = executor.submit(() -> {
    throw new RuntimeException("error");
});
try {
    future.get(); // 这里会抛出异常
} catch (ExecutionException e) {
    // 处理异常
}
```

### 3. 统一异常处理方式

- **自定义线程工厂**，为线程设置UncaughtExceptionHandler，统一处理未捕获异常。
- **线程池**可通过ThreadFactory设置异常处理器。

**示例：**
```java
ThreadFactory factory = r -> {
    Thread t = new Thread(r);
    t.setUncaughtExceptionHandler((thread, e) -> {
        // 统一异常处理，如日志、报警
    });
    return t;
};
ExecutorService executor = Executors.newFixedThreadPool(2, factory);
```

### 4. 总结

| 场景         | 异常处理方式                         | 说明/建议                       |
|------------|-------------------------------|----------------------------|
| 普通线程      | run()内try-catch                | 避免线程意外终止，记录日志/补偿           |
| 线程池execute | 任务内try-catch或设置UncaughtExceptionHandler | 否则异常被吞掉，需统一处理               |
| 线程池submit  | get()时catch ExecutionException   | 不get则异常被吞掉，建议及时处理           |

> 多线程异常不会抛到主线程，需在线程内部catch或用UncaughtExceptionHandler统一处理，线程池submit还可通过Future.get()捕获异常。


## submit和execute的区别？

| 对比项         | execute()                          | submit()                                 |
|--------------|----------------------------------|----------------------------------------|
| 定义          | 只接受Runnable任务                   | 可接受Runnable和Callable任务              |
| 返回值         | 无（void）                         | 返回Future对象，可获取结果/异常              |
| 异常处理        | 任务抛出异常会被吞掉，不会抛到主线程         | 任务抛出异常会封装在Future，get()时抛出ExecutionException |
| 获取结果        | 无法获取                           | 可通过Future.get()获取返回值/异常            |
| 适用场景        | 只需执行任务，无需结果/异常处理              | 需要获取任务结果或处理异常                   |

```java
// execute
executor.execute(() -> {
    // 只执行任务，不能获取结果
});

// submit
Future<Integer> future = executor.submit(() -> {
    return 123;
});
Integer result = future.get(); // 获取结果或异常
```

> execute只执行任务无返回值，submit能获取结果和异常，推荐用submit处理需要结果或异常的场景。

## 雪花算法？时钟回拨问题？
### 雪花算法
雪花算法（Snowflake）是分布式系统中常用的**全局唯一ID生成算法**，最早由Twitter提出。

经典的Snowflake 64位ID结构如下：

| 位数   | 含义           | 说明                         |
|------|--------------|----------------------------|
| 1    | 符号位         | 固定为0，正数                |
| 41   | 时间戳         | 距某个起始时间的毫秒数（可用69年）   |
| 10   | 机器标识       | 数据中心ID+机器ID（支持1024台机器） |
| 12   | 序列号（保证同一毫秒内生成多个ID时不重复）         | 同一毫秒内的自增序列（支持4096个ID） |


> 雪花算法用时间戳+机器ID+序列号拼成64位唯一ID，支持高并发分布式唯一ID生成，且大致递增。

### 时钟回拨问题解决

| 方案        | 适用场景       | 说明与优缺点                                                                                          |
| --------- | ---------- | ----------------------------------------------------------------------------------------------- |
| **等待恢复**  | 对可用性要求不高   | 当发现系统时钟回拨时，程序**暂停生成ID**，等待系统时间恢复正常。<br>优点：实现简单，保证ID唯一且有序。<br>缺点：服务暂停，影响可用性，可能造成阻塞。              |
| **备用序列号** | 对ID递增性要求不高 | 当时钟回拨时，启用备用的序列号生成逻辑（比如增加序列号范围）以继续生成ID，保证服务不中断。<br>优点：服务不中断。<br>缺点：ID不再严格递增，可能导致顺序性下降，并发处理能力受影响。 |
| **时间戳补偿** | 对ID递增性要求高  | 通过逻辑维护一个补偿时间戳，人工或自动调节时间戳，使ID仍保持递增顺序。<br>优点：保持ID的递增性。<br>缺点：实现较复杂，代码和运维成本增加。                     |
| **多时钟源**  | 高可靠性要求     | 采用多个时间源（如NTP服务器、GPS时间等），确保系统时间准确且稳定。<br>优点：高可靠性，减少回拨风险。<br>缺点：系统设计复杂，硬件和维护成本高。                  |


## 索引下推？
**索引下推**（Index Condition Pushdown，简称ICP）是 MySQL 5.6+ 引入的一种**优化查询性能的技术**，常用于InnoDB和MyISAM存储引擎。


### 什么是索引下推？

- 在没有ICP之前，MySQL在用索引查找时，如果有多个条件（如`where a=1 and b=2`），只有**最左前缀**（如a=1）会用到索引，后续条件（如b=2）需要回表到数据行再判断。
- **有了ICP后**，MySQL会在索引遍历阶段，尽量把更多的where条件“下推”到索引层过滤，**减少回表次数**，提升查询效率。

### 工作原理

- MySQL在扫描索引时，先用索引能判断的条件过滤一部分数据（如a=1）。
- 对于复合索引，能在索引中判断的其他条件（如b=2）也在索引遍历时判断。
- 只有通过所有下推条件的索引记录，才会回表读取完整数据行。

### 例子

假设有如下表和索引：

```sql
CREATE TABLE t (
  a INT,
  b INT,
  c INT,
  INDEX idx_ab(a, b)
);
```

查询语句：

```sql
SELECT * FROM t WHERE a=1 AND b=2 AND c=3;
```

- **没有ICP**：a=1用索引，b=2和c=3要回表判断。
- **有ICP**：a=1和b=2都在索引遍历时判断，只有b=2通过的才回表判断c=3。

### 优点

- **减少回表次数**，提升查询性能，尤其是大表和复合索引场景。
- 对于只用到索引字段的查询，甚至可以做到**覆盖索引**，无需回表。

### 如何查看是否用到ICP？

- 执行`EXPLAIN`，如果`Extra`列出现`Using index condition`，说明用到了索引下推。

> 索引下推是MySQL把更多where条件下推到索引遍历阶段过滤，减少回表次数，提高查询效率的优化技术。

## InnoDB和MyISAM的区别？

| 对比项         | InnoDB                         | MyISAM                         |
|--------------|--------------------------------|--------------------------------|
| 存储结构     | 行存储（Row-based）           | 行存储（Row-based）           |
| 事务支持     | 支持事务（ACID）             | 不支持事务（非ACID）          |
| 锁机制       | 行级锁（Row-level）           | 表级锁（Table-level）         |
| 索引         | 支持B+树索引（主键、唯一、普通） | 支持B+树索引（主键、唯一、普通） |
| 索引实现     | 支持全文索引（Full-text）     | 不支持全文索引（Full-text）    |
| 外键支持     | 支持外键（Foreign Key）       | 不支持外键（Foreign Key）      |


## TCP已建立连接时客户端突然断电 / 进程崩溃会怎样？
| 检测方式              | 是否默认启用    | 检测原理                | 响应速度       | 优点      | 缺点              |
| ----------------- | --------- | ------------------- | ---------- | ------- | --------------- |
| **无任何操作**         | ✅ 是       | TCP 不主动检测           | ❌ 极慢（永久挂住） | 简单      | 无法感知对端异常断开      |
| **应用层心跳机制**       | ❌ 否（需手动）  | 应用每隔 T 秒发送 ping 或请求 | ✅ 快（自定义）   | 快速准确、可控 | 实现复杂度稍高         |
| **主动读/写操作**       | ✅ 是       | 调用 read/write 发现异常  | ✅ 中等       | 实现简单    | 必须有数据交互触发，空闲时无效 |
| **TCP KeepAlive** | ❌ 否（默认关闭） | 内核发送探测包检测连接状态       | ❌ 慢（默认2h+） | 自动完成    | 开启麻烦，默认超时时间非常长  |

| 场景             | 建议做法                         |
| -------------- | ---------------------------- |
| 通信频繁（如游戏/推送系统） | 主动读写结合心跳机制                   |
| 长连接但低频通信（如RPC） | 开启 TCP keepalive + 应用层超时     |
| 重要服务/金融级稳定性需求  | 心跳 + 超时 + TCP keepalive 三重保障 |

## Raft介绍一下 和Paxos区别？
**Raft**是一个**分布式一致性算法**，用来保证多个节点之间的数据一致性。简单说就是：多个服务器如何达成共识，选出一个"老大"来管理数据。

### 核心概念

#### 三种角色
- **Leader（领导者）**：处理所有客户端请求，管理数据复制
- **Follower（跟随者）**：被动响应Leader和Candidate的请求
- **Candidate（候选人）**：选举过程中的临时角色

#### 任期（Term）
- 每个任期都有一个数字标识（1, 2, 3...）
- 每个任期最多只能有一个Leader
- 任期是递增的，不会回退

### 选举过程（Leader Election）

#### 触发条件
- 节点启动时
- Leader宕机时
- Follower超时未收到Leader心跳时

#### 选举步骤
1. **Follower → Candidate**：超时后发起选举
2. **投票阶段**：
   - Candidate给自己投票
   - 向其他节点请求投票
   - 其他节点只能投给任期号更大的Candidate
3. **结果**：
   - 获得多数票 → 成为Leader
   - 收到更高任期号 → 变回Follower
   - 超时未获得多数票 → 重新选举

### 日志复制（Log Replication）

#### 基本流程
1. **客户端请求** → Leader
2. **Leader记录日志** → 本地
3. **并行发送** → 所有Follower
4. **Follower确认** → 回复Leader
5. **Leader提交** → 通知Follower提交
6. **返回结果** → 客户端

#### 日志一致性
- 每个日志条目都有**任期号**和**索引号**
- Leader确保所有Follower的日志与自己一致
- 通过**AppendEntries RPC**同步日志

### 安全性保证

#### 选举限制
- 只有包含所有已提交日志的节点才能成为Leader
- 确保新Leader不会丢失已提交的数据

#### 日志匹配
- 如果两个日志在相同索引位置有相同任期号，则它们包含相同的命令
- 如果两个日志在相同索引位置有相同任期号，则它们之前的所有日志条目都相同

### 简单示例

**场景：5个节点的集群**

```
初始状态：所有节点都是Follower
Term 1: 节点A超时 → 发起选举 → 获得3票 → 成为Leader
Term 1: 客户端写请求 → Leader A处理 → 复制到其他节点 → 提交成功
Term 2: Leader A宕机 → 节点B超时 → 发起选举 → 成为新Leader
```

### 与Paxos的区别

| 特性 | Raft | Paxos |
|------|------|-------|
| **理解难度** | 相对简单 | 复杂 |
| **角色划分** | 明确（Leader/Follower/Candidate） | 角色不固定 |
| **日志管理** | 有明确的日志复制机制 | 需要额外实现 |
| **实现复杂度** | 较低 | 较高 |

### 实际应用

- **etcd**：Kubernetes的配置存储
- **Consul**：服务发现和配置管理
- **TiKV**：分布式数据库
- **CockroachDB**：分布式SQL数据库

### 要点

> Raft通过明确的Leader选举和日志复制机制，保证分布式系统中的数据一致性，相比Paxos更容易理解和实现。

- 强一致性保证
- 易于理解和实现
- 自动故障恢复
- 支持动态成员变更

> 选举选老大，复制保一致，任期防冲突，日志要匹配。

## hashCode()和equals()的区别,为什么重写equals()就要重写hashCode()？
- Java 对 equals() 和 hashCode() 的契约如下：
  - 如果两个对象通过 equals() 比较相等，则它们的 hashCode() 必须相等
  - 如果两个对象 hashCode() 相等，它们不一定 equals() 相等（哈希冲突是允许的）

| 问题                 | 结论               |
| ------------------ | ---------------- |
| `equals()` 比较什么？   | 值是否相等            |
| `hashCode()` 用来干嘛？ | 快速查找桶            |
| 为什么要同时重写？          | 保证集合类正常工作，避免逻辑错误 |
| 不重写会怎样？            | 数据重复、查找失败、逻辑异常   |

## 你对反射的了解？
反射就是在程序运行期间动态的获取对象的属性和方法的功能叫做反射。它能够在程序运行期间，对于任意一个类，都能知道它所有的方法和属性，对于任意一个对象，都能知道他的属性和方法。 获取Class对象的三种方式：getClass();xx.class;Class.forName("xxx"); 反射的优缺点： 优点：运行期间能够动态的获取类，提高代码的灵活性。 缺点：性能比直接的Java代码要慢很多。 应用场景：spring的xml配置模式，以及动态代理模式都用到了反射。

## 优先队列
PriorityQueue不是线程安全的，线程安全适用PriorityBlockingQueue，使用了ReentrantLock实现线程安全

## Spring Boot用哪个动态代理？
| 特性         | JDK 动态代理                   | CGLIB 动态代理          |
| ---------- | -------------------------- | ------------------- |
| 是否需要接口     | ✅ 必须实现接口                   | ❌ 不需要接口             |
| 实现方式       | Java 反射 + 接口               | 继承目标类 + 字节码增强（ASM）  |
| 性能         | JDK 1.6 之前慢，之后较快           | 创建代理时稍慢，执行时更快       |
| final 方法支持 | ❌ 无法代理 final 方法            | ❌ final 方法无法代理      |
| 原理         | `Proxy.newProxyInstance()` | `Enhancer.create()` |

- Spring AOP 默认使用：
  - JDK 动态代理：如果目标类实现了接口
  - CGLIB 动态代理：如果目标类没有实现接口

## 消息队列的推拉模式知道吗？

| 对比项      | 推（Push）         | 拉（Pull）        |
| -------- | --------------- | -------------- |
| **消息发送** | 队列主动将消息推送给消费者   | 消费者主动向队列轮询拉取消息 |
| **实时性**  | 高（消息到达即发送）      | 相对低（轮询间隔影响）    |
| **控制权**  | 队列控制（可能导致消费者过载） | 消费者控制拉取频率、数量   |
| **复杂性**  | 需要处理消费者负载问题     | 需设计合适的拉取策略     |
| **可靠性**  | 可能消息丢失（若未确认即宕机） | 更容易处理确认机制与重试   |

### ✅ 推（Push）适用场景：

| 典型场景                    | 原因                 |
| ----------------------- | ------------------ |
| **即时消息通知系统**（如短信、邮件、推送） | 实时性要求高，用户操作立刻响应    |
| **服务调用或RPC结果通知**        | 一旦有消息，立即通知消费者执行    |
| **低并发高实时**              | 消息不多，立刻推送能带来更快响应体验 |

👉 **代表系统：** RabbitMQ 默认使用 Push 模式


### ✅ 拉（Pull）适用场景：

| 典型场景               | 原因               |
| ------------------ | ---------------- |
| **大数据/日志分析系统**     | 需要按批处理、避免频繁中断    |
| **爬虫/异步任务系统**      | 任务处理复杂，消费者需要自己调度 |
| **消费速率不均/波动大**     | 避免消费者压力过大，自控节奏   |
| **离线处理**（如电商大促后统计） | 没有强实时性要求，按需拉取更高效 |

👉 **代表系统：** Kafka 默认使用 Pull 模式


| 条件      | 建议使用方式      |
| ------- | ----------- |
| 实时性优先   | 推           |
| 控制消费节奏  | 拉           |
| 消息量大    | 拉（避免推爆消费者）  |
| 网络不稳定   | 拉（消费者可断点续拉） |
| 消费者数量不定 | 推（结合队列分发）   |


一些中间件（如 Kafka Connect 或 Redis Stream）可以：

* **推送消息到缓冲队列**
* **消费者从缓冲中拉取处理**

这样可以**兼顾实时性和负载控制**。


## 负载均衡算法有哪些？
| 算法名称                     | 类型     | 核心原理                              | 优点             | 缺点            |
| ------------------------ | ------ | --------------------------------- | -------------- | ------------- |
| 轮询（Round Robin）          | 静态     | 请求依次分配到后端服务器                      | 实现简单、请求均衡      | 忽略服务器性能、负载差异  |
| 加权轮询                     | 静态     | 根据权重分配请求，权重大者分得多                  | 考虑性能差异，灵活配置    | 需人工设定权重，不够智能  |
| 随机（Random）               | 静态     | 随机选择一台服务器                         | 实现简单，适合节点性能相近  | 容易负载不均        |
| 加权随机                     | 静态     | 按权重进行随机分配                         | 随机性+性能考虑       | 同样需人工设定权重     |
| 源地址哈希                    | 静态     | 根据请求源 IP 哈希分配，保证同一客户端命中相同节点       | 保持会话一致性（粘性会话）  | 不利于动态扩容       |
| 最少连接（Least Connections）  | 动态     | 分配到当前连接数最少的服务器                    | 动态反映负载状态，分配合理  | 实现复杂，需要连接状态监控 |
| 加权最少连接                   | 动态     | 综合考虑权重与连接数                        | 更精细的负载控制       | 权重设置复杂        |
| 响应时间优先（Fastest Response） | 动态     | 分配到响应时间最短的节点                      | 高性能优先          | 需要实时采样响应时间    |
| 一致性哈希                    | 静态/分布式 | 哈希请求 key 映射到 hash 环，适用于缓存或服务治理等场景 | 缓存命中率高，节点变化影响小 | 实现复杂，适合特定应用   |

## Redis哨兵运行的时候如果主节点抖了一下咋办 假如抖的时候来请求了咋办 刚好没有超过超时配置？

### 情况描述

* 主节点短暂“抖动”或响应延迟，但没有完全宕机，且延迟时间没超过哨兵的\*\*故障判定超时（`down-after-milliseconds`）\*\*配置。
* 这个时候，有客户端请求打到主节点。

### 哨兵和请求处理过程

1. **哨兵对主节点的健康检查是周期性的，只有连续超过配置时间的不可用才认定为主节点宕机**

   * 例如 `down-after-milliseconds` = 30秒，主节点延迟10秒响应，哨兵不会立即判定它挂掉。
2. **如果抖动时间没超过超时，哨兵认为主节点仍然正常**

   * 哨兵不会触发故障转移（failover）。
3. **客户端请求会继续发给主节点**

   * 如果主节点还能响应请求，客户端会等待响应，可能会体验到延迟。
   * 如果主节点真的卡死或拒绝请求，客户端会报错或超时。
4. **哨兵只会在确定主节点“下线”后启动故障转移流程**

   * 故障转移会选举新的主节点，通知客户端（或客户端通过哨兵获取新主节点信息）。

### 综上，抖动情况下请求表现

| 事件            | 影响与处理                        |
| ------------- | ---------------------------- |
| 抖动时间 < 哨兵判定时间 | 哨兵认为主节点正常，请求继续发往主节点，可能有响应延迟  |
| 抖动时间 > 哨兵判定时间 | 哨兵判定主节点故障，启动故障转移，客户端请求转向新主节点 |
| 主节点完全不可用      | 请求失败或超时，等待哨兵切换主节点            |

### 如何降低抖动带来的影响？

* **调优哨兵故障判定参数**，比如 `down-after-milliseconds`，根据业务对延迟和可用性的容忍度权衡设置。
* **客户端设置合理的超时和重试机制**。
* **使用哨兵集群监控多个节点，避免单点误判**。
* **主节点性能调优，避免抖动**。

## 如何实现防抖和节流？
- 前端实现

| 特性     | 防抖（Debounce）         | 节流（Throttle）    |
| ------ | -------------------- | --------------- |
| 执行时机   | 事件停止触发后执行一次          | 按固定时间间隔执行一次     |
| 执行频率   | 多次触发只执行一次            | 多次触发按间隔执行多次     |
| 适用场景   | 输入框防抖、搜索、窗口大小调整完成后执行 | 滚动事件、窗口大小实时变化处理 |
| 触发函数次数 | 一定时间内只执行一次           | 一定时间内按频率执行多次    |


## 进程之间的通信方式？
| 通信方式           | 是否共享内存 | 特点                 | 应用场景  |
| -------------- | ------ | ------------------ | ----- |
| 管道（Pipe）       | 否      | 单向通信，父子进程之间使用      | 简单通信  |
| 命名管道（FIFO）     | 否      | 支持无亲缘关系的进程         | 本地通信  |
| 信号（Signal）     | 否      | 传递少量信号，用于进程控制      | 通知或中断 |
| 消息队列           | 否      | 结构化数据传递，有消息格式      | 解耦通信  |
| 共享内存           | 是      | 速度最快，需配合同步机制（如信号量） | 大数据通信 |
| 信号量（Semaphore） | 是/否    | 主要用于进程同步（可辅助共享内存）  | 同步控制  |
| 套接字（Socket）    | 否（可远程） | 支持网络通信，**可跨主机**    | 分布式系统 |
| 内存映射文件（mmap）   | 是      | 将文件映射进内存供多个进程访问    | 文件共享  |

| 通信 | 进程间通信 | pipe(), socket() | 通信描述符 |

## Linux查看进程有哪些命令？

**常用进程查看命令：**

| 命令 | 作用 | 常用参数 | 示例 |
|------|------|----------|------|
| `ps` | 查看进程快照 | `-ef`, `-aux` | `ps -ef \| grep java` |
| `top` | 实时查看进程 | `-p PID` | `top -p 1234` |
| `htop` | 增强版top | 交互式操作 | `htop` |
| `pgrep` | 按名称查找PID | `-f` 完整命令行 | `pgrep -f tomcat` |
| `pidof` | 查找程序PID | 程序名 | `pidof nginx` |
| `pstree` | 树形显示进程 | `-p` 显示PID | `pstree -p` |

**面试重点回答：**
```
最常用的是ps和top：
- ps -ef：查看所有进程的完整信息
- ps -aux：显示详细的资源使用情况  
- top：实时监控进程CPU、内存使用
- pgrep：快速根据进程名查找PID
```

## DB一次请求正常时间应该是多少？Redis呢？

**数据库请求响应时间标准：**

| 数据库类型 | 正常响应时间 | 优秀水平 | 告警阈值 | 说明 |
|------------|-------------|----------|----------|------|
| **MySQL** | 10-50ms | <10ms | >100ms | 简单查询，有索引 |
| **PostgreSQL** | 10-50ms | <10ms | >100ms | 简单查询，有索引 |
| **Redis** | 0.1-1ms | <0.5ms | >5ms | 内存操作，单线程 |
| **MongoDB** | 5-20ms | <5ms | >50ms | 文档查询 |

**影响因素：**

| 因素 | MySQL影响 | Redis影响 | 优化建议 |
|------|-----------|-----------|----------|
| 网络延迟 | 1-5ms | 0.1-0.5ms | 内网部署，减少跳数 |
| 查询复杂度 | 较大 | 很小 | 优化SQL，添加索引 |
| 数据量大小 | 较大 | 一般 | 分页查询，数据分片 |
| 并发连接数 | 较大 | 一般 | 连接池管理 |

**面试重点回答：**
```
- MySQL简单查询：10-50ms正常，超过100ms需要优化
- Redis操作：0.1-1ms正常，超过5ms有问题
- 复杂查询可能需要几百毫秒，需要优化SQL和索引
- 网络延迟通常占1-5ms，内网部署可以降低
```

## 数据库ORM连接池有哪些点需要考量？

**连接池核心参数：**

| 参数 | 作用 | 推荐值 | 设置依据 |
|------|------|--------|----------|
| **初始连接数** | 启动时创建的连接数 | 5-10 | 避免冷启动，不宜过大 |
| **最大连接数** | 连接池最大容量 | CPU核数×2 | 数据库承载能力 |
| **最小空闲连接** | 保持的最少连接数 | 5 | 保证响应速度 |
| **最大空闲时间** | 连接空闲多久被回收 | 10-30分钟 | 平衡资源利用和响应 |
| **连接超时时间** | 获取连接的超时时间 | 30秒 | 避免请求长时间等待 |
| **验证查询** | 检测连接有效性 | `SELECT 1` | 确保连接可用 |

**连接池选型对比：**

| 连接池 | 特点 | 性能 | 适用场景 |
|--------|------|------|----------|
| **HikariCP** | 轻量级，启动快 | 最优 | Spring Boot默认推荐 |
| **Druid** | 功能丰富，监控强 | 良好 | 需要详细监控的场景 |
| **C3P0** | 老牌稳定 | 一般 | 传统项目 |
| **DBCP** | Apache出品 | 一般 | 简单场景 |

**关键考量点：**

| 考量维度 | 关键问题 | 最佳实践 |
|----------|----------|----------|
| **性能** | 连接获取速度、资源消耗 | 选择HikariCP，合理设置连接数 |
| **稳定性** | 连接泄漏、死锁检测 | 启用连接验证，设置超时时间 |
| **监控** | 连接使用情况、异常统计 | 集成监控，设置告警 |
| **扩展性** | 动态调整连接数 | 支持运行时参数调整 |

**面试重点回答：**
```
主要考虑四个方面：
1. 连接数设置：最大连接数=CPU核数×2，避免过大造成数据库压力
2. 超时管理：连接超时、空闲超时要合理设置
3. 连接验证：定期检查连接有效性，避免使用无效连接
4. 监控告警：监控连接池使用情况，及时发现问题

推荐使用HikariCP，性能最优，Spring Boot默认选择。
```