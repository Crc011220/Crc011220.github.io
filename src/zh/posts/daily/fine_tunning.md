---
icon: pen-to-square
date: 2026-02-01
category:
  - Learning Records
tag:
  - Notes
---

# Fine Tuning 微调与 LoRA

## 一、微调与 LoRA 的底层逻辑

### 什么是微调

可以将预训练模型比作刚毕业的全能本科生，具备广泛知识但缺乏行业特定业务能力。**微调**就是通过行业数据训练，使其从通才转变为懂业务的专才，让模型掌握公司业务或行业黑话。

### LoRA 的原理

**LoRA**（Low-Rank Adaptation）的核心逻辑是：冻结原模型参数，不修改模型「大脑」，而是在模型层间插入可训练的低秩矩阵（Adapter 适配器参数）。如同给教科书贴便利贴，新增知识写在便利贴上，模型推理时同时参考原模型和新增参数。

### LoRA 的三大优势

- **省显存**：仅训练新增的 Adapter 参数，显存占用仅为全量微调的 1/3 甚至更少，免费云端显卡也能运行
- **速度快**：训练时间大幅缩短，别人需一周，LoRA 可能仅需几十分钟，且在垂直领域效果不输全量微调
- **效果好**：以最小代价实现专属领域效果优化，实现「不动大手术，只做微整形」

## 二、环境准备

### 使用 ModelScope 免费云端算力

1. 登录 [ModelScope](https://modelscope.cn) 官网，进入「我的 Notebook」
2. 选择 GPU 环境（24G 显存足够运行 DeepSeek-R1 的 LoRA 微调）
3. 镜像选择官方默认 Pytorch 镜像，预装必要驱动，开箱即用
4. 启动后点击「查看 Notebook」进入网页代码编辑器
5. 注意：超过一小时无操作会自动关闭，需定期操作或设置自动刷新

### 核心依赖库安装

离开 ModelScope 官方镜像时需安装：

- **transformers**：大模型基础设施
- **peft**：管理 LoRA 适配器参数
- **bitsandbytes**：量化工具，节省显存

安装时可使用国内镜像源，提升下载速度。

## 三、代码实战步骤

### 1. 工作区整理

- 在文件浏览器右键新建文件夹，用于存放训练模型、日志和数据集
- 进入该文件夹后，新建 Jupyter Notebook（相较 .py 脚本，可分块运行、容错率高，适合边学边练）

### 2. 加载模型并测试

- 在 ModelScope 模型库找到版本，通过 SDK 下载到本地
- 模型默认存放在 `.cache/modelscope/models/deepseek-ai/`，需通过终端（`ls -a`、`cd`）找到绝对路径并替换代码中的变量
- 有 GPU 时保留相关配置，无独显则删除

### 3. 制作数据集

- 准备问答数据（如 50 条唱歌技巧问答），转换为 JSON 格式（一行一个 JSON 对象）
- 将问题和答案拼接，通过代码直接定义数据集（数据量少时更直观）

### 4. 拆分数据集

按比例拆分为训练集和测试集（如 50 条 → 45 条训练 + 5 条测试），避免模型死记硬背，确保真正理解知识。

### 5. Tokenizer 处理

- 拼接问题和答案为一句话
- 进行 tokenize 分词，设置 `max_length` 对数据进行截断或补齐，统一数据长度以便 GPU 处理

### 6. 量化设置

通过代码对模型进行量化（如 8bit 量化），压缩模型体积一半以上，显著降低显存占用。牺牲少量精度，但不影响整体效果。

### 7. LoRA 设置

| 参数 | 说明 |
|------|------|
| **r**（秩） | 决定 Adapter 参数容量，值越大学习能力越强但显存越高，轻量级微调设为 8 或 16 性价比高 |
| **alpha**（缩放因子） | 通常设为 r 的两倍，控制微调对原模型的影响程度 |
| **task_type** | 指定为语言模型对话生成 |

设置后仅训练约 **0.06%** 的参数，其余参数冻结。

### 8. 训练参数配置与执行

| 参数 | 说明 |
|------|------|
| `output_dir` | 训练成果保存路径 |
| `num_train_epochs` | 训练轮次，数据量少需多轮，数据量大则 1～3 轮即可 |
| `per_device_train_batch_size` | 每次送入显卡的数据条数，显存溢出时可减小为 2 或 1 |
| `fp16` | 开启半精度训练，显存占用砍半，训练速度翻倍 |

配置完成后执行训练，关键输出文件为 `adapter_model.safetensors`（Adapter 参数）和 `adapter_config.json`（配置说明）。

## 四、微调技能的价值与应用

微调的核心价值在于**举一反三**，可根据不同数据将模型打造成特定领域专家：

- 替换为公司产品手册 → 金牌客服
- 替换为法律条文 → 法律顾问
- 替换为 Python 代码库 → 编程助手

2026 年，会调用 API 的人众多，而能根据业务需求完成模型微调的人才是行业稀缺资源。掌握从数据清洗到模型微调的全流程，是 AI 工程师的基本功。
