---
icon: pen-to-square
date: 2026-02-01
category:
  - Learning Records
tag:
  - Notes
---

# 大模型幻觉的成因与治理

## 什么是幻觉

大模型幻觉是指模型在未知或知识不足时，自信地创造虚假信息的现象，与简单错误不同。

- **简单错误**：因知识未覆盖导致的无知（如知识库仅更新到 2024 年却被问 2025 年诺贝尔奖得主，回答「不知道」或错误引用 2024 年数据）
- **幻觉**：模型主动脑补不存在的内容（如虚构诺贝尔奖得主姓名、获奖感言及论文），其核心特征是「自信的创造」，即使逻辑严密、语言流畅，核心事实完全虚假

## 幻觉的三大症状

### 事实捏造

表现为无中生有，如帮写论文时虚构不存在的参考文献（书名、作者），在中医古籍、特定法律条款等冷门专业领域仍常见。

### 事实冲突

处理文档时生成与参考材料矛盾的内容，例如财报原文显示净利润亏损 5%，总结却称「实现稳健增长」，即生成内容与输入信息直接冲突。

### 逻辑谬误

长文本推理中注意力漂移导致因果断裂，如前文说「A 导致 B」，中间推理后结论却变成「A 导致 C」，整体读起来流畅但因果关系不成立。

## 幻觉产生的三大根源

### 数据源头的熵增

互联网数据中 AI 生成内容占比上升，导致「知识污染」。模型 A 生成的虚假信息被模型 B 当作真理学习，进而生成新的虚假内容，真实信号减弱，虚假噪音被当作高权重知识，模型学习的「教材」本身已被污染。

### 模型压缩

大模型本质是「有损压缩器」，类似将图书馆书籍压缩进 JPG 图片，放大时部分细节模糊。模型对模糊细节不会承认「看不清」，而是根据概率选择最可能的词填充，导致虚构内容（如虚构历史事件），模型自身不认为在撒谎。

### 推理偷懒

模型虽有内在思维链（internal cot），理论上应先推导、验证再输出结果，但受算力限制或追求速度，会跳过验证步骤，类似学生做题跳过中间步骤直接写答案，导致逻辑顺但结论错误的幻觉。

## 幻觉治理方案

### 显性思维链

又称「慢思考」，对应推理模型 system two。与快速直觉式的 system one 不同，面对问题时，模型会在后台先拆分问题为小步骤，逐步推导并自我校验，确认无误后再输出结果。适用于数学计算、写代码等容错率低的任务，准确率接近 100%。

### agentic RAG

在普通 RAG 基础上增加「自我反思」机制。智能代理检索资料后，会先判断信息是否足够回答问题，若不足或有冲突，自动发起多次检索，直至信息充足。最终生成的每个句子都标注来源（文件及段落），提供出处安全感，是企业客服机器人、专业知识库的工业标准方案。

## 治理方案选型建议

| 场景 | 方案 | 说明 |
|------|------|------|
| 简单场景（demo 演示、闲聊） | 普通 prompt 工程 | 成本最低 |
| 复杂逻辑任务（解数学题、算法） | 推理模型 | 确保逻辑正确 |
| 超长文本处理（百万字小说、长财报分析） | 长上下文（long context） | 宏观分析能力强 |
| 企业应用（客服机器人、专业知识库） | agentic RAG | 稳定性高，幻觉率低 |
| 高风险行业（金融、新闻） | 增加事后核查 | 如编辑审核员拦截错误输出 |

**终极形态**：组合使用多种方案（如长上下文模型梳理背景 → agentic RAG 精准搜索数据 → 推理模型生成分析报告）。

## 未来展望：可解释性与可验证性

### 可解释性

拒绝黑盒，要求模型展示思考过程，如同数学题需提供解析步骤，说明结论的推导逻辑是否通顺。

### 可验证性

AI 生成的关键结论（医疗建议、投资分析等）需附带可查验的证据链（搜索引擎可查或原始文档链接），是建立信任的核心方式。

---

幻觉伴随智能诞生，无法根除但可通过思维链、agentic RAG 等工具控制，目标是在严谨场景「上枷锁」、创意场景「给自由」，让 AI 从「随机鹦鹉」进化为可靠的推理伙伴。
