<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.18" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.59" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://crc011220.github.io/posts/unimelb/ml.html"><meta property="og:site_name" content="Ruochen Chen"><meta property="og:title" content="Machine Learning"><meta property="og:description" content="Machine Learning Introduction An instance is a single exemplar from the data, consisting of a bundle of (possibly unknown) attribute values (feature values) (and, in the case of..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-06-21T10:08:49.000Z"><meta property="article:tag" content="Unimelb"><meta property="article:published_time" content="2025-06-19T00:00:00.000Z"><meta property="article:modified_time" content="2025-06-21T10:08:49.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Machine Learning","image":[""],"datePublished":"2025-06-19T00:00:00.000Z","dateModified":"2025-06-21T10:08:49.000Z","author":[{"@type":"Person","name":"Ruochen Chen"}]}</script><link rel="icon" href="/mac.ico"><title>Machine Learning | Ruochen Chen</title><meta name="description" content="Machine Learning Introduction An instance is a single exemplar from the data, consisting of a bundle of (possibly unknown) attribute values (feature values) (and, in the case of...">
    <link rel="stylesheet" href="/assets/css/styles.563fed46.css">
    <link rel="preload" href="/assets/js/runtime~app.16418bc7.js" as="script"><link rel="preload" href="/assets/css/styles.563fed46.css" as="style"><link rel="preload" href="/assets/js/6312.2d95f1ad.js" as="script"><link rel="preload" href="/assets/js/app.0b60fbc5.js" as="script">
    <link rel="prefetch" href="/assets/js/zh_posts_declarative_haskell.html.f219f509.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_java8_ÂáΩÊï∞ÂºèÁºñÁ®ã.html.6406d92a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_Netty01-nio.html.6aaca557.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_Netty04-‰ºòÂåñ‰∏éÊ∫êÁ†Å.html.8edea904.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_Netty03-ËøõÈò∂.html.6b130a66.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_Êï∞ÁªÑ.html.9ef6b4e9.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_Âä®ÊÄÅËßÑÂàí.html.61abe486.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_Netty02-intro.html.48ff395e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_nginx_1.html.be9ccc3a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_‰∫åÂèâÊ†ë.html.c9482b31.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_Èù¢ËØïË¶ÅÁÇπ.html.5266fb5f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_declarative_prolog.html.d10c8ca1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_ÈìæË°®.html.d97cbc37.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_COMP90024.html.c07eee32.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_Âõæ.html.e75c5fd4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_Ê†àÂíåÈòüÂàó.html.2a7e3777.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hive_Hive-SQLËØ≠Ê≥ïÂ§ßÂÖ®.html.4ea325b1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_ÂÖ∂‰ªñÈóÆÈ¢ò.html.b2b35bb6.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_14.html.91687ee1.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_declarative_haskellÈÄüËÆ∞.html.0de6f0c8.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_ÂõûÊ∫Ø.html.f2eaeec4.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_ÂÖ∂‰ªñ.html.f274621f.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_COMP90049.html.4b1c6d22.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_COMP90050.html.4b5d3bee.js" as="script"><link rel="prefetch" href="/assets/js/posts_note_Coin-exchange-project-note.html.9c9c631c.js" as="script"><link rel="prefetch" href="/assets/js/posts_tailwind_summary.html.7c9f97e6.js" as="script"><link rel="prefetch" href="/assets/js/2664.0c0e265f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_Êï∞ÊçÆÁªìÊûÑ.html.1143a147.js" as="script"><link rel="prefetch" href="/assets/js/posts_typescript_1.html.adb4c039.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_ËÆ°ÁÆóÊú∫ÁΩëÁªú.html.57bf0039.js" as="script"><link rel="prefetch" href="/assets/js/posts_typescript_2.html.70e869a7.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_Ë¥™ÂøÉ.html.8b0ae2af.js" as="script"><link rel="prefetch" href="/assets/js/posts_aws-saa_1.html.12f65834.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_ml.html.930a6c4a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_Êï∞ÊçÆÂ∫ì.html.bb6e239c.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_COMP90048.html.8968005c.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_ËÆ°ÁÆóÊú∫ÁªÑÊàêÂéüÁêÜ.html.f075ed19.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_Êìç‰ΩúÁ≥ªÁªü.html.9a98732a.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_1.html.42f88b26.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_declarative_prologÈÄüËÆ∞.html.06d2d57f.js" as="script"><link rel="prefetch" href="/assets/js/8300.ef6ef338.js" as="script"><link rel="prefetch" href="/assets/js/posts_mybatis_2.html.5926ba81.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_ÂèåÊåáÈíà.html.dd171978.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_7.html.d2987d20.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_4.html.d05f7970.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_5.html.74809557.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_8.html.48797aee.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_2.html.5da88c74.js" as="script"><link rel="prefetch" href="/assets/js/posts_aws-saa_3.html.3976b1b1.js" as="script"><link rel="prefetch" href="/assets/js/posts_nginx_1.html.9d684d75.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_SWEN90016.html.240e6126.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_ÂìàÂ∏å.html.f3d63117.js" as="script"><link rel="prefetch" href="/assets/js/posts_spark_Spark-Core.html.d371024a.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_11.html.acf3feb6.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_14.html.6ae00502.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_8.html.35609b90.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_4.html.76f297f5.js" as="script"><link rel="prefetch" href="/assets/js/posts_spark_Spark-Sql.html.1a76e157.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_21.html.5d38e92e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_‰ø°ÊÅØÊñ∞ÊäÄÊúØ.html.016ea36f.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_11.html.6ac0e485.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_5.html.d6b5776e.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_6.html.9f42e615.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_10.html.7cfe6b37.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_1.html.275b2472.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_6.html.b0bf65af.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_4.html.bb865133.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_ÂçïË∞ÉÊ†à.html.97d2a1c2.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_15.html.6ad131ac.js" as="script"><link rel="prefetch" href="/assets/js/posts_aws-saa_2.html.19b4fc69.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_6.html.0ce6907d.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_3.html.07708648.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_12.html.33aac800.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_14.html.4487a39f.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_13.html.1600cb03.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_javaai.html.ddef5ab6.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_Â≠óÁ¨¶‰∏≤.html.66e8af08.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_5.html.c674a286.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_6.html.c703f5fb.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_2.html.2012a517.js" as="script"><link rel="prefetch" href="/assets/js/posts_typescript_3.html.67716c58.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_2.html.3cb286a6.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_16.html.47a98467.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_2.html.2faaae84.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_7.html.b7a17cf5.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_3.html.e6de0801.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_12.html.78a79e16.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_17.html.48e4e11f.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_‰ΩçËøêÁÆó.html.89a49729.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_13.html.1af16bb4.js" as="script"><link rel="prefetch" href="/assets/js/intro.html.94b9bc8e.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_9.html.c802974b.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_15.html.c14ce54d.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_create_mcp.html.7bbd9d99.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_18.html.6db3b8d0.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_1.html.52e2c809.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_mcp.html.97488bfa.js" as="script"><link rel="prefetch" href="/assets/js/posts_mybatis_1.html.0715b7ed.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_1.html.b4be9a5c.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_7.html.391ad3ae.js" as="script"><link rel="prefetch" href="/assets/js/posts_istio_1.html.0402dff2.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_4.html.babb3186.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_15.html.1a066aec.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_10.html.a809572e.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_1.html.3f7ea202.js" as="script"><link rel="prefetch" href="/assets/js/zh_intro.html.4f0fc279.js" as="script"><link rel="prefetch" href="/assets/js/posts_spark_Spark-Intro.html.ccd5e5dd.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_5.html.e4df8be3.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_19.html.f4de2c0a.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_7.html.be9d15e1.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_3.html.1db9eef8.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_7.html.95a6d006.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_8.html.bf7de1dc.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_index.html.964e7b71.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_3.html.b6b4d014.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_Hive.html.0678d205.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_Êï∞Â≠¶.html.452843d9.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_7.html.97e8c4ab.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_9.html.daf44b98.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_HDFS.html.bc68b1b5.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_index.html.969cd922.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_2.html.03f4e466.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_8.html.266a2255.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_4.html.f53cce1e.js" as="script"><link rel="prefetch" href="/assets/js/posts_jd_note.html.d14373ad.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_5.html.4cdca3c2.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_3.html.47cad464.js" as="script"><link rel="prefetch" href="/assets/js/posts_docker_1.html.fb8facad.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_11.html.ce50e313.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_microsvc_1.html.2fe97c3c.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_index.html.8bdb826b.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_summary.html.dcef505d.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_6.html.b6472eba.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_6.html.02cce475.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_3.html.e8a57164.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_6.html.0c46208c.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_7.html.34e04d11.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_8.html.ae4c64a3.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_4.html.a8ec1263.js" as="script"><link rel="prefetch" href="/assets/js/posts_elasticsearch_query-dsl.html.c10df9f4.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_cloudflare.html.8d90577a.js" as="script"><link rel="prefetch" href="/assets/js/posts_algorithm_20.html.490f1029.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_1.html.0cac3363.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_5.html.a42942da.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_2.html.1499c365.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_10.html.156d0fc8.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_16.html.94f2539e.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_practices_3.html.2d055dbe.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_tools.html.4cf9b015.js" as="script"><link rel="prefetch" href="/assets/js/posts_elasticsearch_1.html.55fea42c.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_2.html.4fddb7fe.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_index.html.9f6e664a.js" as="script"><link rel="prefetch" href="/assets/js/posts_dubbo_1.html.1f23a627.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_concepts_4.html.1c4ee376.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_9.html.132d4ce9.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_index.html.3644a432.js" as="script"><link rel="prefetch" href="/assets/js/posts_nextjs_index.html.b114f681.js" as="script"><link rel="prefetch" href="/assets/js/posts_interview_9.html.a3039a5a.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_index.html.6e477592.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_1.html.ea5597b0.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_8.html.bc2310ff.js" as="script"><link rel="prefetch" href="/assets/js/posts_elasticsearch_2.html.965ea244.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_genesis.html.b92085d2.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_5.html.4cfebd9b.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_GEOM90007.html.daec0d9f.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_index.html.77a0d6fd.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_MapReduce.html.66b74478.js" as="script"><link rel="prefetch" href="/assets/js/posts_genesis.html.f2dcbd5d.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_12.html.6f85b8a6.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_sealos.html.2f8ff09a.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_index.html.30eae38c.js" as="script"><link rel="prefetch" href="/assets/js/posts_dubbo_2.html.4153924b.js" as="script"><link rel="prefetch" href="/assets/js/posts_clich√©_13.html.9f0ab2c4.js" as="script"><link rel="prefetch" href="/assets/js/posts_aws-saa_index.html.91a04274.js" as="script"><link rel="prefetch" href="/assets/js/posts_typescript_index.html.3113541a.js" as="script"><link rel="prefetch" href="/assets/js/posts_elasticsearch_index.html.4152a6b9.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_index.html.c927a97d.js" as="script"><link rel="prefetch" href="/assets/js/index.html.8b8ff801.js" as="script"><link rel="prefetch" href="/assets/js/posts_dubbo_index.html.6c52fb32.js" as="script"><link rel="prefetch" href="/assets/js/posts_hadoop_Yarn.html.94f37571.js" as="script"><link rel="prefetch" href="/assets/js/posts_nginx_index.html.75cc2b5d.js" as="script"><link rel="prefetch" href="/assets/js/posts_ai_index.html.6d4a62d9.js" as="script"><link rel="prefetch" href="/assets/js/posts_mybatis_index.html.f1a73719.js" as="script"><link rel="prefetch" href="/assets/js/posts_spark_index.html.434a7834.js" as="script"><link rel="prefetch" href="/assets/js/posts_kubernetes_microsvc_index.html.7ac9796f.js" as="script"><link rel="prefetch" href="/assets/js/posts_cmb_9.html.e9ae3067.js" as="script"><link rel="prefetch" href="/assets/js/posts_nginx_2.html.61b94ab9.js" as="script"><link rel="prefetch" href="/assets/js/zh_index.html.b526dd8b.js" as="script"><link rel="prefetch" href="/assets/js/posts_tailwind_index.html.a3b1860b.js" as="script"><link rel="prefetch" href="/assets/js/posts_docker_index.html.915fb03b.js" as="script"><link rel="prefetch" href="/assets/js/posts_istio_index.html.d4b67811.js" as="script"><link rel="prefetch" href="/assets/js/posts_note_index.html.79ea061a.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_ËΩØ‰ª∂ËÆæËÆ°‰∏éÂºÄÂèë.html.d87b372b.js" as="script"><link rel="prefetch" href="/assets/js/posts_unimelb_GEOM90008.html.d7040807.js" as="script"><link rel="prefetch" href="/assets/js/category_learning-records_index.html.f32ee64d.js" as="script"><link rel="prefetch" href="/assets/js/tag_nginx_index.html.0fa6f2ea.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_declarative-programming_index.html.6ae8ae47.js" as="script"><link rel="prefetch" href="/assets/js/category_index.html.50e2e1bc.js" as="script"><link rel="prefetch" href="/assets/js/timeline_index.html.a204d771.js" as="script"><link rel="prefetch" href="/assets/js/article_index.html.ffcd7938.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_Â≠¶‰π†Á¨îËÆ∞_index.html.12546e3e.js" as="script"><link rel="prefetch" href="/assets/js/category_internship-journal_index.html.4b3fa613.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_learning-records_index.html.af6fedad.js" as="script"><link rel="prefetch" href="/assets/js/tag_index.html.dbf647b4.js" as="script"><link rel="prefetch" href="/assets/js/star_index.html.7f8a9df9.js" as="script"><link rel="prefetch" href="/assets/js/tag_programmer-clich√©_index.html.120cca1a.js" as="script"><link rel="prefetch" href="/assets/js/tag_algorithm-practices_index.html.d975dd18.js" as="script"><link rel="prefetch" href="/assets/js/tag_china-merchant-bank_index.html.de8b373f.js" as="script"><link rel="prefetch" href="/assets/js/tag_technical-interview_index.html.acf61e6f.js" as="script"><link rel="prefetch" href="/assets/js/posts_index.html.c7f3157a.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_ÂºÄÂßã_index.html.29cb4412.js" as="script"><link rel="prefetch" href="/assets/js/tag_tailwind-css_index.html.7b3e36e9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ÊóÖÁ®ã_index.html.151709c9.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_ÁÆÄÂéÜ_index.html.96ae735a.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_algorithm_index.html.5a457b02.js" as="script"><link rel="prefetch" href="/assets/js/category_genesis_index.html.66947f9e.js" as="script"><link rel="prefetch" href="/assets/js/tag_javascript_index.html.266dcd48.js" as="script"><link rel="prefetch" href="/assets/js/tag_kubernetes_index.html.2b919c53.js" as="script"><link rel="prefetch" href="/assets/js/tag_typescript_index.html.ab5e1572.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_review_index.html.9bc60916.js" as="script"><link rel="prefetch" href="/assets/js/tag_leetcode_index.html.6b98bbdb.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_java8_index.html.5b1186ee.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_netty_index.html.3ede65fb.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_nginx_index.html.c21f0432.js" as="script"><link rel="prefetch" href="/assets/js/tag_aws-saa_index.html.01a20249.js" as="script"><link rel="prefetch" href="/assets/js/tag_mybatis_index.html.bdbe6d2a.js" as="script"><link rel="prefetch" href="/assets/js/tag_unimelb_index.html.d4bafe83.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_hive_index.html.fab4d732.js" as="script"><link rel="prefetch" href="/assets/js/tag_docker_index.html.b7d4cbf8.js" as="script"><link rel="prefetch" href="/assets/js/tag_hadoop_index.html.39a6a55f.js" as="script"><link rel="prefetch" href="/assets/js/tag_nextjs_index.html.581d2c34.js" as="script"><link rel="prefetch" href="/assets/js/tag_resume_index.html.c4e4c327.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_nio_index.html.0a4acee3.js" as="script"><link rel="prefetch" href="/assets/js/tag_dubbo_index.html.90f9e5c2.js" as="script"><link rel="prefetch" href="/assets/js/tag_index_index.html.ee3192d7.js" as="script"><link rel="prefetch" href="/assets/js/tag_istio_index.html.cb329abb.js" as="script"><link rel="prefetch" href="/assets/js/tag_notes_index.html.075779e3.js" as="script"><link rel="prefetch" href="/assets/js/tag_react_index.html.49ec34fb.js" as="script"><link rel="prefetch" href="/assets/js/tag_spark_index.html.287e8a9c.js" as="script"><link rel="prefetch" href="/assets/js/404.html.15229e01.js" as="script"><link rel="prefetch" href="/assets/js/zh_timeline_index.html.3a7839f4.js" as="script"><link rel="prefetch" href="/assets/js/tag_ai_index.html.3120c8b4.js" as="script"><link rel="prefetch" href="/assets/js/tag_es_index.html.8f0f4273.js" as="script"><link rel="prefetch" href="/assets/js/tag_jd_index.html.6c64e177.js" as="script"><link rel="prefetch" href="/assets/js/zh_category_index.html.e65aefca.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_declarative_index.html.6759320d.js" as="script"><link rel="prefetch" href="/assets/js/zh_article_index.html.2c545722.js" as="script"><link rel="prefetch" href="/assets/js/zh_tag_index.html.6a5580f0.js" as="script"><link rel="prefetch" href="/assets/js/zh_star_index.html.698b9149.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_review_index.html.6b5498be.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_java8_index.html.245580da.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_netty_index.html.9e91bcfd.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_nginx_index.html.6deedd0e.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_algo_index.html.d664c5ec.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_hive_index.html.e3d7d626.js" as="script"><link rel="prefetch" href="/assets/js/zh_posts_index.html.46dc1fe4.js" as="script"><link rel="prefetch" href="/assets/js/posts_jd_index.html.7a8d7890.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!----><!--[--><a class="route-link vp-brand" href="/" aria-label="Take me home"><img class="vp-nav-logo" src="/bubu.jpg" alt><!----><span class="vp-site-name hide-in-pad">Ruochen Chen</span></a><!--]--><!----></div><div class="vp-navbar-center"><!----><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="Blog Home"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span><!--]-->Blog Home<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Posts"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>Posts<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Algorithm</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/algorithm/" aria-label="Algorithm Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Algorithm Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">AWS-SAA</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/aws-saa/" aria-label="AWS-SAA Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->AWS-SAA Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Clich√©</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/clich%C3%A9/" aria-label="Clich√© Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Clich√© Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">China Merchant Bank</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/cmb/" aria-label="CMB Internship Record"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->CMB Internship Record<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Docker</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/docker/" aria-label="Docker Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Docker Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Dubbo</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/dubbo/" aria-label="Dubbo Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Dubbo Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">ElasticSearch</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/elasticsearch/" aria-label="ElasticSearch Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->ElasticSearch Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Hadoop and Hive</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/hadoop/" aria-label="Hadoop and Hive Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Hadoop and Hive Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Interview</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/interview/" aria-label="Interview Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Interview Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Kubernetes</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/kubernetes/concepts/" aria-label="Concepts"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Concepts<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/kubernetes/practices/" aria-label="Practices"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Practices<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/kubernetes/microsvc/" aria-label="MicroSvc"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->MicroSvc<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">MyBatis</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/mybatis/" aria-label="MyBatis Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->MyBatis Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">NextJS</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/nextjs/" aria-label="NextJS Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->NextJS Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">NGINX</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/nginx/" aria-label="NGINX Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->NGINX Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Note</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/note/" aria-label="Notes"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Notes<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Tailwind CSS</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/tailwind/" aria-label="Tailwind CSS Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Tailwind CSS Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Typescript</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/typescript/" aria-label="Typescript Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Typescript Contents<!----></a></li></ul></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle">Unimelb Notes</h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link route-link-active auto-link" href="/posts/unimelb/" aria-label="Unimelb Notes Contents"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Unimelb Notes Contents<!----></a></li></ul></li></ul></button></div></div></nav><!--]--><!----></div><div class="vp-navbar-end"><!----><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/posts/unimelb/ml.html" aria-label="English"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/zh/" aria-label="ÁÆÄ‰Ωì‰∏≠Êñá"><!---->ÁÆÄ‰Ωì‰∏≠Êñá<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/Crc011220/Crc011220.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-outlook-button" tabindex="-1" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" class="icon outlook-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="outlook icon" name="outlook"><path d="M224 800c0 9.6 3.2 44.8 6.4 54.4 6.4 48-48 76.8-48 76.8s80 41.6 147.2 0 134.4-134.4 38.4-195.2c-22.4-12.8-41.6-19.2-57.6-19.2C259.2 716.8 227.2 761.6 224 800zM560 675.2l-32 51.2c-51.2 51.2-83.2 32-83.2 32 25.6 67.2 0 112-12.8 128 25.6 6.4 51.2 9.6 80 9.6 54.4 0 102.4-9.6 150.4-32l0 0c3.2 0 3.2-3.2 3.2-3.2 22.4-16 12.8-35.2 6.4-44.8-9.6-12.8-12.8-25.6-12.8-41.6 0-54.4 60.8-99.2 137.6-99.2 6.4 0 12.8 0 22.4 0 12.8 0 38.4 9.6 48-25.6 0-3.2 0-3.2 3.2-6.4 0-3.2 3.2-6.4 3.2-6.4 6.4-16 6.4-16 6.4-19.2 9.6-35.2 16-73.6 16-115.2 0-105.6-41.6-198.4-108.8-268.8C704 396.8 560 675.2 560 675.2zM224 419.2c0-28.8 22.4-51.2 51.2-51.2 28.8 0 51.2 22.4 51.2 51.2 0 28.8-22.4 51.2-51.2 51.2C246.4 470.4 224 448 224 419.2zM320 284.8c0-22.4 19.2-41.6 41.6-41.6 22.4 0 41.6 19.2 41.6 41.6 0 22.4-19.2 41.6-41.6 41.6C339.2 326.4 320 307.2 320 284.8zM457.6 208c0-12.8 12.8-25.6 25.6-25.6 12.8 0 25.6 12.8 25.6 25.6 0 12.8-12.8 25.6-25.6 25.6C470.4 233.6 457.6 220.8 457.6 208zM128 505.6C128 592 153.6 672 201.6 736c28.8-60.8 112-60.8 124.8-60.8-16-51.2 16-99.2 16-99.2l316.8-422.4c-48-19.2-99.2-32-150.4-32C297.6 118.4 128 291.2 128 505.6zM764.8 86.4c-22.4 19.2-390.4 518.4-390.4 518.4-22.4 28.8-12.8 76.8 22.4 99.2l9.6 6.4c35.2 22.4 80 12.8 99.2-25.6 0 0 6.4-12.8 9.6-19.2 54.4-105.6 275.2-524.8 288-553.6 6.4-19.2-3.2-32-19.2-32C777.6 76.8 771.2 80 764.8 86.4z"></path></svg><div class="vp-outlook-dropdown"><!----></div></button></div><!--[--><div id="docsearch-container" style="display:none;"></div><div><button type="button" class="DocSearch DocSearch-Button" aria-label="Search Blogs"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search Blogs</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"><svg width="15" height="15" class="DocSearch-Control-Key-Icon"><path d="M4.505 4.496h2M5.505 5.496v5M8.216 4.496l.055 5.993M10 7.5c.333.333.5.667.5 1v2M12.326 4.5v5.996M8.384 4.496c1.674 0 2.116 0 2.116 1.5s-.442 1.5-2.116 1.5M3.205 9.303c-.09.448-.277 1.21-1.241 1.203C1 10.5.5 9.513.5 8V7c0-1.57.5-2.5 1.464-2.494.964.006 1.134.598 1.24 1.342M12.553 10.5h1.953" stroke-width="1.2" stroke="currentColor" fill="none" stroke-linecap="square"></path></svg></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--><!--]--><!----><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="Blog Home"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-home" style=""></span><!--]-->Blog Home<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><span class="font-icon icon fa-fw fa-sm fas fa-book" style=""></span><span class="vp-sidebar-title">Posts</span><!----></p><ul class="vp-sidebar-links"><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Ai</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Algorithm</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Aws Saa</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Clich√©</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Cmb</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Docker</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Dubbo</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Elasticsearch</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/genesis.html" aria-label="Genesis"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Genesis<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Hadoop</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Interview</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Istio</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Jd</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Kubernetes</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Mybatis</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Nextjs</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Nginx</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Note</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Spark</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Tailwind</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Typescript</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Unimelb</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/unimelb/COMP90050.html" aria-label="Advanced Database Systems (COMP90050)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Advanced Database Systems (COMP90050)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/unimelb/COMP90024.html" aria-label="Cluster and Cloud Computing (COMP90024)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Cluster and Cloud Computing (COMP90024)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/unimelb/COMP90048.html" aria-label="Declarative Programming (COMP90048)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Declarative Programming (COMP90048)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/unimelb/GEOM90007.html" aria-label="Information Visualisation (GEOM90007)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Information Visualisation (GEOM90007)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/unimelb/COMP90049.html" aria-label="Introduction to Machine Learning (COMP90049)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Introduction to Machine Learning (COMP90049)<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/posts/unimelb/ml.html" aria-label="Machine Learning"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Machine Learning<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/unimelb/SWEN90016.html" aria-label="Software Process and Management (SWEN90016)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Software Process and Management (SWEN90016)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/unimelb/GEOM90008.html" aria-label="Spatial Data Management (GEOM90008)"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->Spatial Data Management (GEOM90008)<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/unimelb/" aria-label="UNIMELB Course Notes"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span><!--]-->UNIMELB Course Notes<!----></a></li></ul></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="About Me"><!--[--><span class="font-icon icon fa-fw fa-sm fas fa-circle-info" style=""></span><!--]-->About Me<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>Machine Learning</h1><div class="page-info"><span class="page-author-info" aria-label="Authorüñä" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Ruochen Chen</span></span><span property="author" content="Ruochen Chen"></span></span><!----><span class="page-date-info" aria-label="Writing DateüìÖ" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">June 19, 2025</span><meta property="datePublished" content="2025-06-19T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time‚åõ" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 31 min</span><meta property="timeRequired" content="PT31M"></span><span class="page-category-info" aria-label="Categoryüåà" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color5 clickable" role="navigation">Learning Records</span><!--]--><meta property="articleSection" content="Learning Records"></span><span class="page-tag-info" aria-label="Tagüè∑" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color7 clickable" role="navigation">Unimelb</span><!--]--><meta property="keywords" content="Unimelb"></span></div><hr></div><div class="vp-toc-placeholder"><aside id="toc" vp-toc><!----><div class="vp-toc-header">On This Page<button type="button" class="print-button" title="Print"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#Âì™‰∫õÁÆóÊ≥ïÊïèÊÑü‰∫éÊï∞ÂÄºËåÉÂõ¥">Âì™‰∫õÁÆóÊ≥ïÊïèÊÑü‰∫éÊï∞ÂÄºËåÉÂõ¥Ôºü</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#ÁÆóÊ≥ï">ÁÆóÊ≥ï</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#Ë∑ùÁ¶ªËÆ°ÁÆó">Ë∑ùÁ¶ªËÆ°ÁÆó</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#kÁöÑÈÄâÊã©">KÁöÑÈÄâÊã©</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#elipson-smoothing">Elipson-Smoothing</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#laplace-smoothing">Laplace Smoothing</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#mse-rmse-mae">MSE, RMSE, MAE</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#gradient-descent">Gradient Descent</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#gradient-descent-1">Gradient Descent</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#odds">Odds</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#scalling">Scalling</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#use-logistic-regression-as-multi-class-classification">Use Logistic Regression as multi-class classification</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#application">Application</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#split-data-into-train-validation-test">Split data into train, validation, test</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#why-split-data-into-train-validation-test">Why split data into train, validation, test</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#confusion-matrix">Confusion Matrix</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#holdout-vs-cross-validation">Holdout vs. Cross-Validation</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#accuracy-precision-recall-f1-score">Accuracy, Precision, Recall, F1-Score</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#compute-for-entire-model">Compute for entire model</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#covariance-matrix">Covariance Matrix</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#pcaÁº∫ÁÇπ">PCAÁº∫ÁÇπ</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#perceptron-learning-rule">Perceptron learning rule</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#example">Example</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#üåüËÉåÊôØÁü•ËØÜ">üåüËÉåÊôØÁü•ËØÜ</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#üî¢-ËæìÂÖ•Êï∞ÊçÆ">üî¢ ËæìÂÖ•Êï∞ÊçÆ</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#üß†-Á¨¨‰∫åÂ±ÇÊÑüÁü•Âô®">üß† Á¨¨‰∫åÂ±ÇÊÑüÁü•Âô®</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#üîÅ-ÊùÉÈáçÊõ¥Êñ∞ËøáÁ®ã">üîÅ ÊùÉÈáçÊõ¥Êñ∞ËøáÁ®ã</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#üßÆ-epoch-ËÆ≠ÁªÉËΩÆÊ¨°-Ëß£Èáä">üßÆ EpochÔºàËÆ≠ÁªÉËΩÆÊ¨°ÔºâËß£ÈáäÔºö</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#‚úÖ-Êî∂ÊïõÊù°‰ª∂">‚úÖ Êî∂ÊïõÊù°‰ª∂</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#üèÅ-ÊúÄÁªàÊùÉÈáç">üèÅ ÊúÄÁªàÊùÉÈáç</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#üß†-ÊÄªÁªì">üß† ÊÄªÁªì</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#feature-learning">Feature Learning</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#activation-function">activation function</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#output-function">output function</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#loss-function">loss function</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#k-means">K-Means</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#ÁÆóÊ≥ïÊ≠•È™§">ÁÆóÊ≥ïÊ≠•È™§</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#k-meansÁº∫ÁÇπ">K-MeansÁº∫ÁÇπ</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#evaluate-the-goodness-of-a-clustering-structure-without-relying-on-external-information-i-e-unsupervised-evaluation">evaluate the goodness of a clustering structure without relying on external information (i.e., unsupervised evaluation)</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#cluster-cohesion-compactness-tightness">Cluster cohesion (compactness, tightness)</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#cluster-separation-isolation-distinctiveness">Cluster separation (isolation, distinctiveness)</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#supervised-clustering-evaluation">Supervised Clustering evaluation</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#hierarchical-clustering">Hierarchical Clustering</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#linkage-method">Linkage Method</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#agglomerative-clustering">Agglomerative Clustering</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#divisive-clustering">Divisive Clustering</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#self-training">Self-Training</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#ÁÆóÊ≥ïÊ≠•È™§-1">ÁÆóÊ≥ïÊ≠•È™§</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#confidence-threshold">Confidence Threshold</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#active-learning">Active Learning</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#query-strategy">Query Strategy</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#bagging">Bagging</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#stacking">Stacking</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#boosting">Boosting</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#Ë∑ùÁ¶ªÂ∫¶Èáè-distance-metrics">Ë∑ùÁ¶ªÂ∫¶Èáè (Distance Metrics)</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-Ê¨ßÂá†ÈáåÂæóË∑ùÁ¶ª-euclidean-distance">1. Ê¨ßÂá†ÈáåÂæóË∑ùÁ¶ª (Euclidean Distance)</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-ÊõºÂìàÈ°øË∑ùÁ¶ª-manhattan-distance">2. ÊõºÂìàÈ°øË∑ùÁ¶ª (Manhattan Distance)</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-‰ΩôÂº¶Áõ∏‰ººÂ∫¶-cosine-similarity">3. ‰ΩôÂº¶Áõ∏‰ººÂ∫¶ (Cosine Similarity)</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#ÂàÜÁ±ªËØÑ‰º∞ÊåáÊ†á-classification-metrics">ÂàÜÁ±ªËØÑ‰º∞ÊåáÊ†á (Classification Metrics)</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#Âü∫Á°ÄÊåáÊ†á">Âü∫Á°ÄÊåáÊ†á</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#Â§öÂàÜÁ±ªËØÑ‰º∞">Â§öÂàÜÁ±ªËØÑ‰º∞</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#ÂõûÂΩíËØÑ‰º∞ÊåáÊ†á-regression-metrics">ÂõûÂΩíËØÑ‰º∞ÊåáÊ†á (Regression Metrics)</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_1-ÂùáÊñπËØØÂ∑Æ-mse-mean-squared-error">1. ÂùáÊñπËØØÂ∑Æ (MSE - Mean Squared Error)</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_2-ÂùáÊñπÊ†πËØØÂ∑Æ-rmse-root-mean-squared-error">2. ÂùáÊñπÊ†πËØØÂ∑Æ (RMSE - Root Mean Squared Error)</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#_3-Âπ≥ÂùáÁªùÂØπËØØÂ∑Æ-mae-mean-absolute-error">3. Âπ≥ÂùáÁªùÂØπËØØÂ∑Æ (MAE - Mean Absolute Error)</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#z-score">Z-Score</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#standard-deviation">Standard Deviation</a></li><!----><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="machine-learning" tabindex="-1"><a class="header-anchor" href="#machine-learning"><span>Machine Learning</span></a></h1><table><thead><tr><th>Algorithm</th><th>Type</th><th>Generative/Discriminative</th><th>Linear/Non-linear</th><th>Notes</th></tr></thead><tbody><tr><td>Naive Bayes</td><td>Classification</td><td>Generative</td><td>Linear</td><td>Assumes feature independence, uses Bayes&#39; theorem</td></tr><tr><td>Logistic Regression</td><td>Classification</td><td>Discriminative</td><td>Linear</td><td>Uses sigmoid function, mainly for binary classification</td></tr><tr><td>Decision Trees</td><td>Classification</td><td>Discriminative</td><td>Non-linear</td><td>Handles both numerical and categorical features</td></tr><tr><td>SVM</td><td>Classification</td><td>Discriminative</td><td>Linear/Non-linear</td><td>Uses kernel trick for non-linear, finds optimal hyperplane</td></tr><tr><td>k-NN</td><td>Classification</td><td>Discriminative</td><td>Non-linear</td><td>Instance-based, sensitive to feature scaling</td></tr><tr><td>Neural Networks</td><td>Classification</td><td>Discriminative</td><td>Non-linear</td><td>Can model complex patterns, requires large datasets</td></tr><tr><td>Linear Regression</td><td>Regression</td><td>Discriminative</td><td>Linear</td><td>Predicts continuous values, sensitive to multicollinearity</td></tr><tr><td>k-Means</td><td>Clustering</td><td>-</td><td>Linear</td><td>Unsupervised, sensitive to initial centroids and outliers</td></tr><tr><td>PCA</td><td>Dimensionality Reduction</td><td>-</td><td>Linear</td><td>Unsupervised, maximizes variance, does not consider class labels</td></tr><tr><td>Hierarchical Clustering</td><td>Clustering</td><td>-</td><td>Non-linear</td><td>Unsupervised, builds nested clusters, linkage methods affect results</td></tr><tr><td>Perceptron</td><td>Classification</td><td>Discriminative</td><td>Linear</td><td>Simple model, only for linearly separable data</td></tr><tr><td>Multi-Layer Perceptron</td><td>Classification/Regression</td><td>Discriminative</td><td>Non-linear</td><td>Can solve XOR problem, uses backpropagation for training</td></tr></tbody></table><h1 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction"><span>Introduction</span></a></h1><ul><li>An instance is a single exemplar from the data, consisting of a bundle of (possibly unknown) attribute values (feature values) (and, in the case of supervised ML, a class value). ‰∏ÄË°åÊï∞ÊçÆ</li><li>An feature (attribute) is a single measurement of some aspect of an instance, for example, the frequency of some event related to this instance, or the label of some meaningful category. ÊØè‰∏™Âàó‰∏äÁöÑÁâπÂæÅ„ÄÅ</li><li>label(concepts) refers to the output variable that a machine learning model predicts or classifies. ÊúÄÂêé‰∏ÄÂàóÁöÑÊ†áÁ≠æ„ÄÅ</li></ul><table><thead><tr><th>È°πÁõÆ</th><th>Supervised LearningÔºàÁõëÁù£Â≠¶‰π†Ôºâ</th><th>Semi-supervised LearningÔºàÂçäÁõëÁù£Â≠¶‰π†Ôºâ</th><th>Unsupervised LearningÔºàÊó†ÁõëÁù£Â≠¶‰π†Ôºâ</th></tr></thead><tbody><tr><td><strong>ÂÆö‰πâ</strong></td><td>‰ΩøÁî®Â∏¶Ê†áÁ≠æÁöÑÊï∞ÊçÆËÆ≠ÁªÉÊ®°Âûã</td><td>‰ΩøÁî®Â∞ëÈáèÂ∏¶Ê†áÁ≠æ + Â§ßÈáèÊú™Ê†áËÆ∞Êï∞ÊçÆ</td><td>‰ΩøÁî®Êú™Ê†áËÆ∞Êï∞ÊçÆÂèëÁé∞ÁªìÊûÑÊàñÊ®°Âºè</td></tr><tr><td><strong>ËÆ≠ÁªÉÊï∞ÊçÆ</strong></td><td>ÂÖ®ÈÉ®Êï∞ÊçÆÈÉΩÊúâÊ†áÁ≠æ (x, y)</td><td>ÈÉ®ÂàÜÊï∞ÊçÆÊúâÊ†áÁ≠æÔºåÂÖ∂‰ΩôÊ≤°Êúâ</td><td>ÊâÄÊúâÊï∞ÊçÆÈÉΩÊ≤°ÊúâÊ†áÁ≠æ</td></tr><tr><td><strong>ÁõÆÊ†á</strong></td><td>Â≠¶‰π†‰ªéËæìÂÖ•Âà∞ËæìÂá∫ÁöÑÊò†Â∞ÑÂáΩÊï∞</td><td>Âà©Áî®Êú™Ê†áËÆ∞Êï∞ÊçÆËæÖÂä©ÊèêÂçáÁõëÁù£Â≠¶‰π†ÊÄßËÉΩ</td><td>ÊåñÊéòÊï∞ÊçÆÁöÑÈöêËóèÁªìÊûÑ„ÄÅËÅöÁ±ªÊàñÈôçÁª¥</td></tr><tr><td><strong>‰ºòÁÇπ</strong></td><td>- ÊÄßËÉΩÂ•ΩÔºåÈ¢ÑÊµãÂáÜÁ°Æ<br>- Êòì‰∫éËØÑ‰º∞</td><td>- Èôç‰ΩéÊ†áÊ≥®ÊàêÊú¨<br>- Âà©Áî®Êõ¥Â§öÊï∞ÊçÆ<br>- ‰ªã‰∫é‰∏§ËÄÖ‰πãÈó¥</td><td>- Êó†ÈúÄ‰∫∫Â∑•Ê†áÊ≥®<br>- ÂèØÂèëÁé∞ÊΩúÂú®ÁªìÊûÑ</td></tr><tr><td><strong>Áº∫ÁÇπ</strong></td><td>- ÈúÄË¶ÅÂ§ßÈáèÊ†áÊ≥®Êï∞ÊçÆ<br>- ÊàêÊú¨È´ò</td><td>- Ê®°ÂûãËæÉÂ§çÊùÇÔºåÈöæ‰ª•Ë∞É‰ºò<br>- ‰æùËµñÊ†áÁ≠æË¥®Èáè</td><td>- Ê≤°ÊúâÊòéÁ°ÆÁöÑËØÑ‰º∞Ê†áÂáÜ<br>- ÁªìÊûú‰∏ç‰∏ÄÂÆöÂèØËß£Èáä</td></tr><tr><td><strong>Â∏∏ËßÅÁÆóÊ≥ï</strong></td><td>- Logistic Regression<br>- Decision Trees <br>- Naive Bayes<br>- SVM<br>- k-NN<br>- Neural Networks</td><td>- Self-Training<br>- Active Learning</td><td>- k-Means<br>- PCA<br>- Hierarchical Clustering</td></tr><tr><td><strong>Â∫îÁî®Âú∫ÊôØ</strong></td><td>- ÂõæÂÉèËØÜÂà´<br>- ÊñáÊú¨ÂàÜÁ±ª<br>- ÂåªÁñóËØäÊñ≠</td><td>- ÂåªÁñóÂΩ±ÂÉèÂàÜÊûêÔºàÊ†áÁ≠æÁ®ÄÁº∫Ôºâ<br>- ÁΩëÁªúÂÆâÂÖ®<br>- Â≠¶ÊúØÊñáÊú¨ÂàÜÁ±ª</td><td>- ÂÆ¢Êà∑ÂàÜÁæ§<br>- ÂºÇÂ∏∏Ê£ÄÊµã<br>- Êé®ËçêÁ≥ªÁªüÈôçÁª¥</td></tr><tr><td><strong>Ê†áÁ≠æ‰æùËµñ</strong></td><td>È´ò</td><td>‰∏≠Á≠â</td><td>Êó†</td></tr><tr><td><strong>Â≠¶‰π†Á≠ñÁï•</strong></td><td>ÊãüÂêàÊ†áÁ≠æÈ¢ÑÊµã</td><td>ÁªìÂêàÁõëÁù£‰∏éÊó†ÁõëÁù£ÁöÑÊñπÂºè</td><td>Âà©Áî®Áõ∏‰ººÊÄß„ÄÅË∑ùÁ¶ª„ÄÅÂØÜÂ∫¶Á≠âËá™ÁªÑÁªáÁªìÊûÑ</td></tr></tbody></table><table><thead><tr><th>Êï∞ÊçÆÁ±ªÂûã/ÁÆóÊ≥ï</th><th>NominalÔºàÁ±ªÂà´ÔºåÊó†È°∫Â∫èÔºâ</th><th>OrdinalÔºàÁ±ªÂà´ÔºåÊúâÈ°∫Â∫èÔºâ</th><th>NumericÔºàÊï∞ÂÄºÂûãÔºâ</th></tr></thead><tbody><tr><td><strong>Logistic Regression</strong></td><td>‚ùåÔºàÈúÄ One-Hot ÁºñÁ†ÅÔºâ</td><td>‚ö†Ô∏èÔºàÂª∫ËÆÆÁî®Êï¥Êï∞Ôºå‰ΩÜÂ∞èÂøÉÁ∫øÊÄßÂÖ≥Á≥ªÔºâ</td><td>‚úÖÔºàÂ§©ÁÑ∂ÊîØÊåÅÔºâ</td></tr><tr><td><strong>Decision Trees</strong></td><td>‚úÖÔºàÁõ¥Êé•ÊîØÊåÅÔºâ</td><td>‚úÖÔºàÈ°∫Â∫èÂèØÂΩ±ÂìçÂàíÂàÜÔºâ</td><td>‚úÖÔºàÂ§©ÁÑ∂ÊîØÊåÅÔºâ</td></tr><tr><td><strong>Naive Bayes</strong></td><td>‚úÖÔºàÈùûÂ∏∏ÈÄÇÂêàÔºåÂ¶ÇÂ§öÈ°πÂºèNBÔºâ</td><td>‚ö†Ô∏èÔºàÂèØÂΩì‰Ωú nominal Â§ÑÁêÜÔºå‰ΩÜÊúâÈ°∫Â∫è‰ø°ÊÅØÊú™Ë¢´Âà©Áî®Ôºâ</td><td>‚úÖÔºàÈúÄ‰ΩøÁî®È´òÊñØNBÔºâ</td></tr><tr><td><strong>SVM</strong></td><td>‚ùåÔºàÈúÄ One-Hot ÊàñÊï∞ÂÄºÁºñÁ†ÅÔºâ</td><td>‚ö†Ô∏èÔºàÂèØËΩ¨Êï∞ÂÄºÔºå‰ΩÜÂΩ±ÂìçÂ§ßÔºâ</td><td>‚úÖ</td></tr><tr><td><strong>k-NN</strong></td><td>‚ö†Ô∏èÔºàÂèØÁºñÁ†Å‰ΩÜË∑ùÁ¶ªËÆ°ÁÆóË¶ÅÂ∞èÂøÉÔºâ</td><td>‚ö†Ô∏èÔºàÈ°∫Â∫èÂèØÁºñÁ†ÅÔºå‰ªçÈúÄË∞®ÊÖéÔºâ</td><td>‚úÖ</td></tr><tr><td><strong>Neural Networks</strong></td><td>‚ùåÔºàÈúÄÁã¨ÁÉ≠ÁºñÁ†ÅÊàñÂµåÂÖ•Ôºâ</td><td>‚ö†Ô∏èÔºàÁî®ÂµåÂÖ•ÊàñÊï∞ÂÄºÔºå‰ΩÜÊ≥®ÊÑèËØØÂØºÔºâ</td><td>‚úÖ</td></tr><tr><td><strong>k-Means</strong></td><td>‚ùåÔºà‰∏çÈÄÇÂêàÈùûÊï∞ÂÄºÊï∞ÊçÆÔºâ</td><td>‚ö†Ô∏èÔºàÂèØÂ∞ùËØïÁºñÁ†ÅÔºå‰ΩÜ‰∏çÊé®ËçêÔºâ</td><td>‚úÖÔºàÂøÖÈ°ªÊòØÊï∞ÂÄºÂûãÔºâ</td></tr><tr><td><strong>PCA</strong></td><td>‚ùåÔºà‰ªÖÈôêÊï∞ÂÄºÂûãÔºâ</td><td>‚ùåÔºà‰∏çÂèØÁî®‰∫éÁ±ªÂà´Ôºâ</td><td>‚úÖÔºàÂøÖÈ°ªÊòØÊï∞ÂÄºÂûãÔºâ</td></tr><tr><td><strong>Hierarchical Clustering</strong></td><td>‚ö†Ô∏èÔºàÈúÄË∑ùÁ¶ªÂÆö‰πâÔºåÁºñÁ†ÅÂêéÂèØÁî®Ôºâ</td><td>‚ö†Ô∏èÔºàÈ°∫Â∫èÁºñÁ†ÅÊúâÊó∂ÂêàÁêÜÔºâ</td><td>‚úÖÔºàÂ∏∏ËßÅ‰ΩøÁî®Ôºâ</td></tr></tbody></table><h2 id="Âì™‰∫õÁÆóÊ≥ïÊïèÊÑü‰∫éÊï∞ÂÄºËåÉÂõ¥" tabindex="-1"><a class="header-anchor" href="#Âì™‰∫õÁÆóÊ≥ïÊïèÊÑü‰∫éÊï∞ÂÄºËåÉÂõ¥"><span>Âì™‰∫õÁÆóÊ≥ïÊïèÊÑü‰∫éÊï∞ÂÄºËåÉÂõ¥Ôºü</span></a></h2><p>‚úÖ ÂèóÂΩ±ÂìçÔºöSVM, k-NN, PCA, Ê¢ØÂ∫¶‰∏ãÈôçÁ±ªÊ®°ÂûãÔºàÂ¶ÇÈÄªËæëÂõûÂΩí„ÄÅÁ•ûÁªèÁΩëÁªúÔºâ</p><p>‚ùå ‰∏çÊïèÊÑüÔºöÂÜ≥Á≠ñÊ†ë„ÄÅÈöèÊú∫Ê£ÆÊûó„ÄÅÊú¥Á¥†Ë¥ùÂè∂ÊñØ</p><table><thead><tr><th>ÊñπÊ≥ï</th><th>‰πüÂè´</th><th>‰ΩúÁî®</th><th>Êï∞Â≠¶ÂΩ¢Âºè</th></tr></thead><tbody><tr><td><strong>Scaling</strong></td><td>Min-Max Scaling</td><td>Áªü‰∏ÄÊï∞ÂÄºËåÉÂõ¥Ôºà‰∏çÊîπÂèòÂàÜÂ∏ÉÂΩ¢Áä∂Ôºâ</td><td>$x&#39; = \frac{x - \min(x)}{\max(x) - \min(x)}$</td></tr><tr><td><strong>Normalization</strong></td><td>Standardization / Z-score</td><td>Áªü‰∏ÄÂàÜÂ∏ÉÂΩ¢Áä∂ÔºàÂèò‰∏∫ÂùáÂÄº0ÊñπÂ∑Æ1Ôºâ</td><td>$x&#39; = \frac{x - \mu}{\sigma}$</td></tr></tbody></table><h1 id="knn" tabindex="-1"><a class="header-anchor" href="#knn"><span>KNN</span></a></h1><p>classification and regression</p><h2 id="ÁÆóÊ≥ï" tabindex="-1"><a class="header-anchor" href="#ÁÆóÊ≥ï"><span>ÁÆóÊ≥ï</span></a></h2><ul><li>Choose k: Decide the number of nearest neighbors (k).</li><li>Compute Distance: Measure the distance between the test instance and all training instances (e.g., Euclidean distance, Manhattan distance, or Cosine similarity).</li><li>Find Nearest Neighbors: Select the k closest training instances.</li><li>Predict the Output: <ul><li>For classification, use majority voting or weighted voting among the k neighbors.</li><li>For regression, take the average or weighted average of the k neighbors&#39; values.</li></ul></li></ul><h2 id="Ë∑ùÁ¶ªËÆ°ÁÆó" tabindex="-1"><a class="header-anchor" href="#Ë∑ùÁ¶ªËÆ°ÁÆó"><span>Ë∑ùÁ¶ªËÆ°ÁÆó</span></a></h2><ul><li>Majority class voting: ÈÄâÊã©Âá∫Áé∞Ê¨°Êï∞ÊúÄÂ§öÁöÑÁ±ªÂà´‰Ωú‰∏∫È¢ÑÊµãÁªìÊûúÔºå‰∏çÁÆ°ËøúËøëweightÈÉΩ‰∏ÄÊ†∑</li><li>inverse distance weighting: Ê†πÊçÆË∑ùÁ¶ªÁöÑÂÄíÊï∞Âä†ÊùÉÔºåË∑ùÁ¶ªË∂äËøëÊùÉÈáçË∂äÂ§ß 1/d+Œµ</li><li>Inverse linear distance weighting $$w_j = \frac{d_3 - d_j}{d_3 - d_1}$$ <ul><li>d_3 is the distance of the farthest neighbor (Here is 3NN)</li><li>d_j is the distance of the j-th neighbor ‰ªñÊòØÁ¨¨Âá†ËøúÁöÑÈÇ£‰∏™ÈÇªÂ±ÖÁöÑdistance ÊØîÂ¶ÇÁ¨¨‰∫åËøúÁöÑË∑ùÁ¶ªÊòØ4 Â∞±Â°´4</li></ul></li><li>Cosine similarity: ËÆ°ÁÆó‰∏§‰∏™ÂêëÈáè‰πãÈó¥ÁöÑÂ§πËßí‰ΩôÂº¶ÂÄºÔºåÂÄºË∂äÂ§ßË∂äÁõ∏‰ºº <ul><li>cosine similarity = dot product / (magnitude of x * magnitude of y) $$\cos(\theta) = \frac{A \cdot B}{|A| |B|}$$</li><li>magnitude of x = sqrt(x1^2 + x2^2 + ... + xn^2)</li><li>cosine distance = 1 - cosine similarity <ul><li>high distance means low similarity</li></ul></li></ul></li></ul><h2 id="kÁöÑÈÄâÊã©" tabindex="-1"><a class="header-anchor" href="#kÁöÑÈÄâÊã©"><span>KÁöÑÈÄâÊã©</span></a></h2><ul><li>Â¶ÇÊûúkÂ§™Â∞èÔºåÊ®°Âûã‰ºöËøáÊãüÂêàÔºåÂõ†‰∏∫Ê®°Âûã‰ºöËøáÂ∫¶‰æùËµñ‰∫éÊúÄËøëÁöÑÈÇªÂ±ÖÔºåÂØºËá¥Ê®°ÂûãÂØπÂô™Â£∞ÊïèÊÑü</li><li>Â¶ÇÊûúkÂ§™Â§ßÔºåÊ®°Âûã‰ºöÊ¨†ÊãüÂêàÔºåÂõ†‰∏∫Ê®°Âûã‰ºöÂøΩÁï•ÁâπÂæÅÂ∑ÆÂºÇÔºåÂØºËá¥Ê®°ÂûãÂØπÂô™Â£∞‰∏çÊïèÊÑü <ul><li>Â¶ÇÊûúk=NÔºå ÂøΩÁï•ÁâπÂæÅÂ∑ÆÂºÇÔºåÈÄÄÂåñÊàêÂ§öÊï∞Á±ªÊäïÁ•®Ê≥ï</li></ul></li></ul><h1 id="probability" tabindex="-1"><a class="header-anchor" href="#probability"><span>Probability</span></a></h1><ul><li>marginal probability: Âè™ÂÖ≥Ê≥®Êüê‰∏Ä‰∏™ÂèòÈáèÁöÑÊ¶ÇÁéáÔºåÂøΩÁï•ÔºàËæπÁºòÂåñÔºâÂÖ∂‰ªñÂèòÈáè</li><li>conditional probability: Âú®ÁªôÂÆöÂÖ∂‰ªñÂèòÈáèÁöÑÊÉÖÂÜµ‰∏ãÔºåÊüê‰∏Ä‰∏™ÂèòÈáèÁöÑÊ¶ÇÁéá</li><li>joint probability: ‰∏§‰∏™‰∫ã‰ª∂ÂêåÊó∂ÂèëÁîüÁöÑÊ¶ÇÁéá</li><li>disjoint events: ‰∏§‰∏™‰∫ã‰ª∂‰∏çËÉΩÂêåÊó∂ÂèëÁîü</li><li>Bayes&#39; theorem: $$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$ <ul><li>P(A|B) is the probability of A given B</li><li>P(B|A) is the probability of B given A</li><li>P(A) is the probability of A</li><li>P(B) is the probability of B</li></ul></li></ul><h1 id="decision-trees" tabindex="-1"><a class="header-anchor" href="#decision-trees"><span>Decision Trees</span></a></h1><p>classification and regression</p><p>handle numerical and categorical features</p><ul><li>0-R <ul><li>Áõ¥Êé•È¢ÑÊµãÊúÄÈ¢ëÁπÅÁöÑÁ±ª</li></ul></li><li>1-R(decision stump) <ul><li>ÈÄâÊã©ÊúÄÂ∞ëÁöÑerror countÁöÑfeature, ÁÑ∂ÂêéÊ†πÊçÆÈÄâÊã©ÁöÑfeatureËøõË°åÈ¢ÑÊµã</li></ul></li><li>Information Gain (for classification)Ôºöchoose the attribute that has th largest difference between the entropy of the class distribution at the parent node, and the average entropy across its daughter nodes (weighted by the fraction of instances at each node)</li></ul><p>$$ IG(A|R) = H(R) - \sum_{i \in A} P(A = i) H(A = i) $$</p><p>$$ IG(O) = H(R) - MI(O) $$</p><ul><li>In this dataset, we have <strong>6 instances total</strong>‚Äî<strong>3 Y</strong> and <strong>3 N</strong>. The entropy at the <strong>top level</strong> of our tree is:</li></ul><p>$$ H(R) = - \left[ \frac{3}{6} \log_2 \frac{3}{6} + \frac{3}{6} \log_2 \frac{3}{6} \right] $$</p><ul><li><p>average entropyÔºà‰πüÂ∞±ÊòØMI Mean InformationÔºâ: sum the calculated entropy at each daughter multiplied by the fraction of instances at that daughter</p></li><li><p>ÊúÄÁªàÈÄâÊã©ÊúÄÈ´òÁöÑIGÁöÑfeatureËøõË°åsplitÔºåpureÁöÑnodeÂ∞±Áõ¥Êé•ÂÅúÔºåÂ¶ÇÊûú‰∏Ä‰∏™Â≠êÈõÜ‰∏çÊòØÁ∫ØÁöÑÔºàÂç≥ÂÖ∂‰∏≠ÁöÑÊ†∑Êú¨‰∏çÂÖ®Â±û‰∫éÂêå‰∏ÄÁ±ªÂà´ÔºâÔºåÈÇ£‰πàÂ∞±ÈúÄË¶ÅÁªßÁª≠ÂàÜË£ÇÔºåÁõ¥Âà∞ËææÂà∞ÂÅúÊ≠¢Êù°‰ª∂‰∏∫Ê≠¢„ÄÇ</p></li><li><p>Gain Ratio (for classification) $$ GR(A|R) = \frac{IG(A|R)}{SplitInfo(A|R)} $$ $$SI(o) = - \left[ \frac{2}{6} \log_2 \frac{2}{6} + \frac{1}{6} \log_2 \frac{1}{6} + \frac{3}{6} \log_2 \frac{3}{6} \right] \approx 1.459$$</p></li><li><p>ÊØîÂ¶ÇËØ¥outlookÈáåÊúâ‰∏§‰∏™sÔºå‰∏Ä‰∏™nÔºå‰∏â‰∏™qÔºåsplitinfoÂ¶Ç‰∏ä</p></li><li><p>IGÊúâhigh-arity biasÔºåÊâÄ‰ª•ÈúÄË¶ÅÁî®gain ratioÊù•Ëß£ÂÜ≥</p></li></ul><h1 id="naive-bayes" tabindex="-1"><a class="header-anchor" href="#naive-bayes"><span>Naive Bayes</span></a></h1><p>primarily for classification</p><ol><li><strong>Calculate Prior Probabilities</strong>: Compute the probability of each class based on the training data.</li><li><strong>Compute Likelihood</strong>: Estimate the probability of features given each class using the conditional probability formula.</li><li><strong>Apply Bayes‚Äô Theorem</strong>: Use Bayes&#39; rule to compute the posterior probability for each class.</li><li><strong>Classify</strong>: Assign the class with the highest posterior probability to the new instance.</li></ol><p>compute example Âì™‰∏™Â§ßÈÄâÂì™‰∏™ Â¶ÇÊûúÊúâ‰∏çÁ°ÆÂÆöÁöÑattriuteÂ∞±Ë∑≥ËøáËÆ°ÁÆó‰ªñ</p><p><strong>N:</strong> $P(N) \times P(\text{Temp} = h \mid N) \times P(\text{Wind} = F \mid N) = \frac{1}{2} \times \frac{2}{3} \times \frac{1}{3} = \frac{1}{9}$</p><p><strong>Y:</strong> $P(Y) \times P(\text{Temp} = h \mid N) \times P(\text{Wind} = F \mid N) = \frac{1}{2} \times \frac{1}{3} \times 1 = \frac{1}{6}$</p><h2 id="elipson-smoothing" tabindex="-1"><a class="header-anchor" href="#elipson-smoothing"><span>Elipson-Smoothing</span></a></h2><ul><li>Instead of using zero values, we replace them with a small positive constant Œµ, which allows us to avoid complete probability collapse</li></ul><h2 id="laplace-smoothing" tabindex="-1"><a class="header-anchor" href="#laplace-smoothing"><span>Laplace Smoothing</span></a></h2><ul><li>Œ±=1 È¢òÁõÆ‰ºöÁªô</li><li>ÂàÜÂ≠êÂä†1ÔºåÂàÜÊØçÂä†Á±ªÂà´Êï∞*Œ±, ÊØîÂ¶Ç‰∏Ä‰∏™outlookÈáåÈù¢Êúâ‰∏â‰∏™Á±ªÂà´x,y,zÔºåÈÇ£‰πàÂàÜÊØçÂä†3</li><li>Âà´Âøò‰∫ÜÊúâ‰∫õÊ¶ÇÁéáÊòØ0ÁöÑÂÖ∂ÂÆû‰ªñÂàÜÊØç‰∏çÊòØ0</li></ul><h1 id="linear-regression" tabindex="-1"><a class="header-anchor" href="#linear-regression"><span>Linear Regression</span></a></h1><p>goal is to find the linear equation that best fits the data, aka minimise the loss function $$ y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \dots + \beta_nx_n + \epsilon $$</p><ul><li><strong>$y$</strong>: Dependent variable (what you&#39;re trying to predict).</li><li><strong>$x_1, x_2, \dots, x_n$</strong>: Independent variables (features or predictors).</li><li><strong>$\beta_0$</strong>: Intercept (the value of $y$ when all $x$ values are 0).</li><li><strong>$\beta_1, \beta_2, \dots, \beta_n$</strong>: Coefficients (the change in $y$ for a one-unit change in each $x$).</li><li><strong>$\epsilon$</strong>: Error term (difference between the actual and predicted values).</li></ul><p>Independent variables being highly correlated with each other, makes the model&#39;s predictions unstable</p><h2 id="mse-rmse-mae" tabindex="-1"><a class="header-anchor" href="#mse-rmse-mae"><span>MSE, RMSE, MAE</span></a></h2><ul><li>If outliers are a concern, RMSE is more sensitive and should be analyzed carefully.</li><li>If we want a more interpretable measure, MAE is often preferred.</li><li>MSE is useful in optimisation tasks, as it provides a continuous loss function for training models.</li></ul><h2 id="gradient-descent" tabindex="-1"><a class="header-anchor" href="#gradient-descent"><span>Gradient Descent</span></a></h2><ul><li>for finding the optimum parameters for a loss function (such as MSE), we first need to calculate the partial derivatives of the loss function (MSE).</li></ul><p>$$MSE(\beta) = \mathcal{L}(\beta) = \frac{1}{N} \sum_{i} (y_i - \hat{y}<em i="">i)^2 = \frac{1}{N} \sum</em> (y_i - x_i^T \beta)^2$$</p><ul><li><p>The partial derivative of the MSE loss function would be: $$\frac{\partial \mathcal{L}}{\partial \beta_k} = -\frac{2}{N} \sum_{i} x_{ik} (y_i - x_i^T \beta_k)$$</p></li><li><p>ÂàùÂßãÂáΩÊï∞ÂèØ‰ª•Èöè‰æøÈÄâÔºåThen, use <strong>Gradient Descent</strong> method to find the $\beta$ that minimises the loss (MSE) in an iterative fashion. $$ \beta_k^{j+1} = \beta_k^j + \Delta \beta_k^j, \quad \text{with} \quad \Delta \beta_k^j = - \eta \frac{\partial \mathcal{L}}{\partial \beta_k^j} $$</p></li><li><p>ËÆ∞‰Ωè beta0ÊòØÂ∏∏Êï∞ ÊâÄ‰ª•‰ªñÁöÑxÊòØ1</p></li><li><p>learning rate is too high, the algorithm may overshoot the minimum and fail to converge.</p></li><li><p>learning rate is too low, the algorithm may converge slowly.</p><ul><li>If we‚Äôre in the first few steps and MSE is increasing, then we can start again with a different initial guess and/or learning rate.</li><li>After several iterations, if the decrease in the MSE becomes negligible, indicating that the gradient is nearly zero, we consider the algorithm to have converged; alternatively, if higher accuracy is desired, we can reduce the learning rate on our current estimate of Œ≤ to further refine the solution.</li></ul></li></ul><h1 id="logistic-regression" tabindex="-1"><a class="header-anchor" href="#logistic-regression"><span>Logistic Regression</span></a></h1><p>classification problem, mainly for binary classification, cannot handle non-linear</p><p>may overfit when A large number of features relative to the number of training examples. ÁâπÂæÅÊï∞ÈáèËøúÂ§ß‰∫éËÆ≠ÁªÉÊ†∑Êú¨Êï∞Èáè</p><p>sigmoid function: $$ \sigma(z) = \frac{1}{1 + e^{-z}} $$</p><p>In <strong>Logistic Regression</strong>, we are regressing (predicting) the <strong>probability</strong> that an input belongs to a certain class.</p><p>The <strong>Logistic Regression model</strong> is:</p><p>$$ P(Y=1 | X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_n X_n)}} $$</p><p>Where:</p><ul><li>$P(Y=1 | X)$ is the <strong>probability</strong> of the data point being in <strong>Class 1</strong>.</li><li>$X_1, X_2, ... X_n$ are the <strong>input features</strong>.</li><li>$\beta_0, \beta_1, ... \beta_n$ are the <strong>coefficients</strong> learned from the data.</li><li>ËÆ∞‰Ωè Ê∞∏ËøúÂÖàÊâæclass1ÁöÑÊ¶ÇÁéá ‰∏ÄËà¨sigmoidÂáΩÊï∞ÊòØ0.5‰∏∫ÂàÜÁïåÁ∫ø Â§ß‰∫é0.5Â∞±ÊòØ1 Â∞è‰∫é0.5Â∞±ÊòØ0 ÁÑ∂Âêéclass0ÁöÑÊ¶ÇÁéáÂ∞±ÊòØ1-class1ÁöÑÊ¶ÇÁéá</li></ul><h2 id="gradient-descent-1" tabindex="-1"><a class="header-anchor" href="#gradient-descent-1"><span>Gradient Descent</span></a></h2><p>$$ \sigma(x_A; \beta) = \sigma(0.2+(0.3\times1+(-2.2)\times0+3.3\times1+(-0.2)\times5))=0.94 $$ ÂÖàÁÆóÂá∫ÊâÄÊúâÁöÑXa,Xb,Xc,Xd,XeÁöÑsigma(x_i; \beta) ÁÑ∂ÂêéËøõË°åÊõ¥Êñ∞ÂèÇÊï∞</p><p>$$ \beta_1 = \beta_1 - \eta \sum_{i \in {A,B,C,D,E}} (\sigma(x_i; \beta) - y_i) x_{1i} $$</p><h2 id="odds" tabindex="-1"><a class="header-anchor" href="#odds"><span>Odds</span></a></h2><p>$$ \text{Odds} = \frac{P(Y=1)}{P(Y=0)} $$ compare the likelihood of the event happening versus not happening</p><h2 id="scalling" tabindex="-1"><a class="header-anchor" href="#scalling"><span>Scalling</span></a></h2><p>Scaling is important in logistic regression (and many other machine learning models) for the following reasons:</p><ol><li><strong>Improves Model Performance</strong> Logistic regression uses gradient-based optimisation (e.i., Gradient Descent) to find the optimal weights. When features have different scales (e.g., <code>Sun</code> values range from 0 to 7 while <code>IBM</code> is just 0 or 2), the optimisation can become inefficient or converge slowly.</li><li><strong>Prevents Certain Features from Dominating</strong> In this dataset, the <code>Sun</code> feature ranges from 0 to 7, while others like <code>IBM</code> only take values from {0, 2}. Without scaling, the model might assign too much importance to <code>Sun</code> just because of its larger values, even if it&#39;s not the most important predictor.</li><li><strong>Better Numerical Stability</strong> Logistic regression calculates logits (linear combination of features and weights), which are then passed through the sigmoid function. If the feature values are too large, it can lead to numerical instability (e.g., extremely large or small values in exponentiation).</li></ol><h2 id="use-logistic-regression-as-multi-class-classification" tabindex="-1"><a class="header-anchor" href="#use-logistic-regression-as-multi-class-classification"><span>Use Logistic Regression as multi-class classification</span></a></h2><ul><li>One-vs-All <ul><li>train a separate binary logistic regression classifier for each class. Each classifier distinguishes one class from all other classes.</li></ul></li><li>Softmax Regression <ul><li>generalizes the binary logistic regression model to handle multiple classes simultaneously</li></ul></li></ul><h1 id="svm" tabindex="-1"><a class="header-anchor" href="#svm"><span>SVM</span></a></h1><p><strong>classification</strong> and <strong>regression</strong> tasks. It works by finding the optimal hyperplane that best separates the data into different classes while maximising the margin (distance between the hyperplane and the nearest data points from each class, called support vectors).</p><p>In real-world data, perfect linear separation is often impossible due to noise or overlap between classes. To handle this, soft-margin SVM introduces slack variables ($\xi$) and a penalty parameter ($C$):</p><p>Soft-margin SVM introduces <strong>slack variables</strong> ($\xi_i$) to allow margin violations and misclassifications when the data is not linearly separable.</p><ul><li>If $\xi_i = 0$, the point is correctly classified and outside the margin.</li><li>If $0 &lt; \xi_i \leq 1$, the point is within the margin but still correctly classified.</li><li>If $\xi_i &gt; 1$, the point is misclassified.</li></ul><p>Â¶ÇÊûúÊ≤°ÊúâslackÂèòÈáèÔºåÈÇ£‰πàÊï∞ÊçÆÂøÖÈ°ªÂÆåÂÖ®Á∫øÊÄßÂèØÂàÜÔºåÂê¶ÂàôÊó†Ê≥ïÊâæÂà∞Ë∂ÖÂπ≥Èù¢„ÄÇ</p><p><strong>Penalty for Slack ($C$)</strong></p><ul><li>The penalty parameter $C$ controls how much we penalize large $\xi_i$ values.</li><li><strong>Higher $C$</strong>: Less tolerance for margin violations, leading to a more complex model that prioritizes correct classification. model overfit data</li><li><strong>Lower $C$</strong>: More tolerance for margin violations, resulting in a softer boundary that generalizes better. model underfit data</li></ul><p>The SVM optimization problem with slack variables is:</p><p>$$ \min \frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i $$</p><p>subject to:</p><p>$$ y_i (w \cdot x_i + b) \geq 1 - \xi_i, \quad \xi_i \geq 0 $$</p><p>where:</p><ul><li>$w$ is the weight vector,</li><li>$b$ is the bias term,</li><li>$y_i$ are the class labels ($\pm1$),</li><li>$x_i$ are the feature vectors.</li></ul><p>SVM Classification Rule:</p><ul><li>If $f(x) \geq 0$, classify as <strong>Class 1</strong>.</li><li>If $f(x) &lt; 0$, classify as <strong>Class 0</strong>.</li></ul><h2 id="application" tabindex="-1"><a class="header-anchor" href="#application"><span>Application</span></a></h2><ul><li>Multi-class classification</li><li>Rating</li><li>Ranking</li><li>Structured prediction</li></ul><h1 id="evaluation" tabindex="-1"><a class="header-anchor" href="#evaluation"><span>Evaluation</span></a></h1><h2 id="split-data-into-train-validation-test" tabindex="-1"><a class="header-anchor" href="#split-data-into-train-validation-test"><span>Split data into train, validation, test</span></a></h2><ul><li><strong>Basic problems?</strong> A simple <strong>train-test split</strong> (e.g., 80-20) usually works.</li><li><strong>Need hyperparameter tuning?</strong> Use a <strong>train-validation-test split</strong> (e.g., 70-15-15).</li><li><strong>Imbalanced data?</strong> Make sure to use <strong>stratification</strong>. <ul><li>stratification ensures that each subset of data has the same proportion of different categories</li></ul></li></ul><h2 id="why-split-data-into-train-validation-test" tabindex="-1"><a class="header-anchor" href="#why-split-data-into-train-validation-test"><span>Why split data into train, validation, test</span></a></h2><ul><li>To Make Sure Our Model Actually Learns (and Not Just Memorizes)</li><li>To Get a Fair Performance Estimate</li><li>To Tune the Model Without Cheating (validation set)</li><li>To Handle Class ImbalancesÂΩì‰∏Ä‰∏™Êï∞ÊçÆÈáå‰∏ÄÁ±ªËøúËøúË∂ÖËøáÂè¶‰∏ÄÁ±ª Fairly (stratified sampling)</li></ul><h2 id="confusion-matrix" tabindex="-1"><a class="header-anchor" href="#confusion-matrix"><span>Confusion Matrix</span></a></h2><ul><li>True Positive (TP): Predicted positive, actually positive.</li><li>True Negative (TN): Predicted negative, actually negative.</li><li>False Positive (FP): Predicted positive, actually negative. <ul><li>The false positives (FP) are those items that we attempted to classify as being of class d, but they were actually of some other class Êú¨Êù•‰∏çÊòØd‰ΩÜÊòØË¢´ÂàÜÊàê‰∫Üd</li></ul></li><li>False Negative (FN): Predicted negative, actually positive. <ul><li>false negatives (FN): those items that were actually of class d, but we classified as being of some other class Êú¨Êù•ÊòØd‰ΩÜÊòØË¢´ÂàÜÊàê‰∫ÜÂà´ÁöÑ</li></ul></li></ul><p>Confusion matrix isn&#39;t just for binary classification‚Äîit also works for <strong>multi-class classification</strong>. In this case, the matrix expands to accommodate all possible class predictions.</p><p>For a problem with <em>three classes</em> (e.g., Cat, Dog, and Rabbit), the confusion matrix might look like this:</p><table><thead><tr><th><strong>Actual / Predicted</strong></th><th><strong>Predicted: Cat</strong></th><th><strong>Predicted: Dog</strong></th><th><strong>Predicted: Rabbit</strong></th></tr></thead><tbody><tr><td><strong>Actual: Cat</strong></td><td><strong>Correct: Cat</strong></td><td>Cat misclassified as Dog</td><td>Cat misclassified as Rabbit</td></tr><tr><td><strong>Actual: Dog</strong></td><td>Dog misclassified as Cat</td><td><strong>Correct: Dog</strong></td><td>Dog misclassified as Rabbit</td></tr><tr><td><strong>Actual: Rabbit</strong></td><td>Rabbit misclassified as Cat</td><td>Rabbit misclassified as Dog</td><td><strong>Correct: Rabbit</strong></td></tr></tbody></table><ul><li><em>Diagonal values</em> represent correct classifications.</li><li><em>Off-diagonal values</em> are <em>errors</em>, where one class is misclassified as another.</li></ul><h2 id="holdout-vs-cross-validation" tabindex="-1"><a class="header-anchor" href="#holdout-vs-cross-validation"><span>Holdout vs. Cross-Validation</span></a></h2><p><strong>1. Holdout Evaluation</strong></p><ul><li>split dataset randomly into <strong>training and test sets</strong>‚Äîtypically something like <strong>80% for training and 20% for testing</strong>.</li><li>Train the model on the training set, then test it on the test set once.</li><li>The test set gives an estimate of how the model will perform on new data.</li></ul><p><strong>2. Cross-Validation</strong></p><ul><li>Instead of just one train-test split, you split the dataset into $K$ equal-sized parts (folds) (e.g., K=5 or 10).</li><li>Train the model K times, each time using $K-1$ folds for training** and one fold for testing.</li><li>The final performance score is the <strong>average</strong> across all runs.</li><li>kÂ§™Â§ßÔºåËÆ°ÁÆóÈáèÂ§™Â§ßÔºåÂÆπÊòìËøáÊãüÂêàÔºåkÂ§™Â∞èÔºåÊñπÂ∑ÆÂ§™Â§ßÔºåÂÆπÊòìÊ¨†ÊãüÂêà</li></ul><p><strong>When Should You Use Holdout vs. Cross-Validation?</strong></p><table><thead><tr><th>Scenario</th><th>Holdout</th><th>Cross-Validation</th></tr></thead><tbody><tr><td>Large dataset (millions of records)</td><td>‚úÖ Works well</td><td>‚ùå Too slow</td></tr><tr><td>Small dataset (few thousand samples)</td><td>‚ùå Might not be reliable</td><td>‚úÖ More accurate</td></tr><tr><td>Need fast evaluation</td><td>‚úÖ Quick &amp; simple</td><td>‚ùå Computationally heavy</td></tr><tr><td>Hyperparameter tuning</td><td>‚ùå Risky (prone to overfitting)</td><td>‚úÖ More stable</td></tr><tr><td>Deep learning models (large compute cost)</td><td>‚úÖ Saves time</td><td>‚ùå Too expensive</td></tr></tbody></table><hr><h2 id="accuracy-precision-recall-f1-score" tabindex="-1"><a class="header-anchor" href="#accuracy-precision-recall-f1-score"><span>Accuracy, Precision, Recall, F1-Score</span></a></h2><p>ÂçïÁî®accuracyÂèØËÉΩ‰∏çÂáÜÁ°ÆÔºåÂõ†‰∏∫Êï∞ÊçÆ‰∏çÂπ≥Ë°°ÔºåÊØîÂ¶Ç99%ÁöÑÊ†∑Êú¨ÊòØ0Ôºå1%ÁöÑÊ†∑Êú¨ÊòØ1ÔºåÈÇ£‰πàÂ¶ÇÊûúÊ®°ÂûãÂÖ®ÈÉ®È¢ÑÊµã0Ôºåaccuracy‰πüÊòØ99%Ôºå‰ΩÜÊòØËøô‰∏™Ê®°ÂûãÂÖ∂ÂÆûÂæàÂ∑Æ„ÄÇ</p><p>Precision/Recall are typically in an inverse relationship, so we need to balance them.</p><ul><li>Precision: True Positives / (True Positives + False Positives) <ul><li>È¢ÑÊµã‰∏∫Ê≠£ÁöÑÊ†∑Êú¨‰∏≠ÔºåÂÆûÈôÖ‰∏∫Ê≠£ÁöÑÊØî‰æãÔºåË∂äÈ´òË∂äÂ•Ω</li></ul></li><li>Recall: True Positives / (True Positives + False Negatives) <ul><li>Âú®ÊâÄÊúâÂÆûÈôÖ‰∏∫Ê≠£Á±ªÁöÑÊ†∑Êú¨‰∏≠ÔºåÊúâÂ§öÂ∞ëË¢´ÊàêÂäüËØÜÂà´ÔºåË∂äÈ´òË∂äÂ•Ω</li></ul></li></ul><p>F1-Score: 2 * (Precision * Recall) / (Precision + Recall)</p><h2 id="compute-for-entire-model" tabindex="-1"><a class="header-anchor" href="#compute-for-entire-model"><span>Compute for entire model</span></a></h2><ul><li><strong>Macro Averaging</strong>: Computes the precision and recall <strong>independently for each class</strong> and then takes their <strong>unweighted average</strong>. This treats all classes <strong>equally</strong>, regardless of their size.</li><li><strong>Micro Averaging</strong>: Aggregates the contributions of <strong>all classes</strong> before calculating precision and recall. This approach <strong>weights</strong> larger classes more heavily and gives an overall system performance measure.</li><li><strong>Weighted Averaging</strong>: Similar to macro averaging, but each class is <strong>weighted by its support</strong> (i.e., the number of instances in that class). This helps when classes are <strong>imbalanced</strong>.</li></ul><p><strong>When to Use Macro vs. Micro Averaging?</strong> ËÄÉËôëweight Áî®micro ‰∏çËÄÉËôëÁî®macro Áé∞ÂÆû‰∏≠microÂ§ö</p><ul><li>If we want to <em>prioritize small classes</em> and ensure each class is given <strong>equal importance</strong>, <strong>macro averaging</strong> is the better choice.</li><li>If we care more about <em>overall system performance</em>, where larger classes influence the results more (common in real-world applications like fraud detection), <strong>micro averaging</strong> is preferable.</li></ul><table><thead><tr><th>Aspect</th><th>Model Bias</th><th>Evaluation Bias</th></tr></thead><tbody><tr><td><strong>Definition</strong></td><td>Errors due to incorrect assumptions in the model</td><td>Errors due to incorrect evaluation methods</td></tr><tr><td><strong>Cause</strong></td><td>Model is too simple or incorrectly structured</td><td>Test set is biased or inappropriate metrics are used</td></tr><tr><td><strong>Effect</strong></td><td>Leads to <strong>underfitting</strong> (poor learning)</td><td>Leads to <strong>misleading performance metrics</strong></td></tr><tr><td><strong>Example</strong></td><td>Using a linear model for a nonlinear problem</td><td>Evaluating a fraud detection model with only non-fraud cases in the test set</td></tr><tr><td><strong>Solution</strong></td><td>Use a more flexible complex model, add more features</td><td>Use fair test sets, proper metrics, and cross-validation</td></tr></tbody></table><table><thead><tr><th></th><th>Model Variance (Ê®°ÂûãÊñπÂ∑Æ)</th><th>Evaluation Variance (ËØÑ‰º∞ÊñπÂ∑Æ)</th></tr></thead><tbody><tr><td>ÊÑè‰πâ</td><td>Ê®°ÂûãËæìÂá∫ÈöèËÆ≠ÁªÉÈõÜ‰∏çÂêåËÄåÊ≥¢Âä®ÁöÑÁ®ãÂ∫¶</td><td>ÊÄßËÉΩËØÑ‰º∞ÁªìÊûúÈöèÊµãËØïÈõÜÊàñÂàíÂàÜ‰∏çÂêåËÄåÊ≥¢Âä®ÁöÑÁ®ãÂ∫¶</td></tr><tr><td>ÂÖ≥Ê≥®ÁÇπ</td><td>Ê®°ÂûãÊú¨Ë∫´ÁöÑÁ®≥ÂÆöÊÄßÂíåÊ≥õÂåñËÉΩÂäõ</td><td>ËØÑ‰º∞ÊåáÊ†áÁöÑÁ®≥ÂÆöÊÄßÂíåÂèØ‰ø°Â∫¶</td></tr><tr><td>È´òÊñπÂ∑ÆËß£ÂÜ≥ÊñπÊ≥ï</td><td>ÁÆÄÂåñÊ®°Âûã„ÄÅÂ¢ûÂä†Êï∞ÊçÆ„ÄÅÊ≠£ÂàôÂåñ</td><td>‰ΩøÁî®‰∫§ÂèâÈ™åËØÅ„ÄÅÂ§öÊ¨°ÈáçÂ§çÂÆûÈ™å</td></tr></tbody></table><table><thead><tr><th>ÊÉÖÂÜµ</th><th>Train Error</th><th>Test Error</th><th>ÈóÆÈ¢ò</th><th>Ëß£ÂÜ≥ÂäûÊ≥ï</th></tr></thead><tbody><tr><td>Underfitting (high bias)</td><td>È´ò</td><td>È´ò</td><td>Ê®°ÂûãÂ§™ÁÆÄÂçï</td><td>Â¢ûÂä†Â§çÊùÇÂ∫¶, add more feature, boosting</td></tr><tr><td>Overfitting (high variance)</td><td>‰Ωé</td><td>È´ò</td><td>Ê®°ÂûãÂ§™Â§çÊùÇ</td><td>ÂáèÂ∞ëÂ§çÊùÇÂ∫¶, reduce feature, add more traning data, bagging</td></tr><tr><td>ÁêÜÊÉ≥Áä∂ÊÄÅ</td><td>‰Ωé</td><td>‰Ωé</td><td>Ê®°ÂûãÂêàÈÄÇ</td><td>‚úÖ Êó†ÈúÄ‰øÆÊîπ</td></tr></tbody></table><table><thead><tr><th>Ê®°ÂûãÊÉÖÂÜµ</th><th>ÂÅèÂ∑Æbias</th><th>ÊñπÂ∑Ævariance</th><th>ÈîôËØØÁ±ªÂûã</th></tr></thead><tbody><tr><td>ÁÆÄÂçïÊ®°ÂûãÔºàÁ∫øÊÄßÔºâ</td><td>È´ò</td><td>‰Ωé</td><td>Ê¨†ÊãüÂêàÔºàUnderfitÔºâ</td></tr><tr><td>Â§çÊùÇÊ®°ÂûãÔºàÊ∑±ÁΩëÔºâ</td><td>‰Ωé</td><td>È´ò</td><td>ËøáÊãüÂêàÔºàOverfitÔºâ</td></tr><tr><td>ÈÄÇ‰∏≠Ê®°Âûã</td><td>‰Ωé</td><td>‰Ωé</td><td>Ê≥õÂåñÂ•Ω ‚úÖ</td></tr></tbody></table><h1 id="feature-selection" tabindex="-1"><a class="header-anchor" href="#feature-selection"><span>Feature Selection</span></a></h1><p>better performance (too many feature overfitting), faster training, more interpretable model</p><ol><li><p><em>Filter Methods</em> ‚Äì These use statistical techniques to rank and select features before training a model.</p><ul><li>Example: Mutual Information, Chi-Square Test, Correlation. <ul><li>Mutual InformationÂ§ßÔºåËØ¥ÊòéËøô‰∏™ÁâπÂæÅÂíåÁõÆÊ†áÂèòÈáè‰πãÈó¥ÁöÑÂÖ≥Á≥ªÂæàÂº∫ÔºåÊâÄ‰ª•Ëøô‰∏™ÁâπÂæÅÂæàÈáçË¶Å„ÄÇ best attribute for classification„ÄÇ</li><li>Mutual Information is another name for Information Gain</li></ul></li></ul></li><li><p><em>Wrapper Methods</em> ‚Äì These test different subsets of features by training models and evaluating their performance.</p><ul><li>Example: Recursive Feature Elimination (RFE)Ôºö iteratively remove less important features and select the most relevant ones for a given model</li></ul></li><li><p><em>Embedded Methods</em> ‚Äì These select features automatically while training the model.</p><ul><li>Example: Decision Tree feature importance.</li></ul></li></ol><table><thead><tr><th>ÊñπÊ≥ïÁ±ªÂûã</th><th>Ê†∏ÂøÉÊÄùÊÉ≥</th><th>ÊòØÂê¶‰æùËµñÊ®°Âûã</th><th>‰ºòÁÇπ</th><th>Áº∫ÁÇπ</th><th>‰∏æ‰æã</th></tr></thead><tbody><tr><td><strong>Filter ÊñπÊ≥ï</strong></td><td>Áã¨Á´ã‰∫éÊ®°ÂûãÔºåÊ†πÊçÆÁªüËÆ°ÊåáÊ†áÔºàÂ¶ÇÁõ∏ÂÖ≥ÊÄßÔºâÂØπÁâπÂæÅËøõË°åÊéíÂ∫èÂíåÈÄâÊã©</td><td>‚ùå ‰∏ç‰æùËµñÊ®°Âûã</td><td>Âø´ÈÄü„ÄÅÊ®°ÂûãÊó†ÂÖ≥„ÄÅÈÄÇÂêàÈ´òÁª¥Êï∞ÊçÆ</td><td>ÂøΩÁï•ÁâπÂæÅ‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÅ‰∏éÂÖ∑‰ΩìÊ®°ÂûãÊÄßËÉΩ‰∏ç‰∏ÄÂÆöÁõ∏ÂÖ≥</td><td>‰∫í‰ø°ÊÅØÔºàMutual InfoÔºâ„ÄÅÂç°ÊñπÊ£ÄÈ™åÔºàChi-SquareÔºâ„ÄÅÁõ∏ÂÖ≥Á≥ªÊï∞Á≠â</td></tr><tr><td><strong>Wrapper ÊñπÊ≥ï</strong></td><td>‰ΩøÁî®Ê®°ÂûãËØÑ‰º∞‰∏çÂêåÁâπÂæÅÂ≠êÈõÜÁöÑÊïàÊûúÔºåÈÄâÊã©ÊúÄ‰ºòÁªÑÂêà</td><td>‚úÖ ‰æùËµñÊ®°Âûã</td><td>ÈÄöÂ∏∏ÈÄâÊã©ÊïàÊûúÊõ¥Â•ΩÁöÑÁâπÂæÅÂ≠êÈõÜÔºåËÄÉËôëÁâπÂæÅ‰πãÈó¥‰∫§‰∫í</td><td>ËÆ°ÁÆóÊàêÊú¨È´ò„ÄÅÂÆπÊòìËøáÊãüÂêà</td><td>ÈÄíÂΩíÁâπÂæÅÊ∂àÈô§ÔºàRFEÔºâ„ÄÅÂâçÂêë/ÂêéÂêëÈÄâÊã©</td></tr><tr><td><strong>Embedded ÊñπÊ≥ï</strong></td><td>Âú®Ê®°ÂûãËÆ≠ÁªÉËøáÁ®ã‰∏≠ËøõË°åÁâπÂæÅÈÄâÊã©ÔºåÁâπÂæÅÈÄâÊã©‰∏éÂ≠¶‰π†ËøáÁ®ã‰∏Ä‰ΩìÂåñ</td><td>‚úÖ Âº∫‰æùËµñÊ®°Âûã</td><td>ËÆ≠ÁªÉÊïàÁéáËæÉÈ´òÔºåËÉΩËá™Âä®ÈÄâÊã©ÁâπÂæÅ„ÄÅÈÄÇÂ∫îÊ®°Âûã</td><td>‰æùËµñÂÖ∑‰ΩìÊ®°ÂûãÁªìÊûÑÔºàÂ¶ÇÁ∫øÊÄß„ÄÅÊ≠£ÂàôÂåñÔºâÔºõÈöæ‰ª•Ê≥õÂåñ</td><td>Lasso ÂõûÂΩí„ÄÅÂÜ≥Á≠ñÊ†ëÁâπÂæÅÈáçË¶ÅÊÄß„ÄÅÊ≠£ÂàôÂåñÈÄªËæëÂõûÂΩí</td></tr></tbody></table><table><thead><tr><th>ÊñπÊ≥ï</th><th>Ê†∏ÂøÉÊÄùÊÉ≥</th><th>Â∏∏ËßÅÈóÆÈ¢ò</th><th>Ëß£ÂÜ≥ÊñπÊ°à</th></tr></thead><tbody><tr><td><strong>Forward Selection</strong></td><td>‰ªéÊó†Âà∞ÊúâÔºåÈÄêÊ≠•<strong>Âä†ÂÖ•</strong>ÊúÄÊúâÁî®ÁöÑÁâπÂæÅÔºàË¥™ÂøÉÁ≠ñÁï•Ôºâ</td><td>ÂèØËÉΩÈîôËøáÊõ¥‰ºòÁöÑÁâπÂæÅÁªÑÂêàÔºõÂâç‰∏ÄÊ≠•ÈÄâÈîôÂêéÊó†Ê≥ïÂõûÂ§¥</td><td>‰ΩøÁî®‰∫§ÂèâÈ™åËØÅËØÑ‰º∞ÊØè‰∏ÄÊ≠•ÔºõÁªìÂêàÂµåÂÖ•ÂºèÊñπÊ≥ïËæÖÂä©ÈÄâÊã©</td></tr><tr><td><strong>Backward Elimination</strong></td><td>‰ªéÂÖ®‰ΩìÂºÄÂßãÔºåÈÄêÊ≠•<strong>Âà†Èô§</strong>ÊúÄÊó†Áî®ÁöÑÁâπÂæÅ</td><td>ÂàùÂßãÊ®°ÂûãÂåÖÂê´ÊâÄÊúâÁâπÂæÅÔºåËÆ°ÁÆóÂºÄÈîÄÂ§ßÔºõÊòìÂèóÂ§öÈáçÂÖ±Á∫øÊÄßÂΩ±Âìç</td><td>Âú®ÂàùÊ≠•ËøáÊª§Âêé‰ΩøÁî®ÔºõÈÖçÂêàÊ≠£ÂàôÂåñÔºàÂ¶Ç RidgeÔºâÂáèÂ∞ëÂÖ±Á∫øÊÄßÂΩ±Âìç</td></tr></tbody></table><h1 id="pca" tabindex="-1"><a class="header-anchor" href="#pca"><span>PCA</span></a></h1><p>unsupervised learning</p><p>Principal Component Analysis (PCA) is a linear dimensionality reduction technique that transforms a dataset into a lower-dimensional space by projecting it onto the directions (principal components) that maximize variance. These directions are orthogonal (uncorrelated) and ordered by the amount of original data variance they capture.</p><p>Formally, given a dataset $X \in \mathbb{R}^{n \times d}$, where $n$ is the number of observations and $d$ is the number of features, PCA seeks to find a new set of orthogonal axes, called <strong>principal components</strong>, onto which the data can be projected such that:</p><p>The first principal component corresponds to the direction of maximum variance in the data.</p><p>Each subsequent component captures the highest remaining variance under the constraint of being orthogonal to all previous components.</p><h2 id="covariance-matrix" tabindex="-1"><a class="header-anchor" href="#covariance-matrix"><span>Covariance Matrix</span></a></h2><ul><li>ÂçèÊñπÂ∑ÆÁü©Èòµ ÊòØÊèèËø∞Êï∞ÊçÆÂêÑÁâπÂæÅ‰πãÈó¥ÊñπÂ∑ÆÂíåÂçèÊñπÂ∑ÆÁöÑÁü©ÈòµÔºåÂèçÊò†ÁâπÂæÅÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇ</li><li>ÁâπÂæÅÂÄºeigenvalue ÊòØÂçèÊñπÂ∑ÆÁü©ÈòµÁöÑÂõ∫ÊúâÂ±ûÊÄßÔºå‰ª£Ë°®Êï∞ÊçÆÊ≤øÂØπÂ∫îÁâπÂæÅÂêëÈáèÊñπÂêëÁöÑÊñπÂ∑ÆÂ§ßÂ∞è„ÄÇ</li><li>Âú® PCA ‰∏≠ÔºåÈÄöËøáÂØπÂçèÊñπÂ∑ÆÁü©ÈòµÊ±ÇÁâπÂæÅÂÄºÂíåÁâπÂæÅÂêëÈáèÔºåÊâæÂà∞ÂØπÂ∫îÊúÄÂ§ßÁâπÂæÅÂÄºÁöÑÁâπÂæÅÂêëÈáèÔºåÂÆûÁé∞ÊúâÊïàÈôçÁª¥„ÄÇ</li><li>n samples and d features, covariance matrix is a <code>d x d</code> matrix</li><li>compute covariance matrix ÊÄª‰πòÊ≥ïÊ¨°Êï∞ÊòØ<code>n*d^2</code></li></ul><h2 id="pcaÁº∫ÁÇπ" tabindex="-1"><a class="header-anchor" href="#pcaÁº∫ÁÇπ"><span>PCAÁº∫ÁÇπ</span></a></h2><p>PCA does not know about class labels</p><p>PCA maximizes variance</p><p>Notice: do dimensionality reduction (and feature selection) inside cross-validation, only applied to the training set</p><h1 id="perceptron" tabindex="-1"><a class="header-anchor" href="#perceptron"><span>Perceptron</span></a></h1><ul><li>ÊâæÂÜ≥Á≠ñËæπÁïå classification and regression</li><li>only can do linear</li><li>Âè™ËÉΩ‰º†Êï∞Â≠ó</li></ul><h2 id="perceptron-learning-rule" tabindex="-1"><a class="header-anchor" href="#perceptron-learning-rule"><span>Perceptron learning rule</span></a></h2><p>$$\theta_j^{(t)} \leftarrow \theta_j^{(t-1)} + \eta \left( y^{(i)} - \hat{y}^{(i, t)} \right) x_j^{(i)}$$</p><p>where $\eta$ is the learning rate, $y^{(i)}$ is the true label, $\hat{y}^{(i, t)}$ is the predicted label at time $t$, $x_j^{(i)}$ is the $j$-th feature of the $i$-th sample, and $\theta_j^{(t)}$ is the weight of the $j$-th feature at time $t$, $\theta_j^{(t-1)}$ is the weight of the $j$-th feature at time $t-1$ Áé∞ÊúâÁöÑweight</p><p>ÂÖàËÆ°ÁÆó$\hat{y}$ÔºåÂ¶ÇÊûúyÂíå$\hat{y}$‰∏ÄÊ†∑ÔºåÂ∞±ËØ¥ÊòéËøô‰∏™weightÊòØÂ•ΩÁöÑÔºå‰∏çÈúÄË¶ÅÊõ¥Êñ∞„ÄÇ</p><p>Áõ¥Âà∞Êüê‰∏ÄËΩÆÊùÉÈáç ‰∏çÂÜçÂèòÂåñÔºàÊâÄÊúâÊ†∑Êú¨ÈÉΩÊ≠£Á°ÆÂàÜÁ±ªÔºâ‰∏∫Ê≠¢</p><table><thead><tr><th>ÁâπÊÄß</th><th>Perceptron</th><th>Multi-Layer Perceptron (MLP)</th></tr></thead><tbody><tr><td>Â±ÇÊï∞</td><td>ÂçïÂ±Ç</td><td>Â§öÂ±ÇÔºàËá≥Â∞ëÂê´‰∏Ä‰∏™ÈöêËóèÂ±ÇÔºâ</td></tr><tr><td>ËÉΩÂäõ</td><td>Á∫øÊÄßÂàÜÁ±ª</td><td>ÈùûÁ∫øÊÄßÂàÜÁ±ª„ÄÅÂ§öÁßç‰ªªÂä°</td></tr><tr><td>ÊøÄÊ¥ªÂáΩÊï∞</td><td>step function</td><td>ReLU„ÄÅSigmoid„ÄÅtanh</td></tr><tr><td>Ë°®ËææËÉΩÂäõ</td><td>Âº±</td><td>Âº∫</td></tr><tr><td>ÊùÉÈáçÊõ¥Êñ∞ÊñπÂºè</td><td>ÊâãÂä®ËßÑÂàôÔºàPerceptron RuleÔºâ</td><td>Âü∫‰∫éÂØºÊï∞ÁöÑÂèçÂêë‰º†Êí≠</td></tr></tbody></table><h1 id="multi-layer-perceptron" tabindex="-1"><a class="header-anchor" href="#multi-layer-perceptron"><span>Multi-Layer Perceptron</span></a></h1><ul><li>ÊâæÂÜ≥Á≠ñËæπÁïå</li><li>can do non-linear classification, regression</li></ul><h3 id="example" tabindex="-1"><a class="header-anchor" href="#example"><span>Example</span></a></h3><p>Ëøô‰∏™‰æãÂ≠êÊòØÁî®<strong>ÊÑüÁü•Âô®ÔºàPerceptronÔºâÁΩëÁªú</strong>Êù•Â≠¶‰π†<strong>ÂºÇÊàñÔºàXORÔºâÂáΩÊï∞</strong>ÔºåÂπ∂ËØ¶ÁªÜÂ±ïÁ§∫‰∫ÜÊùÉÈáçÊõ¥Êñ∞ÁöÑÂÖ®ËøáÁ®ã„ÄÇ</p><hr><h2 id="üåüËÉåÊôØÁü•ËØÜ" tabindex="-1"><a class="header-anchor" href="#üåüËÉåÊôØÁü•ËØÜ"><span>üåüËÉåÊôØÁü•ËØÜ</span></a></h2><ul><li><p>**ÊÑüÁü•Âô®ÔºàPerceptronÔºâ**ÊòØ‰∏ÄÁßçÊúÄÂü∫Êú¨ÁöÑÁ•ûÁªèÂÖÉÊ®°Âûã„ÄÇ</p></li><li><p>XOR ‰∏çËÉΩÁî®ÂçïÂ±ÇÊÑüÁü•Âô®Ëß£ÂÜ≥ÔºåÂõ†‰∏∫ÂÆÉÊòØ<strong>ÈùûÁ∫øÊÄßÂèØÂàÜ</strong>ÁöÑÔºåÊâÄ‰ª•Êàë‰ª¨ËøôÈáåÁî®‰∏§Â±ÇÔºö</p><ul><li><strong>Á¨¨‰∏ÄÂ±Ç</strong>Ôºö‰∏§‰∏™ÊÑüÁü•Âô®Ôºå‰∏Ä‰∏™ËÆ°ÁÆó AND (<code>p‚ÇÅ</code>)Ôºå‰∏Ä‰∏™ËÆ°ÁÆó OR (<code>p‚ÇÇ</code>)</li><li><strong>Á¨¨‰∫åÂ±Ç</strong>ÔºöÁî® <code>p‚ÇÅ</code> Âíå <code>p‚ÇÇ</code> ÁöÑËæìÂá∫‰Ωú‰∏∫ËæìÂÖ•ÔºåËÆ≠ÁªÉ‰∏Ä‰∏™ÊÑüÁü•Âô®Êù•Ê®°Êãü XOR</li></ul></li></ul><hr><h2 id="üî¢-ËæìÂÖ•Êï∞ÊçÆ" tabindex="-1"><a class="header-anchor" href="#üî¢-ËæìÂÖ•Êï∞ÊçÆ"><span>üî¢ ËæìÂÖ•Êï∞ÊçÆ</span></a></h2><p>Êàë‰ª¨Êúâ 4 ‰∏™ËæìÂÖ•Êï∞ÊçÆÁÇπÔºåÂØπÂ∫î <code>x‚ÇÅ XOR x‚ÇÇ</code>Ôºö</p><table><thead><tr><th style="text-align:right;">#</th><th>x‚ÇÅ</th><th>x‚ÇÇ</th><th>p‚ÇÅ = AND(x‚ÇÅ,x‚ÇÇ)</th><th>p‚ÇÇ = OR(x‚ÇÅ,x‚ÇÇ)</th><th>y = XOR(x‚ÇÅ,x‚ÇÇ)</th></tr></thead><tbody><tr><td style="text-align:right;">1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td></tr><tr><td style="text-align:right;">2</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td></tr><tr><td style="text-align:right;">3</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td></tr><tr><td style="text-align:right;">4</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table><hr><h2 id="üß†-Á¨¨‰∫åÂ±ÇÊÑüÁü•Âô®" tabindex="-1"><a class="header-anchor" href="#üß†-Á¨¨‰∫åÂ±ÇÊÑüÁü•Âô®"><span>üß† Á¨¨‰∫åÂ±ÇÊÑüÁü•Âô®</span></a></h2><p>Êàë‰ª¨Áî® <code>p‚ÇÅ</code> Âíå <code>p‚ÇÇ</code> ÁöÑËæìÂá∫‰Ωú‰∏∫ËæìÂÖ•ÔºåËæìÂÖ•ÂΩ¢Âºè‰∏∫Ôºö</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>P = &lt;-1, p‚ÇÅ, p‚ÇÇ&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>ÂÖ∂‰∏≠ <code>-1</code> ÊòØ‰∏∫‰∫ÜË°®Á§∫ÂÅèÁΩÆÔºàbiasÔºâÔºåÂØπÂ∫îÊùÉÈáç <code>Œ∏‚ÇÄ</code></p><p>ÂàùÂßãÂåñÂèÇÊï∞Ôºö</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Œ∏ = &lt;Œ∏‚ÇÄ, Œ∏‚ÇÅ, Œ∏‚ÇÇ&gt; = &lt;0, 0, 0&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><hr><h2 id="üîÅ-ÊùÉÈáçÊõ¥Êñ∞ËøáÁ®ã" tabindex="-1"><a class="header-anchor" href="#üîÅ-ÊùÉÈáçÊõ¥Êñ∞ËøáÁ®ã"><span>üîÅ ÊùÉÈáçÊõ¥Êñ∞ËøáÁ®ã</span></a></h2><ul><li><p>‰ΩøÁî®<strong>ÊÑüÁü•Âô®ÁÆóÊ≥ï</strong>ÔºàPerceptron Learning RuleÔºâÔºö</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Œ∏ ‚Üê Œ∏ + Œ∑(y - ≈∑)P</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><ul><li>Â≠¶‰π†Áéá Œ∑ = 0.1</li><li>≈∑ ÊòØÂΩìÂâçÊ®°ÂûãÁöÑÈ¢ÑÊµãÔºà0 Êàñ 1ÔºâÔºåÁî± z = Œ∏¬∑P ÂÜ≥ÂÆö</li><li>Áî®Á°¨ÈòàÂÄºÂáΩÊï∞ f(z)Ôºöz &gt; 0 ‚Üí ≈∑=1ÔºåÂê¶Âàô ≈∑=0</li></ul></li></ul><hr><h3 id="üßÆ-epoch-ËÆ≠ÁªÉËΩÆÊ¨°-Ëß£Èáä" tabindex="-1"><a class="header-anchor" href="#üßÆ-epoch-ËÆ≠ÁªÉËΩÆÊ¨°-Ëß£Èáä"><span>üßÆ EpochÔºàËÆ≠ÁªÉËΩÆÊ¨°ÔºâËß£ÈáäÔºö</span></a></h3><h4 id="epoch-1" tabindex="-1"><a class="header-anchor" href="#epoch-1"><span>Epoch 1:</span></a></h4><ul><li><p>ÂØπÊØè‰∏™Ê†∑Êú¨ËæìÂÖ•ÂêëÈáè PÔºåËÆ°ÁÆó zÔºåÈ¢ÑÊµã ≈∑</p></li><li><p>Â¶ÇÊûú ≈∑ ‚â† yÔºåÂ∞±Ë∞ÉÊï¥ÊùÉÈáç</p></li><li><p>‰æãÂ¶ÇÔºö</p><ul><li><p>Á¨¨‰∏Ä‰∏™Ê†∑Êú¨ÔºöP = ‚ü®-1, 0, 1‚ü©Ôºåz = 0 ‚Üí ≈∑ = 0ÔºåËÄå y = 1</p><ul><li>ÊâÄ‰ª•Êõ¥Êñ∞ Œ∏ ‚Üê Œ∏ + 0.1 √ó (1 - 0) √ó ‚ü®-1, 0, 1‚ü© ‚Üí Œ∏ = ‚ü®-0.1, 0, 0.1‚ü©</li></ul></li></ul></li></ul><p>‰Ω†ÂèØ‰ª•Âú®ÊØè‰∏ÄË°åÁúãÂà∞ z ÁöÑËÆ°ÁÆó„ÄÅÈ¢ÑÊµã„ÄÅÊòØÂê¶Êõ¥Êñ∞Ôºå‰ª•ÂèäÊñ∞ÁöÑÊùÉÈáç„ÄÇ</p><hr><h2 id="‚úÖ-Êî∂ÊïõÊù°‰ª∂" tabindex="-1"><a class="header-anchor" href="#‚úÖ-Êî∂ÊïõÊù°‰ª∂"><span>‚úÖ Êî∂ÊïõÊù°‰ª∂</span></a></h2><p>ÂΩìÊâÄÊúâÊ†∑Êú¨ÈÉΩË¢´Ê≠£Á°ÆÂàÜÁ±ªÔºàÂç≥Ê≤°ÊúâÊùÉÈáçÊõ¥Êñ∞ÔºâÊó∂ÔºåËØ¥ÊòéÊ®°ÂûãÂ∑≤Áªè<strong>Êî∂Êïõ</strong>„ÄÇ</p><p>Âú®Ëøô‰∏™‰æãÂ≠ê‰∏≠Ôºå<strong>Á¨¨ 4 Ê¨° Epoch</strong>ÂêéÊùÉÈáç‰∏çÂÜçÊõ¥Êñ∞ÔºåÊâÄ‰ª•ËÆ≠ÁªÉÂÆåÊàê„ÄÇ</p><hr><h2 id="üèÅ-ÊúÄÁªàÊùÉÈáç" tabindex="-1"><a class="header-anchor" href="#üèÅ-ÊúÄÁªàÊùÉÈáç"><span>üèÅ ÊúÄÁªàÊùÉÈáç</span></a></h2><p>ËÆ≠ÁªÉÁªìÊùüÂêéÔºåÁ¨¨‰∫åÂ±ÇÁöÑÊùÉÈáçÂèÇÊï∞‰∏∫Ôºö</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Œ∏ = &lt;0, -0.2, 0.1&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>Ëß£ÈáäÂ¶Ç‰∏ãÔºö</p><ul><li><code>Œ∏‚ÇÄ = 0</code> ‚Üí ÂÅèÁΩÆÈ°π</li><li><code>Œ∏‚ÇÅ = -0.2</code> ‚Üí ‰∏é AND(p‚ÇÅ) Áõ∏‰πò</li><li><code>Œ∏‚ÇÇ = 0.1</code> ‚Üí ‰∏é OR(p‚ÇÇ) Áõ∏‰πò</li></ul><hr><h2 id="üß†-ÊÄªÁªì" tabindex="-1"><a class="header-anchor" href="#üß†-ÊÄªÁªì"><span>üß† ÊÄªÁªì</span></a></h2><p>ÈÄöËøáÁ¨¨‰∏ÄÂ±ÇÊèêÂèñ‰∫ÜÁÆÄÂçïÁöÑÈÄªËæëÁâπÂæÅÔºàAND Âíå ORÔºâÔºåÁ¨¨‰∫åÂ±ÇÁªÑÂêàËøô‰∏§‰∏™ÁâπÂæÅÂ≠¶‰π†Êõ¥Â§çÊùÇÁöÑ XOR„ÄÇ</p><p>ËøôÁßçÁªìÊûÑ‰ΩìÁé∞‰∫ÜÔºö</p><blockquote><p><strong>‚ÄúÁªÑÂêàÁÆÄÂçïÈÄªËæëÔºåÂÆûÁé∞Â§çÊùÇÂÜ≥Á≠ñ‚Äù</strong></p></blockquote><hr><h2 id="feature-learning" tabindex="-1"><a class="header-anchor" href="#feature-learning"><span>Feature Learning</span></a></h2><p>Áî±Á•ûÁªèÁΩëÁªúÁõ¥Êé•‰ªéÂéüÂßãÊï∞ÂÄºÊï∞ÊçÆ‰∏≠Ëá™Âä®Â≠¶‰π†ÁâπÂæÅË°®Á§∫„ÄÇ</p><p>ÁâπÂæÅ‰Ωú‰∏∫‰∏≠Èó¥Ë°®Á§∫ÔºåÊòØÊ®°ÂûãÂÜÖÈÉ®‰∏ÄÂ±ÇÂ±Ç‚ÄúÊäΩË±°‚ÄùÂá∫Êù•ÁöÑÔºåÂØπÁõÆÊ†á‰ªªÂä°ÊúâÁî®„ÄÇ</p><p>‰πüÂè´Representation LearningÔºàË°®Á§∫Â≠¶‰π†Ôºâ„ÄÇ</p><p>‰ºòÁÇπÔºöÂáèÂ∞ë‰∫Ü‰∫∫Â∑•ÁâπÂæÅËÆæËÆ°ÁöÑÈúÄÊ±Ç„ÄÇ</p><p>‰ª£‰ª∑ÔºöÈúÄË¶ÅÊõ¥Â§öÂèÇÊï∞Ë∞É‰ºòÔºàÊØîÂ¶ÇÁΩëÁªúÂ±ÇÊï∞„ÄÅÊøÄÊ¥ªÂáΩÊï∞„ÄÅÂ≠¶‰π†ÁéáÁ≠âÔºâ„ÄÇ</p><h2 id="activation-function" tabindex="-1"><a class="header-anchor" href="#activation-function"><span>activation function</span></a></h2><ul><li>sigmoid: $$ \sigma(z) = \frac{1}{1 + e^{-z}} $$</li><li>tanh: $$ \tanh(z) = \frac{e^z - e<sup>{-z}}{e</sup>z + e^{-z}} $$</li><li>ReLU: Helps to delete unnecessary weights $$ \text{ReLU}(z) = \max(0, z) $$</li><li>step function cannot be used for backpropagation because it is not differentiable at 0</li></ul><h2 id="output-function" tabindex="-1"><a class="header-anchor" href="#output-function"><span>output function</span></a></h2><ul><li>binary classification: sigmoid or step function</li><li>multi-class classification: softmax $$ \text{softmax}(z) = \frac{e<sup>{z_i}}{\sum_{j=1}</sup>n e^{z_j}} $$</li></ul><h2 id="loss-function" tabindex="-1"><a class="header-anchor" href="#loss-function"><span>loss function</span></a></h2><ul><li>binary classification: cross-entropy $$ L(y, \hat{y}) = -[y \log(\hat{y}) + (1-y) \log(1-\hat{y})] $$</li><li>multi-class classification: cross-entropy</li></ul><p>$$ L(y, \hat{y}) = -\sum_{i=1}^n y_i \log(\hat{y_i}) $$</p><ul><li>regression: MSE</li></ul><h1 id="backpropagation" tabindex="-1"><a class="header-anchor" href="#backpropagation"><span>Backpropagation</span></a></h1><p>compute the partial derivatives of the error with respect to each weight in the network.</p><p>sequence: Compute the error, propagate the error backwards, update weights.</p><table><thead><tr><th>Á¨¶Âè∑</th><th>ÊÑè‰πâ</th></tr></thead><tbody><tr><td>$\theta_{ji}^{(l)}$</td><td>Á¨¨ $l$ Â±Ç‰∏≠Ôºå‰ªéÁ¨¨ $i$ ‰∏™Á•ûÁªèÂÖÉÂà∞Á¨¨ $j$ ‰∏™Á•ûÁªèÂÖÉÁöÑÊùÉÈáç</td></tr><tr><td>‰∏äÊ†á $l$</td><td>Ëøô‰∏ÄÂ±ÇÁöÑÁºñÂè∑Ôºà‰ªéËæìÂÖ•Âà∞ËæìÂá∫ÈÄêÂ±ÇÈÄíÂ¢ûÔºâ</td></tr><tr><td>‰∏ãÊ†á $i, j$</td><td>Á¨¨ $i$ ‰∏™Á•ûÁªèÂÖÉÊòØ<strong>ËæìÂÖ•Ê∫ê</strong>ÔºåÁ¨¨ $j$ ‰∏™Á•ûÁªèÂÖÉÊòØ<strong>ÁõÆÊ†á</strong></td></tr></tbody></table><ul><li>use MSE for loss function</li></ul><p>In neural networks with backpropagation, we want to minimise the error of our network by finding the optimum weights ($\theta_{ij}$) for our network. To do so, we want to find the relation (dependency) between the error and the weights in each layer. Therefore, we use the derivatives of our error function.</p><p>$$ \theta_{jk}^{(l)} \leftarrow \theta_{jk}^{(l)} + \Delta \theta_{jk}^{(l)} $$</p><p>where:</p><p>$$ \Delta \theta_{jk}^{(l)} = -\eta \frac{\partial E}{\partial \theta_{jk}^{(l)}} = \eta , \delta_k^{(l)} a_j^{(l)} $$</p><p>and</p><p>$$ \delta_k^{(l)} = g&#39;(z_k) (y - a_k^{(l)}) = (1 - \sigma (z_k^{(l)})) \sigma (z_k^{(l)}) (y - a_k^{(l)})\quad \text {for the last layer} $$</p><p>or</p><p>$$ \delta_k^{(l)} = g&#39;(z_k) \theta_{kj}^{(l+1)} \delta_j^{(l+1)} =\sigma(z_k^{(l)}) (1 - \sigma(z_k^{(l)})) \theta_{kj}^{(l+1)} \delta_j^{(l+1)} \quad \text{for the layer before} $$</p><table><thead><tr><th>Á¨¶Âè∑</th><th>Âê´‰πâ</th><th>Â§áÊ≥®</th></tr></thead><tbody><tr><td><code>z</code></td><td>Âä†ÊùÉÂíåÔºàLinearÔºâ</td><td>ËøòÊ≤°‚ÄúÊøÄÊ¥ª‚ÄùÁöÑËæìÂÖ•</td></tr><tr><td><code>a</code></td><td>ÊøÄÊ¥ªÂêéÁöÑËæìÂá∫</td><td>ÂèØ‰Ωú‰∏∫‰∏ã‰∏ÄÂ±ÇÁöÑËæìÂÖ•</td></tr></tbody></table><ul><li>biaÊòØË¶Å‰πòÁöÑ</li></ul><figure><img src="/assets/img/back.404770e7.png" alt="backprop.png" tabindex="0" loading="lazy"><figcaption>backprop.png</figcaption></figure><h1 id="generative-vs-discriminative" tabindex="-1"><a class="header-anchor" href="#generative-vs-discriminative"><span>Generative vs. Discriminative</span></a></h1><p>discriminative approaches model a function to predict y from x, generative approaches model a distribution of x and y</p><p>Âà§Âà´ÂºèÊòØ‚ÄúÂàÜËæ®‚ÄùÂá∫Á±ªÂà´ÔºåÂ≠¶ÁöÑÊòØÂàÜÁ±ªËæπÁïåÔºõ</p><p>ÁîüÊàêÂºèÊòØ‚ÄúÁîüÊàê‚ÄùÊï∞ÊçÆÔºåÂ≠¶ÁöÑÊòØÊï∞ÊçÆÁöÑÂàÜÂ∏É„ÄÇ</p><p>‰∏ªË¶ÅÈíàÂØπÊúâÁõëÁù£Â≠¶‰π†‰∏≠ÁöÑÂàÜÁ±ªÂíåÂõûÂΩí‰ªªÂä°</p><table><thead><tr><th>ÊñπÈù¢</th><th>ÁîüÊàêÂºèÊ®°Âûã (Generative)</th><th>Âà§Âà´ÂºèÊ®°Âûã (Discriminative)</th><th></th></tr></thead><tbody><tr><td>‰ΩúÁî®</td><td>ÂèØ‰ª•ÁîüÊàêÊï∞ÊçÆÔºå‰πüÂèØ‰ª•ÂàÜÁ±ª</td><td>Âè™ËÉΩÂàÜÁ±ª</td><td></td></tr><tr><td>ÂàÜÁ±ªÁ≠ñÁï•</td><td>ÈÄöËøáË¥ùÂè∂ÊñØÂÖ¨ÂºèËÆ°ÁÆóÂêéÈ™åÊ¶ÇÁéá</td><td>Áõ¥Êé•È¢ÑÊµãÁ±ªÂà´</td><td></td></tr><tr><td>Ê®°ÂûãÂ§çÊùÇÂ∫¶</td><td>ÈÄöÂ∏∏Êõ¥Â§çÊùÇ</td><td>ÈÄöÂ∏∏ËæÉÁÆÄÂçï</td><td></td></tr><tr><td>ËÆ≠ÁªÉÊïàÁéá</td><td>ÈÄöÂ∏∏ËæÉ‰Ωé</td><td>ÈÄöÂ∏∏ËæÉÈ´ò</td><td></td></tr><tr><td>ÈÄÇÁî®Âú∫ÊôØ</td><td>ÈúÄË¶ÅÁêÜËß£Êï∞ÊçÆÁîüÊàêËøáÁ®ã„ÄÅÁîüÊàêÊ†∑Êú¨</td><td>Á∫ØÁ≤πÂàÜÁ±ª‰ªªÂä°</td><td></td></tr><tr><td>‰ª£Ë°®ÁÆóÊ≥ï</td><td>Êú¥Á¥†Ë¥ùÂè∂ÊñØ</td><td>ÈÄªËæëÂõûÂΩí„ÄÅSVM„ÄÅÁ•ûÁªèÁΩëÁªú, ÂÜ≥Á≠ñÊ†ë, linear regression, kNN</td><td></td></tr></tbody></table><h1 id="unsupervised-learning" tabindex="-1"><a class="header-anchor" href="#unsupervised-learning"><span>Unsupervised Learning</span></a></h1><h2 id="k-means" tabindex="-1"><a class="header-anchor" href="#k-means"><span>K-Means</span></a></h2><p>unsupervised learning, no labels</p><h3 id="ÁÆóÊ≥ïÊ≠•È™§" tabindex="-1"><a class="header-anchor" href="#ÁÆóÊ≥ïÊ≠•È™§"><span>ÁÆóÊ≥ïÊ≠•È™§</span></a></h3><ul><li>Selecting K cluster centres (centroids) randomly</li><li>Assigning each data point to the nearest centroid</li><li>Updating the centroids based on the average position of points in each cluster</li><li>Repeating the process until centroids stop changing significantly</li></ul><h3 id="k-meansÁº∫ÁÇπ" tabindex="-1"><a class="header-anchor" href="#k-meansÁº∫ÁÇπ"><span>K-MeansÁº∫ÁÇπ</span></a></h3><ul><li>ÈúÄË¶ÅÊâãÂä®ÈÄâÊã©KÂÄº</li><li>ÂØπÂàùÂßãÂÄºÊïèÊÑü</li><li>‰∏çËÉΩÂ§ÑÁêÜÈùûÂúÜÂΩ¢Êï∞ÊçÆ</li><li>ÂØπÂºÇÂ∏∏ÂÄºÊïèÊÑü</li></ul><p>ÊâæKÂèØ‰ª•Áî®elbow method: Look for a point where the reduction in WCSS significantly slows down = the Elbow point</p><h2 id="evaluate-the-goodness-of-a-clustering-structure-without-relying-on-external-information-i-e-unsupervised-evaluation" tabindex="-1"><a class="header-anchor" href="#evaluate-the-goodness-of-a-clustering-structure-without-relying-on-external-information-i-e-unsupervised-evaluation"><span>evaluate the goodness of a clustering structure without relying on external information (i.e., unsupervised evaluation)</span></a></h2><h3 id="cluster-cohesion-compactness-tightness" tabindex="-1"><a class="header-anchor" href="#cluster-cohesion-compactness-tightness"><span>Cluster cohesion (compactness, tightness)</span></a></h3><ul><li>Intra-cluster distance: distances between instances inside each cluster</li><li>WCSS: within-cluster sum of squares <ul><li>ÊØè‰∏™clusterÂÜÖÈÉ®ÔºåÊâÄÊúâÁÇπÂà∞cluster‰∏≠ÂøÉÁöÑË∑ùÁ¶ªÁöÑÂπ≥ÊñπÂíå</li><li>Ë∂äÂ∞èË∂äÂ•Ω</li></ul></li></ul><h3 id="cluster-separation-isolation-distinctiveness" tabindex="-1"><a class="header-anchor" href="#cluster-separation-isolation-distinctiveness"><span>Cluster separation (isolation, distinctiveness)</span></a></h3><ul><li>Inter-cluster distances: the degree to which clusters are distinct or well-separated from each other</li><li>BCSS: between-cluster sum of squares <ul><li>cluster‰πãÈó¥Ë∑ùÁ¶ªÁöÑÂπ≥ÊñπÂíå</li><li>Ë∂äÂ§ßË∂äÂ•Ω Â•ΩÁöÑclusterË¶ÅÊúâhigh cohesion and high separation ËØ¥ÊòéÊØè‰∏™Âõ¢ÂÜÖÈÉ®ÂæàÁ¥ßÂØÜÔºåÂõ¢ÂíåÂõ¢‰πãÈó¥ÂæàÂàÜÊï£</li></ul></li></ul><p>Calinski-Harabasz Index: $$ \text{CH} = \frac{\text{BCSS}}{\text{WCSS}} \times \frac{N - k}{k - 1} $$</p><ul><li>BCSS: between-cluster sum of squares</li><li>WCSS: within-cluster sum of squares</li><li>N: total number of data points</li><li>k: number of clusters</li><li>Higher values indicate better clustering quality</li></ul><h2 id="supervised-clustering-evaluation" tabindex="-1"><a class="header-anchor" href="#supervised-clustering-evaluation"><span>Supervised Clustering evaluation</span></a></h2><p>Homogeneity measures whether each <strong>cluster contains only data points from a single true class</strong>. If a cluster consists of instances that all belong to the same externally supplied label, the clustering is considered highly homogeneous. This can be evaluated using metrics like Entropy and Purity. $$ homogenity = 1 - H(Ytrue|Ypred) / H(Ytrue) $$</p><p>Completeness measures whether <strong>all instances of a given true class are assigned to the same cluster</strong>. A high completeness score means that the clustering effectively groups all instances of a particular class together in one cluster. $$ completeness = 1 - H(Ypred|Ytrue) / H(Ypred) $$ Homogeneity alone can be misleading. It only checks whether all instances within a cluster share the same label but does not ensure that instances of the same class are grouped together.</p><h2 id="hierarchical-clustering" tabindex="-1"><a class="header-anchor" href="#hierarchical-clustering"><span>Hierarchical Clustering</span></a></h2><h3 id="linkage-method" tabindex="-1"><a class="header-anchor" href="#linkage-method"><span>Linkage Method</span></a></h3><table><thead><tr><th><strong>ÈìæÊé•ÊñπÊ≥ï</strong></th><th><strong>ÂÆö‰πâ</strong></th><th><strong>‰ºòÁÇπ</strong></th><th><strong>Áº∫ÁÇπ</strong></th><th><strong>ÈÄÇÁî®Âú∫ÊôØ</strong></th></tr></thead><tbody><tr><td><strong>Single Linkage</strong> ÔºàÊúÄËøëË∑ùÁ¶ªÊ≥ïÔºâ</td><td>‰∏§‰∏™Á∞áÈó¥Ë∑ùÁ¶ªÊòØÂÆÉ‰ª¨ÊúÄÊé•ËøëÁöÑ‰∏§‰∏™ÁÇπ‰πãÈó¥ÁöÑË∑ùÁ¶ª</td><td>- ËÉΩÂèëÁé∞‰ªªÊÑèÂΩ¢Áä∂ÁöÑÁ∞á<br>- ËÆ°ÁÆóÁÆÄÂçïÔºåÈÄÇÂêàÂô™Â£∞ËæÉÂ∞ëÁöÑÊï∞ÊçÆ</td><td>- ÂÆπÊòì‰∫ßÁîü‚ÄúÈìæÁä∂ÊïàÂ∫î‚ÄùÔºàChaining effectÔºâÔºåÂØºËá¥‰∏çËá™ÁÑ∂ÁöÑÈïøÊù°ÂΩ¢Á∞á<br>- ÂØπÂô™Â£∞ÊïèÊÑü</td><td>- Â∏åÊúõÂèëÁé∞ÈùûÁêÉÁä∂Á∞áÊó∂<br>- ÈúÄË¶ÅËøûÊé•ËæÉÊùæÊï£ÁªìÊûÑÊó∂</td></tr><tr><td><strong>Complete Linkage</strong> ÔºàÊúÄËøúË∑ùÁ¶ªÊ≥ïÔºâ</td><td>‰∏§‰∏™Á∞áÈó¥Ë∑ùÁ¶ªÊòØÂÆÉ‰ª¨ÊúÄËøúÁöÑ‰∏§‰∏™ÁÇπ‰πãÈó¥ÁöÑË∑ùÁ¶ª</td><td>- Á∞áÂÜÖÁ¥ßÂØÜÔºåÁ∞áËæπÁïåÊ∏ÖÊô∞<br>- ÊäëÂà∂ÈìæÁä∂ÊïàÂ∫îÔºåÂæóÂà∞ËæÉÁ¥ßÂáëÁöÑÁ∞á</td><td>- ÂØπÁ¶ªÁæ§ÁÇπÊïèÊÑü<br>- ÂèØËÉΩÂØºËá¥ËæÉÂ∞èÁöÑÁ∞áÔºåË¢´Â≠§Á´ãÁöÑÁÇπÂèØËÉΩÊó†Ê≥ïÂêàÂπ∂</td><td>- ÈúÄË¶ÅÂæóÂà∞Á¥ßÂáë„ÄÅÂàÜÁ¶ªËâØÂ•ΩÁ∞áÊó∂</td></tr><tr><td><strong>Average Linkage</strong> ÔºàÂπ≥ÂùáË∑ùÁ¶ªÊ≥ïÔºâ</td><td>‰∏§‰∏™Á∞áÈó¥Ë∑ùÁ¶ªÊòØ‰∏§‰∏™Á∞áÊâÄÊúâÁÇπÂØπ‰πãÈó¥Ë∑ùÁ¶ªÁöÑÂπ≥ÂùáÂÄº</td><td>- Êäò‰∏≠ÊñπÊ≥ïÔºåÈÅøÂÖç‰∫ÜÊúÄËøëÂíåÊúÄËøúË∑ùÁ¶ªÊ≥ïÁöÑÊûÅÁ´Ø<br>- Á®≥ÂÆöÊÄßËæÉÂ•Ω</td><td>- ËÆ°ÁÆóÈáèÂ§ßÔºåÂ∞§ÂÖ∂Êï∞ÊçÆÈáèÂ§ßÊó∂<br>- ÁªìÊûú‰æùËµñ‰∫éÁ∞áÂÜÖÁöÑÁÇπÂàÜÂ∏É</td><td>- ÈúÄË¶ÅÂπ≥Ë°°Á∞áÁöÑÁ¥ßÂØÜÊÄßÂíåÂàÜÁ¶ªÊÄßÊó∂</td></tr><tr><td><strong>Centroid Linkage</strong> ÔºàË¥®ÂøÉË∑ùÁ¶ªÊ≥ïÔºâ</td><td>‰∏§‰∏™Á∞áÈó¥Ë∑ùÁ¶ªÊòØ‰∏§‰∏™Á∞áË¥®ÂøÉ‰πãÈó¥ÁöÑË∑ùÁ¶ª</td><td>- ËÆ°ÁÆóÂø´ÈÄü<br>- Áõ¥Êé•‰ΩøÁî®Á∞á‰∏≠ÂøÉÁÇπ(Ë¶ÅËÆ°ÁÆóÂæóÂá∫ÔºöÊÄªÂíå/Êï∞Èáè)ÔºåÁõ¥ËßÇÊòìÁêÜËß£</td><td>- ÂèØËÉΩÂØºËá¥Á∞áÂêàÂπ∂ÂêéË¥®ÂøÉ‚ÄúÁßªÂä®‚ÄùÔºåÂá∫Áé∞‚ÄúÈÄÜËΩ¨‚ÄùÁé∞Ë±°ÔºàÈùûÂçïË∞ÉÊÄßÔºâÔºåÂØºËá¥ÁªìÊûú‰∏çÁ®≥ÂÆö</td><td>- ÂØπÁêÉÁä∂Á∞áÊïàÊûúËæÉÂ•Ω<br>- ÈÄÇÂêàÂØπË¥®ÂøÉÊïèÊÑüÁöÑÂ∫îÁî®</td></tr></tbody></table><h3 id="agglomerative-clustering" tabindex="-1"><a class="header-anchor" href="#agglomerative-clustering"><span>Agglomerative Clustering</span></a></h3><ul><li>bottom-up approach</li><li>Start with each data point as a separate cluster</li><li>Merge the two closest clusters until only one cluster remains</li></ul><h3 id="divisive-clustering" tabindex="-1"><a class="header-anchor" href="#divisive-clustering"><span>Divisive Clustering</span></a></h3><ul><li>top-down approach</li><li>Start with one, all-inclusive cluster</li><li>At each step, split a cluster until each cluster contains a point (or there are k clusters)</li></ul><h1 id="semi-supervised-learning" tabindex="-1"><a class="header-anchor" href="#semi-supervised-learning"><span>Semi-Supervised Learning</span></a></h1><p>utilizes a small set of labeled data together with a large amount of unlabeled data to improve model performance</p><h2 id="self-training" tabindex="-1"><a class="header-anchor" href="#self-training"><span>Self-Training</span></a></h2><p>assume that <strong>similar instances are likely to have the same label</strong></p><h3 id="ÁÆóÊ≥ïÊ≠•È™§-1" tabindex="-1"><a class="header-anchor" href="#ÁÆóÊ≥ïÊ≠•È™§-1"><span>ÁÆóÊ≥ïÊ≠•È™§</span></a></h3><ol><li>Train the learner on the currently labeled instances.</li><li>Use the learner to predict the labels of the unlabeled instances.</li><li>Where the learner is very confident, add newly labeled instances to the training set.</li><li>Repeat until all instances are labeled, or no new instances can be labeled confidently.</li></ol><h3 id="confidence-threshold" tabindex="-1"><a class="header-anchor" href="#confidence-threshold"><span>Confidence Threshold</span></a></h3><ul><li>Â§™‰ΩéÔºöÊ®°Âûã‰ºöËøáÂ∫¶ÊãüÂêà ÂèØËÉΩ‰ºöÂØºËá¥ÈîôËØØÊ†áÁ≠æÁöÑ‰º†Êí≠ ‰∏çÁ®≥ÂÆö e.g. 0.4-0.5</li><li>Â§™È´òÔºöÊ®°Âûã‰ºöÊ¨†ÊãüÂêà ÂèØËÉΩ‰ºöÂØºËá¥Ê®°ÂûãÊó†Ê≥ïÂ≠¶‰π†Âà∞Ê≠£Á°ÆÁöÑÊ†áÁ≠æ Â≠¶‰π†ÈÄüÂ∫¶ÂæàÊÖ¢ e.g. over 0.8</li></ul><h2 id="active-learning" tabindex="-1"><a class="header-anchor" href="#active-learning"><span>Active Learning</span></a></h2><p>assume that <strong>instances near class boundaries are the most informative for learning</strong>, ask human to label the most informative instances</p><h2 id="query-strategy" tabindex="-1"><a class="header-anchor" href="#query-strategy"><span>Query Strategy</span></a></h2><table><thead><tr><th><strong>Á≠ñÁï•ÂêçÁß∞</strong></th><th><strong>ÊèèËø∞</strong></th><th><strong>‰ºòÁÇπ</strong></th><th><strong>Áº∫ÁÇπ</strong></th></tr></thead><tbody><tr><td><strong>‰∏çÁ°ÆÂÆöÊÄßÈááÊ†∑</strong></td><td>ÈÄâÊã©Ê®°ÂûãÊúÄ‰∏çÁ°ÆÂÆöÁöÑÂÆû‰æã</td><td>- ËÉΩÂ§üÂø´ÈÄüËØÜÂà´Ê®°Âûã‰∏çÁ°ÆÂÆöÂå∫Âüü<br>- ÊèêÈ´òÊ®°ÂûãÁöÑÊ≥õÂåñËÉΩÂäõ</td><td>- ÂèØËÉΩÂØºËá¥ËøáÂ∫¶ÈááÊ†∑‰∏çÁ°ÆÂÆöÂå∫Âüü<br>- ÈúÄË¶ÅËÆ°ÁÆó‰∏çÁ°ÆÂÆöÊÄß</td></tr><tr><td>- ÊúÄ‰∏çËá™‰ø°</td><td>ÈÄâÊã©ÊúÄÂèØËÉΩÁ±ªÂà´ÁöÑÈ¢ÑÊµãÊ¶ÇÁéáÊúÄÂ∞èÁöÑÊ†∑Êú¨(‰∏ÄË°åÈáåÈù¢ÈÄâÊúÄÂ§ßÁöÑÂàóÂíåÂÖ∂‰ªñË°åÈáåÊúÄÂ§ßÁöÑÂàóÊØîÔºåÈÄâÊúÄÂ∞è)</td><td>- ÁÆÄÂçïÊòìË°å<br>- ÈÄÇÂêà‰∫åÂàÜÁ±ªÈóÆÈ¢ò</td><td>- ÂØπÂ§öÂàÜÁ±ªÈóÆÈ¢òÊïàÊûúÊúâÈôê</td></tr><tr><td>- ËæπÁºòÈááÊ†∑</td><td>ÈÄâÊã©‰∏§‰∏™ÊúÄÂèØËÉΩÁ±ªÂà´Ê¶ÇÁéáÂ∑ÆÊúÄÂ∞èÁöÑÊ†∑Êú¨ÔºàÈÄâ‰∏ÄË°åÈáå‰∏§ÂàóÁõ∏ÂáèÊúÄÂ∞èÁöÑÔºâ</td><td>- ËÉΩÊõ¥Â•ΩÂú∞Â§ÑÁêÜÂ§öÂàÜÁ±ªÈóÆÈ¢ò</td><td>- ËÆ°ÁÆóÂ§çÊùÇÂ∫¶ËæÉÈ´ò</td></tr><tr><td>- ÁÜµÈááÊ†∑</td><td>ÈÄâÊã©È¢ÑÊµãÊ¶ÇÁéáÁÜµÂÄºÊúÄÈ´òÁöÑÊ†∑Êú¨</td><td>- ËÉΩÊçïÊçâÊï¥‰Ωì‰∏çÁ°ÆÂÆöÊÄß‰ø°ÊÅØ</td><td>- ËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´ò<br>- ÈúÄË¶ÅÁÜµÁöÑËÆ°ÁÆó</td></tr><tr><td><strong>ÂßîÂëò‰ºöÊü•ËØ¢</strong></td><td>ËÆ≠ÁªÉÂ§ö‰∏™Ê®°ÂûãÂú®Âêå‰∏ÄÊï∞ÊçÆÈõÜ‰∏äÔºå‰ΩøÁî®Ê®°ÂûãËøõË°åÈ¢ÑÊµãÔºåÈÄâÊã©Ê®°Âûã‰πãÈó¥Â∑ÆÂºÇÊúÄÂ§ßÁöÑÂÆû‰æã</td><td>- ËÉΩÂ§üÊçïÊçâÊ®°ÂûãÈó¥ÁöÑ‰∏ç‰∏ÄËá¥ÊÄß<br>- ÊèêÈ´òÊ®°ÂûãÁöÑÈ≤ÅÊ£íÊÄß</td><td>- ÈúÄË¶ÅËÆ≠ÁªÉÂ§ö‰∏™Ê®°Âûã<br>- ËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´ò</td></tr></tbody></table><h1 id="ensemble-learning" tabindex="-1"><a class="header-anchor" href="#ensemble-learning"><span>Ensemble Learning</span></a></h1><p>works when:</p><ul><li>learners to correct each other‚Äôs mistake relies on the assumption of <strong>errors being uncorrelated</strong></li><li>The base classifiers are reasonably accurate (better than chance)</li></ul><h2 id="bagging" tabindex="-1"><a class="header-anchor" href="#bagging"><span>Bagging</span></a></h2><ul><li>involves training multiple instances of the same algorithm on different subsets of the data and averaging the predictions. Âπ≥ÂùáÊéâÊØè‰∏Ä‰∏™Ê®°Âûã ÊäïÁ•®</li><li>e.g. Random Forest</li></ul><table><thead><tr><th>ÁâπÊÄß</th><th>ÈöèÊú∫Ê£ÆÊûóÊèèËø∞</th></tr></thead><tbody><tr><td>Ê†∑Êú¨Êìç‰Ωú (instance manipulation)</td><td>‰ΩøÁî® bootstrap ÊñπÊ≥ïÂØπËÆ≠ÁªÉÊï∞ÊçÆËøõË°åÊúâÊîæÂõûÈááÊ†∑ÔºåÁîüÊàêÂ§öÊ£µÊ†ëÁöÑËÆ≠ÁªÉÈõÜ</td></tr><tr><td>ÁâπÂæÅÊìç‰Ωú (feature manipulation)</td><td>ÊØè‰∏™ËäÇÁÇπÈöèÊú∫ÈÄâÊã©‰∏ÄÈÉ®ÂàÜÁâπÂæÅÔºåÂ¢ûÂº∫Ê®°ÂûãÂ§öÊ†∑ÊÄß</td></tr><tr><td>ÊñπÂ∑Æ vs ÂÅèÂ∑Æ</td><td>‰∏ªË¶ÅÈôç‰ΩéÊñπÂ∑ÆÔºàÂáèÂ∞ëËøáÊãüÂêàÔºâÔºåÂØπÂÅèÂ∑ÆÂΩ±Âìç‰∏çÂ§ß</td></tr><tr><td>ÂçïÊ£µÊ†ëÁöÑÂèØËß£ÈáäÊÄß</td><td>È´òÔºåÂèØ‰ª•Ê∏ÖÊ•öÂú∞Ëß£ÈáäÈ¢ÑÊµãË∑ØÂæÑ</td></tr><tr><td>Êï¥‰ΩìÊ®°ÂûãÁöÑÂèØËß£ÈáäÊÄß</td><td>ËæÉ‰ΩéÔºåÈöæ‰ª•Ëß£ÈáäÂ§ö‰∏™Ê†ëÊäïÁ•®ÁöÑÊï¥‰ΩìÈ¢ÑÊµãÈÄªËæë</td></tr></tbody></table><h2 id="stacking" tabindex="-1"><a class="header-anchor" href="#stacking"><span>Stacking</span></a></h2><ul><li>combines multiple models (often of different types) into a meta-model to learn how to best combine the predictions. ÊääÊØè‰∏Ä‰∏™Ê®°ÂûãÁöÑÈ¢ÑÊµãÁªìÊûú‰Ωú‰∏∫ËæìÂÖ•ÔºåËÆ≠ÁªÉ‰∏Ä‰∏™meta-modelÊù•Â≠¶‰π†Â¶Ç‰ΩïÊúÄÂ•ΩÂú∞ÁªìÂêàËøô‰∫õÈ¢ÑÊµãÁªìÊûú <ul><li>After the base classifiers have been trained on the training set, they are used to make predictions on the validation set. The meta-classifier then uses these predictions as input to learn how to combine them in order to make an overall prediction.</li><li>The meta-classifier is trained on the validation set, using the predictions from the base classifiers as input, and the true labels of the validation set as the target variable</li></ul></li></ul><h2 id="boosting" tabindex="-1"><a class="header-anchor" href="#boosting"><span>Boosting</span></a></h2><ul><li>involves adding ensemble members sequentially that correct the predictions made by prior models and outputs a weighted average of the predictions È°∫Â∫èËÆ≠ÁªÉ ‰∏Ä‰∏™Ê®°Âûã‰øÆÂ§ç‰∏ä‰∏Ä‰∏™Ê®°ÂûãÁöÑÈîôËØØ</li><li>higher weights to better-performing base learners Ë°®Áé∞Â•ΩÁöÑÊ®°ÂûãÊùÉÈáçÊõ¥È´ò</li></ul><h1 id="anomaly-detection" tabindex="-1"><a class="header-anchor" href="#anomaly-detection"><span>Anomaly Detection</span></a></h1><p>Supervised methods require labeled datasets containing <strong>both normal and anomalous instances</strong> to train predictive models.</p><p>Unsupervised methods, on the other hand, do <strong>not require labeled data</strong> and instead identify anomalies based on deviations from learned patterns in the data.</p><p>Semi-supervised methods use a combination of <strong>labeled and unlabeled data</strong> to build models that can detect anomalies.</p><table><thead><tr><th>ÊñπÊ≥ïÁ±ªÂà´</th><th>Ê†∏ÂøÉÊÄùÊÉ≥</th><th>ÂÖ∏ÂûãÁÆóÊ≥ï/Á§∫‰æã</th><th>‰ºòÂäø</th><th>Â±ÄÈôê</th></tr></thead><tbody><tr><td><strong>Proximity-based</strong>ÔºàÂü∫‰∫éË∑ùÁ¶ªÔºâ</td><td>ÂºÇÂ∏∏ÁÇπ‰∏éÂÖ∂‰ªñÁÇπË∑ùÁ¶ªËæÉËøú</td><td>k-NN ÂºÇÂ∏∏Ê£ÄÊµã„ÄÅLOF (Local Outlier Factor)</td><td>ÊòìÁêÜËß£ÔºåÁõ¥ËßÇÊúâÊïà</td><td>ÂØπÈ´òÁª¥Êï∞ÊçÆÊïàÊûúÂ∑ÆÔºå‰æùËµñË∑ùÁ¶ªÂ∫¶Èáè</td></tr><tr><td><strong>Statistical-based</strong>ÔºàÂü∫‰∫éÁªüËÆ°Ôºâ</td><td>ÂºÇÂ∏∏ÂÄºÂÅèÁ¶ªÊÄª‰ΩìÁöÑÁªüËÆ°ÂàÜÂ∏ÉÔºàÂ¶ÇÂùáÂÄº„ÄÅÊñπÂ∑ÆÔºâ</td><td>z-score, Grubbs&#39; test, GaussianÊ®°Âûã</td><td>ÁêÜËÆ∫ÊâéÂÆûÔºåÈÄÇÂêàÊï∞ÂÄºÂûãÊï∞ÊçÆ</td><td>‰æùËµñÂàÜÂ∏ÉÂÅáËÆæÔºåÂØπÈùûÊ≠£ÊÄÅÂàÜÂ∏ÉÊó†Êïà</td></tr><tr><td><strong>Density-based</strong>ÔºàÂü∫‰∫éÂØÜÂ∫¶Ôºâ</td><td>ÂºÇÂ∏∏ÁÇπÊâÄÂ§ÑÂå∫ÂüüÂØÜÂ∫¶ÊòéÊòæ‰Ωé‰∫éÂÖ∂‰ªñÁÇπ</td><td>LOF, DBSCAN, Isolation ForestÔºàÈÉ®ÂàÜÔºâ</td><td>ËÉΩÂèëÁé∞Â±ÄÈÉ®ÂºÇÂ∏∏ÔºåÈÄÇÂêàÂ§çÊùÇÊï∞ÊçÆ</td><td>ÂØÜÂ∫¶‰º∞ËÆ°ÊàêÊú¨ËæÉÈ´òÔºåÂèÇÊï∞ÊïèÊÑü</td></tr><tr><td><strong>Clustering-based</strong>ÔºàÂü∫‰∫éËÅöÁ±ªÔºâ</td><td>ÂºÇÂ∏∏ÁÇπ‰∏çÂ±û‰∫é‰ªª‰ΩïËÅöÁ±ªÊàñÁ¶ªËÅöÁ±ª‰∏≠ÂøÉÂæàËøú</td><td>K-Means, DBSCAN, K-Medoids</td><td>Êòì‰∫éÂèØËßÜÂåñÔºåËÉΩÁªìÂêàÊó†ÁõëÁù£Â≠¶‰π†</td><td>ËÅöÁ±ªË¥®ÈáèÂΩ±ÂìçÂ§ßÔºåÈöæÂ§ÑÁêÜÂ∞èÁ∞áÂºÇÂ∏∏</td></tr></tbody></table><h4 id="semi-supervised-learning-‚Äì-good-for-ambiguous-cases-e-g-platypus" tabindex="-1"><a class="header-anchor" href="#semi-supervised-learning-‚Äì-good-for-ambiguous-cases-e-g-platypus"><span>Semi-supervised Learning ‚Äì Good for ambiguous cases (e.g., platypus)</span></a></h4><ul><li>Train a classifier (e.g., Naive Bayes, Logistic Regression) on known animal categories.</li><li>Identify anomalies by looking at: <ul><li><strong>High-entropy predictions</strong>: e.g., platypusÈ∏≠Âò¥ÂÖΩ = 35% mammal, 35% bird, 30% amphibian.</li><li><strong>Low-confidence predictions</strong> across all classes: e.g., dragon.</li></ul></li><li>To improve reliability: <ul><li>Use an <strong>ensemble of classifiers</strong>.</li><li>Flag instances where multiple models show uncertainty.</li></ul></li></ul><h4 id="unsupervised-learning-‚Äì-best-for-true-anomalies-e-g-dragon" tabindex="-1"><a class="header-anchor" href="#unsupervised-learning-‚Äì-best-for-true-anomalies-e-g-dragon"><span>Unsupervised Learning ‚Äì Best for true anomalies (e.g., dragon)</span></a></h4><ul><li>Ignore labels; use clustering methods (e.g., K-means).</li><li>Flag animals that: <ul><li>Are <strong>far from all cluster centroids</strong>.</li><li>Form <strong>small or isolated clusters</strong>.</li></ul></li><li>Improve robustness: <ul><li>Run clustering multiple times with different <code>K</code> values and seeds.</li><li>Use <strong>voting</strong> or <strong>aggregate distance scores</strong> to decide anomalies.</li></ul></li></ul><h1 id="fairness" tabindex="-1"><a class="header-anchor" href="#fairness"><span>Fairness</span></a></h1><ul><li>Equal Opportunity: ÂØπ‰∫éÊâÄÊúâÁúüÂÆûÊ†áÁ≠æ‰∏∫Ê≠£Á±ªÔºày = 1ÔºâÁöÑ‰∫∫Ôºå‰∏çËÆ∫ÂÖ∂Â±û‰∫éÂì™‰∏™Âèó‰øùÊä§Áæ§‰ΩìÔºåÈÉΩÊúâÁõ∏ÂêåÁöÑË¢´Ê®°ÂûãÈ¢ÑÊµã‰∏∫Ê≠£Á±ªÔºà≈∑ = 1ÔºâÁöÑÊ¶ÇÁéá„ÄÇ</li><li>Predictive Parity: model provides similar predictive outcomes for all demographic groups</li></ul><h1 id="Â∏∏ËßÅËÆ°ÁÆóÊåáÊ†á-common-metrics" tabindex="-1"><a class="header-anchor" href="#Â∏∏ËßÅËÆ°ÁÆóÊåáÊ†á-common-metrics"><span>Â∏∏ËßÅËÆ°ÁÆóÊåáÊ†á (Common Metrics)</span></a></h1><h2 id="Ë∑ùÁ¶ªÂ∫¶Èáè-distance-metrics" tabindex="-1"><a class="header-anchor" href="#Ë∑ùÁ¶ªÂ∫¶Èáè-distance-metrics"><span>Ë∑ùÁ¶ªÂ∫¶Èáè (Distance Metrics)</span></a></h2><h3 id="_1-Ê¨ßÂá†ÈáåÂæóË∑ùÁ¶ª-euclidean-distance" tabindex="-1"><a class="header-anchor" href="#_1-Ê¨ßÂá†ÈáåÂæóË∑ùÁ¶ª-euclidean-distance"><span>1. Ê¨ßÂá†ÈáåÂæóË∑ùÁ¶ª (Euclidean Distance)</span></a></h3><p>ÊúÄÂ∏∏Áî®ÁöÑË∑ùÁ¶ªÂ∫¶ÈáèÔºåËÆ°ÁÆó‰∏§ÁÇπÈó¥ÁöÑÁõ¥Á∫øË∑ùÁ¶ª $$d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}$$</p><p><strong>‰æãÂ≠ê</strong>: ÁÇπA(1,2), ÁÇπB(4,6) $$d(A,B) = \sqrt{(1-4)^2 + (2-6)^2} = \sqrt{9 + 16} = 5$$</p><h3 id="_2-ÊõºÂìàÈ°øË∑ùÁ¶ª-manhattan-distance" tabindex="-1"><a class="header-anchor" href="#_2-ÊõºÂìàÈ°øË∑ùÁ¶ª-manhattan-distance"><span>2. ÊõºÂìàÈ°øË∑ùÁ¶ª (Manhattan Distance)</span></a></h3><p>‰πüÂè´ÂüéÂ∏ÇË°óÂå∫Ë∑ùÁ¶ªÔºåËÆ°ÁÆóÂêÑÁª¥Â∫¶Â∑ÆÂÄºÁöÑÁªùÂØπÂÄº‰πãÂíå $$d(x, y) = \sum_{i=1}^{n} |x_i - y_i|$$</p><p><strong>‰æãÂ≠ê</strong>: ÁÇπA(1,2), ÁÇπB(4,6) $$d(A,B) = |1-4| + |2-6| = 3 + 4 = 7$$</p><ul><li>ÂΩì p=1 Êó∂ÔºåÂ∞±ÊòØÊõºÂìàÈ°øË∑ùÁ¶ª</li><li>ÂΩì p=2 Êó∂ÔºåÂ∞±ÊòØÊ¨ßÂá†ÈáåÂæóË∑ùÁ¶ª</li></ul><h3 id="_3-‰ΩôÂº¶Áõ∏‰ººÂ∫¶-cosine-similarity" tabindex="-1"><a class="header-anchor" href="#_3-‰ΩôÂº¶Áõ∏‰ººÂ∫¶-cosine-similarity"><span>3. ‰ΩôÂº¶Áõ∏‰ººÂ∫¶ (Cosine Similarity)</span></a></h3><p>ËÆ°ÁÆó‰∏§‰∏™ÂêëÈáèÂ§πËßíÁöÑ‰ΩôÂº¶ÂÄºÔºåÂÄºË∂äÂ§ßË∂äÁõ∏‰ºº $$\cos(\theta) = \frac{A \cdot B}{|A| |B|} = \frac{\sum_{i=1}^{n} A_i B_i}{\sqrt{\sum_{i=1}^{n} A_i^2} \sqrt{\sum_{i=1}^{n} B_i^2}}$$</p><p><strong>‰ΩôÂº¶Ë∑ùÁ¶ª</strong>: $d = 1 - \cos(\theta)$</p><p><strong>‰æãÂ≠ê</strong>: ÂêëÈáèA(3,4), ÂêëÈáèB(1,2)</p><ul><li>ÁÇπÁßØ: $A \cdot B = 3√ó1 + 4√ó2 = 11$</li><li>Ê®°Èïø: $|A| = \sqrt{3^2 + 4^2} = 5$, $|B| = \sqrt{1^2 + 2^2} = \sqrt{5}$</li><li>‰ΩôÂº¶Áõ∏‰ººÂ∫¶: $\cos(\theta) = \frac{11}{5\sqrt{5}} = \frac{11}{5\sqrt{5}} ‚âà 0.982$</li></ul><hr><h2 id="ÂàÜÁ±ªËØÑ‰º∞ÊåáÊ†á-classification-metrics" tabindex="-1"><a class="header-anchor" href="#ÂàÜÁ±ªËØÑ‰º∞ÊåáÊ†á-classification-metrics"><span>ÂàÜÁ±ªËØÑ‰º∞ÊåáÊ†á (Classification Metrics)</span></a></h2><h3 id="Âü∫Á°ÄÊåáÊ†á" tabindex="-1"><a class="header-anchor" href="#Âü∫Á°ÄÊåáÊ†á"><span>Âü∫Á°ÄÊåáÊ†á</span></a></h3><p>‰ªéÊ∑∑Ê∑ÜÁü©ÈòµËÆ°ÁÆóÔºö</p><ul><li><strong>ÂáÜÁ°ÆÁéá (Accuracy)</strong>: $\frac{TP + TN}{TP + TN + FP + FN}$</li><li><strong>Á≤æÁ°ÆÁéá (Precision)</strong>: $\frac{TP}{TP + FP}$ (È¢ÑÊµã‰∏∫Ê≠£ÁöÑÊ†∑Êú¨‰∏≠ÁúüÊ≠£‰∏∫Ê≠£ÁöÑÊØî‰æã)</li><li><strong>Âè¨ÂõûÁéá (Recall/Sensitivity)</strong>: $\frac{TP}{TP + FN}$ (ÁúüÊ≠£‰∏∫Ê≠£ÁöÑÊ†∑Êú¨‰∏≠Ë¢´Ê≠£Á°ÆÈ¢ÑÊµãÁöÑÊØî‰æã)</li><li><strong>ÁâπÂºÇÊÄß (Specificity)</strong>: $\frac{TN}{TN + FP}$ (ÁúüÊ≠£‰∏∫Ë¥üÁöÑÊ†∑Êú¨‰∏≠Ë¢´Ê≠£Á°ÆÈ¢ÑÊµãÁöÑÊØî‰æã)</li><li><strong>F1ÂàÜÊï∞</strong>: $F_1 = \frac{2 \times Precision \times Recall}{Precision + Recall}$</li></ul><h3 id="Â§öÂàÜÁ±ªËØÑ‰º∞" tabindex="-1"><a class="header-anchor" href="#Â§öÂàÜÁ±ªËØÑ‰º∞"><span>Â§öÂàÜÁ±ªËØÑ‰º∞</span></a></h3><ul><li><strong>ÂÆèÂπ≥Âùá (Macro Average)</strong>: ÊØè‰∏™Á±ªÂà´ÂçïÁã¨ËÆ°ÁÆóÊåáÊ†áÔºåÁÑ∂ÂêéÂèñÂπ≥Âùá</li><li><strong>ÂæÆÂπ≥Âùá (Micro Average)</strong>: Â∞ÜÊâÄÊúâÁ±ªÂà´ÁöÑTP„ÄÅFP„ÄÅFNÊ±áÊÄªÂêéËÆ°ÁÆó</li><li><strong>Âä†ÊùÉÂπ≥Âùá (Weighted Average)</strong>: ÊåâÂêÑÁ±ªÂà´Ê†∑Êú¨Êï∞ÈáèÂä†ÊùÉÂπ≥Âùá</li></ul><hr><h2 id="ÂõûÂΩíËØÑ‰º∞ÊåáÊ†á-regression-metrics" tabindex="-1"><a class="header-anchor" href="#ÂõûÂΩíËØÑ‰º∞ÊåáÊ†á-regression-metrics"><span>ÂõûÂΩíËØÑ‰º∞ÊåáÊ†á (Regression Metrics)</span></a></h2><h3 id="_1-ÂùáÊñπËØØÂ∑Æ-mse-mean-squared-error" tabindex="-1"><a class="header-anchor" href="#_1-ÂùáÊñπËØØÂ∑Æ-mse-mean-squared-error"><span>1. ÂùáÊñπËØØÂ∑Æ (MSE - Mean Squared Error)</span></a></h3><p>$$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$</p><h3 id="_2-ÂùáÊñπÊ†πËØØÂ∑Æ-rmse-root-mean-squared-error" tabindex="-1"><a class="header-anchor" href="#_2-ÂùáÊñπÊ†πËØØÂ∑Æ-rmse-root-mean-squared-error"><span>2. ÂùáÊñπÊ†πËØØÂ∑Æ (RMSE - Root Mean Squared Error)</span></a></h3><p>$$RMSE = \sqrt{MSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$$</p><h3 id="_3-Âπ≥ÂùáÁªùÂØπËØØÂ∑Æ-mae-mean-absolute-error" tabindex="-1"><a class="header-anchor" href="#_3-Âπ≥ÂùáÁªùÂØπËØØÂ∑Æ-mae-mean-absolute-error"><span>3. Âπ≥ÂùáÁªùÂØπËØØÂ∑Æ (MAE - Mean Absolute Error)</span></a></h3><p>$$MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$$</p><hr><h2 id="z-score" tabindex="-1"><a class="header-anchor" href="#z-score"><span>Z-Score</span></a></h2><p>$$Z = \frac{X - \mu}{\sigma}$$</p><h2 id="standard-deviation" tabindex="-1"><a class="header-anchor" href="#standard-deviation"><span>Standard Deviation</span></a></h2><p>$$ \sigma = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2} $$</p></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/Crc011220/Crc011220.github.io/edit/main/src/posts/unimelb/ml.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last update: </span><span class="vp-meta-info" data-allow-mismatch="text">6/21/2025, 10:08:49 AM</span></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: ruocchen1220@gmail.com">Ruochen Chen</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/posts/unimelb/COMP90049.html" aria-label="Introduction to Machine Learning (COMP90049)"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span>Introduction to Machine Learning (COMP90049)</div></a><a class="route-link auto-link next" href="/posts/unimelb/SWEN90016.html" aria-label="Software Process and Management (SWEN90016)"><div class="hint">Next<span class="arrow end"></span></div><div class="link">Software Process and Management (SWEN90016)<span class="font-icon icon fa-fw fa-sm fas fa-pen-to-square" style=""></span></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">Learning today, leading tomorrow</div><div class="vp-copyright">Copyright ¬© 2025 Ruochen Chen </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script src="/assets/js/runtime~app.16418bc7.js" defer></script><script src="/assets/js/6312.2d95f1ad.js" defer></script><script src="/assets/js/app.0b60fbc5.js" defer></script>
  </body>
</html>
